{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrdbourke/tensorflow-deep-learning/blob/main/00_tensorflow_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ielzxn52r2CB"
      },
      "source": [
        "# 00. Getting started with TensorFlow: A guide to the fundamentals\n",
        "\n",
        "## What is TensorFlow?\n",
        "\n",
        "[TensorFlow](https://www.tensorflow.org/) is an open-source end-to-end machine learning library for preprocessing data, modelling data and serving models (getting them into the hands of others).\n",
        "\n",
        "## Why use TensorFlow?\n",
        "\n",
        "Rather than building machine learning and deep learning models from scratch, it's more likely you'll use a library such as TensorFlow. This is because it contains many of the most common machine learning functions you'll want to use.\n",
        "\n",
        "## What we're going to cover\n",
        "\n",
        "TensorFlow is vast. But the main premise is simple: turn data into numbers (tensors) and build machine learning algorithms to find patterns in them.\n",
        "\n",
        "In this notebook we cover some of the most fundamental TensorFlow operations, more specifically:\n",
        "* Introduction to tensors (creating tensors)\n",
        "* Getting information from tensors (tensor attributes)\n",
        "* Manipulating tensors (tensor operations)\n",
        "* Tensors and NumPy\n",
        "* Using @tf.function (a way to speed up your regular Python functions)\n",
        "* Using GPUs with TensorFlow\n",
        "* Exercises to try\n",
        "\n",
        "Things to note:\n",
        "* Many of the conventions here will happen automatically behind the scenes (when you build a model) but it's worth knowing so if you see any of these things, you know what's happening.\n",
        "* For any TensorFlow function you see, it's important to be able to check it out in the documentation, for example, going to the Python API docs for all functions and searching for what you need: https://www.tensorflow.org/api_docs/python/ (don't worry if this seems overwhelming at first, with enough practice, you'll get used to navigating the documentation).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VArmDlu06sH0"
      },
      "source": [
        "## Introduction to Tensors\n",
        "\n",
        "If you've ever used NumPy, [tensors](https://www.tensorflow.org/guide/tensor) are kind of like NumPy arrays (we'll see more on this later).\n",
        "\n",
        "For the sake of this notebook and going forward, you can think of a tensor as a multi-dimensional numerical representation (also referred to as n-dimensional, where n can be any number) of something. Where something can be almost anything you can imagine: \n",
        "* It could be numbers themselves (using tensors to represent the price of houses). \n",
        "* It could be an image (using tensors to represent the pixels of an image).\n",
        "* It could be text (using tensors to represent words).\n",
        "* Or it could be some other form of information (or data) you want to represent with numbers.\n",
        "\n",
        "The main difference between tensors and NumPy arrays (also an n-dimensional array of numbers) is that tensors can be used on [GPUs (graphical processing units)](https://blogs.nvidia.com/blog/2009/12/16/whats-the-difference-between-a-cpu-and-a-gpu/) and [TPUs (tensor processing units)](https://en.wikipedia.org/wiki/Tensor_processing_unit). \n",
        "\n",
        "The benefit of being able to run on GPUs and TPUs is faster computation, this means, if we wanted to find patterns in the numerical representations of our data, we can generally find them faster using GPUs and TPUs.\n",
        "\n",
        "Okay, we've been talking enough about tensors, let's see them.\n",
        "\n",
        "The first thing we'll do is import TensorFlow under the common alias `tf`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7ieIu8t9ijY",
        "outputId": "7548088b-91d5-412f-8544-3f6b3487e33a"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import os\n",
        "\n",
        "# Set the environment variable for hiding warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.12.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Clear any previous session\n",
        "K.clear_session()\n",
        "\n",
        "# Check if GPU is available\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "try:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)\n",
        "except RuntimeError as e:\n",
        "    # Memory growth must be set before GPUs have been initialized\n",
        "    print(e)\n",
        "finally:\n",
        "    # Find the version number (should be 2.x+)\n",
        "    print(f\"TensorFlow version: {tf.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNtV5t1qz0VP"
      },
      "source": [
        "### Creating Tensors with `tf.constant()`\n",
        "\n",
        "As mentioned before, in general, you usually won't create tensors yourself. This is because TensorFlow has modules built-in (such as [`tf.io`](https://www.tensorflow.org/api_docs/python/tf/io) and [`tf.data`](https://www.tensorflow.org/guide/data)) which are able to read your data sources and automatically convert them to tensors and then later on, neural network models will process these for us.\n",
        "\n",
        "But for now, because we're getting familar with tensors themselves and how to manipulate them, we'll see how we can create them ourselves.\n",
        "\n",
        "We'll begin by using [`tf.constant()`](https://www.tensorflow.org/api_docs/python/tf/constant)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function constant in module tensorflow.python.framework.constant_op:\n",
            "\n",
            "constant(value, dtype=None, shape=None, name='Const')\n",
            "    Creates a constant tensor from a tensor-like object.\n",
            "    \n",
            "    Note: All eager `tf.Tensor` values are immutable (in contrast to\n",
            "    `tf.Variable`). There is nothing especially _constant_ about the value\n",
            "    returned from `tf.constant`. This function is not fundamentally different from\n",
            "    `tf.convert_to_tensor`. The name `tf.constant` comes from the `value` being\n",
            "    embedded in a `Const` node in the `tf.Graph`. `tf.constant` is useful\n",
            "    for asserting that the value can be embedded that way.\n",
            "    \n",
            "    If the argument `dtype` is not specified, then the type is inferred from\n",
            "    the type of `value`.\n",
            "    \n",
            "    >>> # Constant 1-D Tensor from a python list.\n",
            "    >>> tf.constant([1, 2, 3, 4, 5, 6])\n",
            "    <tf.Tensor: shape=(6,), dtype=int32,\n",
            "        numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
            "    >>> # Or a numpy array\n",
            "    >>> a = np.array([[1, 2, 3], [4, 5, 6]])\n",
            "    >>> tf.constant(a)\n",
            "    <tf.Tensor: shape=(2, 3), dtype=int64, numpy=\n",
            "      array([[1, 2, 3],\n",
            "             [4, 5, 6]])>\n",
            "    \n",
            "    If `dtype` is specified, the resulting tensor values are cast to the requested\n",
            "    `dtype`.\n",
            "    \n",
            "    >>> tf.constant([1, 2, 3, 4, 5, 6], dtype=tf.float64)\n",
            "    <tf.Tensor: shape=(6,), dtype=float64,\n",
            "        numpy=array([1., 2., 3., 4., 5., 6.])>\n",
            "    \n",
            "    If `shape` is set, the `value` is reshaped to match. Scalars are expanded to\n",
            "    fill the `shape`:\n",
            "    \n",
            "    >>> tf.constant(0, shape=(2, 3))\n",
            "      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            "      array([[0, 0, 0],\n",
            "             [0, 0, 0]], dtype=int32)>\n",
            "    >>> tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
            "    <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            "      array([[1, 2, 3],\n",
            "             [4, 5, 6]], dtype=int32)>\n",
            "    \n",
            "    `tf.constant` has no effect if an eager Tensor is passed as the `value`, it\n",
            "    even transmits gradients:\n",
            "    \n",
            "    >>> v = tf.Variable([0.0])\n",
            "    >>> with tf.GradientTape() as g:\n",
            "    ...     loss = tf.constant(v + v)\n",
            "    >>> g.gradient(loss, v).numpy()\n",
            "    array([2.], dtype=float32)\n",
            "    \n",
            "    But, since `tf.constant` embeds the value in the `tf.Graph` this fails for\n",
            "    symbolic tensors:\n",
            "    \n",
            "    >>> with tf.compat.v1.Graph().as_default():\n",
            "    ...   i = tf.compat.v1.placeholder(shape=[None, None], dtype=tf.float32)\n",
            "    ...   t = tf.constant(i)\n",
            "    Traceback (most recent call last):\n",
            "    ...\n",
            "    TypeError: ...\n",
            "    \n",
            "    `tf.constant` will create tensors on the current device. Inputs which are\n",
            "    already tensors maintain their placements unchanged.\n",
            "    \n",
            "    Related Ops:\n",
            "    \n",
            "    * `tf.convert_to_tensor` is similar but:\n",
            "      * It has no `shape` argument.\n",
            "      * Symbolic tensors are allowed to pass through.\n",
            "    \n",
            "      >>> with tf.compat.v1.Graph().as_default():\n",
            "      ...   i = tf.compat.v1.placeholder(shape=[None, None], dtype=tf.float32)\n",
            "      ...   t = tf.convert_to_tensor(i)\n",
            "    \n",
            "    * `tf.fill`: differs in a few ways:\n",
            "      *   `tf.constant` supports arbitrary constants, not just uniform scalar\n",
            "          Tensors like `tf.fill`.\n",
            "      *   `tf.fill` creates an Op in the graph that is expanded at runtime, so it\n",
            "          can efficiently represent large tensors.\n",
            "      *   Since `tf.fill` does not embed the value, it can produce dynamically\n",
            "          sized outputs.\n",
            "    \n",
            "    Args:\n",
            "      value: A constant value (or list) of output type `dtype`.\n",
            "      dtype: The type of the elements of the resulting tensor.\n",
            "      shape: Optional dimensions of resulting tensor.\n",
            "      name: Optional name for the tensor.\n",
            "    \n",
            "    Returns:\n",
            "      A Constant Tensor.\n",
            "    \n",
            "    Raises:\n",
            "      TypeError: if shape is incorrectly specified or unsupported.\n",
            "      ValueError: if called on a symbolic tensor.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Let's see the documentation for tf.constant\n",
        "help(tf.constant)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC7aQgqi0M_Z",
        "outputId": "89250b3e-86a9-4d9b-b15f-8ae0812dde5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a scalar (rank 0 tensor)\n",
        "scalar = tf.constant(value=7, \n",
        "                     dtype=None, \n",
        "                     shape=None, \n",
        "                     name='scalar')\n",
        "scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6fXE5dXkO_3"
      },
      "source": [
        "A scalar is known as a rank 0 tensor. Because it has no dimensions (it's just a number).\n",
        "\n",
        "> ðŸ”‘ **Note:** For now, you don't need to know too much about the different ranks of tensors (but we will see more on this later). The important point is knowing tensors can have an unlimited range of dimensions (the exact amount will depend on what data you're representing)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(scalar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OVERLOADABLE_OPERATORS\n",
            "backing_device\n",
            "consumers\n",
            "cpu\n",
            "device\n",
            "dtype\n",
            "eval\n",
            "experimental_ref\n",
            "get_shape\n",
            "gpu\n",
            "graph\n",
            "is_packed\n",
            "name\n",
            "ndim\n",
            "numpy\n",
            "op\n",
            "ref\n",
            "set_shape\n",
            "shape\n",
            "value_index\n"
          ]
        }
      ],
      "source": [
        "# Check the methods available for `scalar`\n",
        "for e in dir(scalar):\n",
        "    if not e.startswith(\"_\"):\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sgUNKoFkJ21",
        "outputId": "5b244f42-05bc-4702-dc5c-a91716443c4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the number of dimensions of a tensor \n",
        "# ndim stands for number of dimensions\n",
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irtCo2fs0V_o",
        "outputId": "e424c961-7a1a-4544-ed5a-becc1cc1d1bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10], dtype=int32)>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a vector (more than 0 dimensions)\n",
        "vector = tf.constant(value=[10, 10], \n",
        "                     dtype=None, \n",
        "                     shape=None, \n",
        "                     name='vector')\n",
        "vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.framework.ops.EagerTensor"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DDc36pvmOse",
        "outputId": "f6fbc397-5058-4f2f-8f27-9d7c6adf4f95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the number of dimensions of our vector tensor\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXf5A5360V7A",
        "outputId": "3f773144-81c5-49d2-819b-192ff0153c03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 7, 10]], dtype=int32)>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a matrix (more than 1 dimension)\n",
        "matrix = tf.constant(value=[[10, 7],\n",
        "                      [7, 10]], \n",
        "                      dtype=None, \n",
        "                      shape=None, \n",
        "                      name='matrix')\n",
        "matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Asmn6YghlT6u",
        "outputId": "aa08a360-2917-4be3-e263-b4cea62ed569"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "matrix.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvQb7RT2s9Te"
      },
      "source": [
        "By default, TensorFlow creates tensors with either an `int32` or `float32` datatype.\n",
        "\n",
        "This is known as [32-bit precision](https://en.wikipedia.org/wiki/Precision_(computer_science) (the higher the number, the more precise the number, the more space it takes up on your computer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEgthLq80V2u",
        "outputId": "f64d9ac7-1a83-4fc3-9511-a02e5e19dd6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
              "array([[10.,  7.],\n",
              "       [ 3.,  2.],\n",
              "       [ 8.,  9.]], dtype=float16)>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create another matrix and define the datatype\n",
        "# Specify the datatype with 'dtype'\n",
        "another_matrix = tf.constant(value=[[10., 7.],\n",
        "                              [3., 2.],\n",
        "                              [8., 9.]], \n",
        "                              dtype=tf.float16, \n",
        "                              shape=None, \n",
        "                              name='another_matrix') \n",
        "another_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-Y-lXdOlXRg",
        "outputId": "7f7c851b-9487-4ce8-de4d-5a747b9912e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Even though another_matrix contains more numbers, its dimensions stay the same\n",
        "another_matrix.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAy7J6fT0Vwz",
        "outputId": "77c91572-9b0a-4e0d-d39f-91455f41ee1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
              "array([[[ 1,  2,  3],\n",
              "        [ 4,  5,  6]],\n",
              "\n",
              "       [[ 7,  8,  9],\n",
              "        [10, 11, 12]],\n",
              "\n",
              "       [[13, 14, 15],\n",
              "        [16, 17, 18]]], dtype=int32)>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# How about a tensor? (more than 2 dimensions, although, all of the above items are also technically tensors)\n",
        "tensor = tf.constant(value=[[[1, 2, 3],\n",
        "                       [4, 5, 6]],\n",
        "                      [[7, 8, 9],\n",
        "                       [10, 11, 12]],\n",
        "                      [[13, 14, 15],\n",
        "                       [16, 17, 18]]], \n",
        "                       dtype=None, \n",
        "                       shape=None, \n",
        "                       name='tensor')\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhIsj108mFOS",
        "outputId": "64bf5633-c17f-42b7-ce0a-14e3df8a2dec"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5MGwSpA100u"
      },
      "source": [
        "This is known as a rank 3 tensor (3-dimensions), however a tensor can have an arbitrary (unlimited) amount of dimensions.\n",
        "\n",
        "For example, you might turn a series of images into tensors with shape (224, 224, 3, 32), where:\n",
        "* 224, 224 (the first 2 dimensions) are the height and width of the images in pixels.\n",
        "* 3 is the number of colour channels of the image (red, green blue).\n",
        "* 32 is the batch size (the number of images a neural network sees at any one time).\n",
        "\n",
        "All of the above variables we've created are actually tensors. But you may also hear them referred to as their different names (the ones we gave them):\n",
        "* **scalar**: a single number.\n",
        "* **vector**: a number with direction (e.g. wind speed with direction).\n",
        "* **matrix**: a 2-dimensional array of numbers.\n",
        "* **tensor**: an n-dimensional array of numbers (where n can be any number, a 0-dimension tensor is a scalar, a 1-dimension tensor is a vector). \n",
        "\n",
        "To add to the confusion, the terms matrix and tensor are often used interchangeably.\n",
        "\n",
        "Going forward since we're using TensorFlow, everything we refer to and use will be tensors.\n",
        "\n",
        "For more on the mathematical difference between scalars, vectors and matrices see the [visual algebra post by Math is Fun](https://www.mathsisfun.com/algebra/scalar-vector-matrix.html).\n",
        "\n",
        "![difference between scalar, vector, matrix, tensor](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZMfDFKC0Cl7"
      },
      "source": [
        "### Creating Tensors with `tf.Variable()`\n",
        "\n",
        "You can also (although you likely rarely will, because often, when working with data, tensors are created for you automatically) create tensors using [`tf.Variable()`](https://www.tensorflow.org/api_docs/python/tf/Variable).\n",
        "\n",
        "The difference between `tf.Variable()` and `tf.constant()` is tensors created with `tf.constant()` are immutable (can't be changed, can only be used to create a new tensor), where as, tensors created with `tf.Variable()` are mutable (can be changed)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class Variable in module tensorflow.python.ops.variables:\n",
            "\n",
            "class Variable(tensorflow.python.trackable.base.Trackable)\n",
            " |  Variable(*args, **kwargs)\n",
            " |  \n",
            " |  See the [variable guide](https://tensorflow.org/guide/variable).\n",
            " |  \n",
            " |  A variable maintains shared, persistent state manipulated by a program.\n",
            " |  \n",
            " |  The `Variable()` constructor requires an initial value for the variable, which\n",
            " |  can be a `Tensor` of any type and shape. This initial value defines the type\n",
            " |  and shape of the variable. After construction, the type and shape of the\n",
            " |  variable are fixed. The value can be changed using one of the assign methods.\n",
            " |  \n",
            " |  >>> v = tf.Variable(1.)\n",
            " |  >>> v.assign(2.)\n",
            " |  <tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
            " |  >>> v.assign_add(0.5)\n",
            " |  <tf.Variable ... shape=() dtype=float32, numpy=2.5>\n",
            " |  \n",
            " |  The `shape` argument to `Variable`'s constructor allows you to construct a\n",
            " |  variable with a less defined shape than its `initial_value`:\n",
            " |  \n",
            " |  >>> v = tf.Variable(1., shape=tf.TensorShape(None))\n",
            " |  >>> v.assign([[1.]])\n",
            " |  <tf.Variable ... shape=<unknown> dtype=float32, numpy=array([[1.]], ...)>\n",
            " |  \n",
            " |  Just like any `Tensor`, variables created with `Variable()` can be used as\n",
            " |  inputs to operations. Additionally, all the operators overloaded for the\n",
            " |  `Tensor` class are carried over to variables.\n",
            " |  \n",
            " |  >>> w = tf.Variable([[1.], [2.]])\n",
            " |  >>> x = tf.constant([[3., 4.]])\n",
            " |  >>> tf.matmul(w, x)\n",
            " |  <tf.Tensor:... shape=(2, 2), ... numpy=\n",
            " |    array([[3., 4.],\n",
            " |           [6., 8.]], dtype=float32)>\n",
            " |  >>> tf.sigmoid(w + x)\n",
            " |  <tf.Tensor:... shape=(2, 2), ...>\n",
            " |  \n",
            " |  When building a machine learning model it is often convenient to distinguish\n",
            " |  between variables holding trainable model parameters and other variables such\n",
            " |  as a `step` variable used to count training steps. To make this easier, the\n",
            " |  variable constructor supports a `trainable=<bool>`\n",
            " |  parameter. `tf.GradientTape` watches trainable variables by default:\n",
            " |  \n",
            " |  >>> with tf.GradientTape(persistent=True) as tape:\n",
            " |  ...   trainable = tf.Variable(1.)\n",
            " |  ...   non_trainable = tf.Variable(2., trainable=False)\n",
            " |  ...   x1 = trainable * 2.\n",
            " |  ...   x2 = non_trainable * 3.\n",
            " |  >>> tape.gradient(x1, trainable)\n",
            " |  <tf.Tensor:... shape=(), dtype=float32, numpy=2.0>\n",
            " |  >>> assert tape.gradient(x2, non_trainable) is None  # Unwatched\n",
            " |  \n",
            " |  Variables are automatically tracked when assigned to attributes of types\n",
            " |  inheriting from `tf.Module`.\n",
            " |  \n",
            " |  >>> m = tf.Module()\n",
            " |  >>> m.v = tf.Variable([1.])\n",
            " |  >>> m.trainable_variables\n",
            " |  (<tf.Variable ... shape=(1,) ... numpy=array([1.], dtype=float32)>,)\n",
            " |  \n",
            " |  This tracking then allows saving variable values to\n",
            " |  [training checkpoints](https://www.tensorflow.org/guide/checkpoint), or to\n",
            " |  [SavedModels](https://www.tensorflow.org/guide/saved_model) which include\n",
            " |  serialized TensorFlow graphs.\n",
            " |  \n",
            " |  Variables are often captured and manipulated by `tf.function`s. This works the\n",
            " |  same way the un-decorated function would have:\n",
            " |  \n",
            " |  >>> v = tf.Variable(0.)\n",
            " |  >>> read_and_decrement = tf.function(lambda: v.assign_sub(0.1))\n",
            " |  >>> read_and_decrement()\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=-0.1>\n",
            " |  >>> read_and_decrement()\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=-0.2>\n",
            " |  \n",
            " |  Variables created inside a `tf.function` must be owned outside the function\n",
            " |  and be created only once:\n",
            " |  \n",
            " |  >>> class M(tf.Module):\n",
            " |  ...   @tf.function\n",
            " |  ...   def __call__(self, x):\n",
            " |  ...     if not hasattr(self, \"v\"):  # Or set self.v to None in __init__\n",
            " |  ...       self.v = tf.Variable(x)\n",
            " |  ...     return self.v * x\n",
            " |  >>> m = M()\n",
            " |  >>> m(2.)\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=4.0>\n",
            " |  >>> m(3.)\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
            " |  >>> m.v\n",
            " |  <tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
            " |  \n",
            " |  See the `tf.function` documentation for details.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Variable\n",
            " |      tensorflow.python.trackable.base.Trackable\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __abs__ = abs(x, name=None)\n",
            " |      Computes the absolute value of a tensor.\n",
            " |      \n",
            " |      Given a tensor of integer or floating-point values, this operation returns a\n",
            " |      tensor of the same type, where each element contains the absolute value of the\n",
            " |      corresponding element in the input.\n",
            " |      \n",
            " |      Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
            " |      `float32` or `float64` that is the absolute value of each element in `x`. For\n",
            " |      a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
            " |      \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
            " |      \n",
            " |      For example:\n",
            " |      \n",
            " |      >>> # real number\n",
            " |      >>> x = tf.constant([-2.25, 3.25])\n",
            " |      >>> tf.abs(x)\n",
            " |      <tf.Tensor: shape=(2,), dtype=float32,\n",
            " |      numpy=array([2.25, 3.25], dtype=float32)>\n",
            " |      \n",
            " |      >>> # complex number\n",
            " |      >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
            " |      >>> tf.abs(x)\n",
            " |      <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
            " |      array([[5.25594901],\n",
            " |             [6.60492241]])>\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
            " |          `int32`, `int64`, `complex64` or `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
            " |          with absolute values. Note, for `complex64` or `complex128` input, the\n",
            " |          returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
            " |  \n",
            " |  __add__ = binary_op_wrapper(x, y)\n",
            " |      The operation invoked by the `Tensor.__add__` operator.\n",
            " |      \n",
            " |      Purpose in the API:\n",
            " |      \n",
            " |        This method is exposed in TensorFlow's API so that library developers\n",
            " |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
            " |        custom composite tensors & other custom objects.\n",
            " |      \n",
            " |        The API symbol is not intended to be called by users directly and does\n",
            " |        appear in TensorFlow's generated documentation.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: The left-hand side of the `+` operator.\n",
            " |        y: The right-hand side of the `+` operator.\n",
            " |        name: an optional name for the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of the elementwise `+` operation.\n",
            " |  \n",
            " |  __and__ = binary_op_wrapper(x, y)\n",
            " |  \n",
            " |  __div__ = binary_op_wrapper(x, y)\n",
            " |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Deprecated in favor of operator or tf.math.divide.\n",
            " |      \n",
            " |      @compatibility(TF2)\n",
            " |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
            " |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
            " |      semantics.\n",
            " |      @end_compatibility\n",
            " |      \n",
            " |      \n",
            " |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
            " |      and `y` are both integers then the result will be an integer. This is in\n",
            " |      contrast to Python 3, where division with `/` is always a float while division\n",
            " |      with `//` is always an integer.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` returns the quotient of x and y.\n",
            " |  \n",
            " |  __eq__(self, other)\n",
            " |      Compares two variables element-wise for equality.\n",
            " |  \n",
            " |  __floordiv__ = binary_op_wrapper(x, y)\n",
            " |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
            " |      \n",
            " |      Mathematically, this is equivalent to floor(x / y). For example:\n",
            " |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
            " |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
            " |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
            " |      \n",
            " |      Note: `x` and `y` must have the same type, and the result will have the same\n",
            " |      type as well.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` rounded toward -infinity.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If the inputs are complex.\n",
            " |  \n",
            " |  __ge__ = greater_equal(x, y, name=None)\n",
            " |      Returns the truth value of (x >= y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6, 7])\n",
            " |      y = tf.constant([5, 2, 5, 10])\n",
            " |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6, 7])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __getitem__ = _SliceHelperVar(var, slice_spec)\n",
            " |      Creates a slice helper object given a variable.\n",
            " |      \n",
            " |      This allows creating a sub-tensor from part of the current contents\n",
            " |      of a variable. See `tf.Tensor.__getitem__` for detailed examples\n",
            " |      of slicing.\n",
            " |      \n",
            " |      This function in addition also allows assignment to a sliced range.\n",
            " |      This is similar to `__setitem__` functionality in Python. However,\n",
            " |      the syntax is different so that the user can capture the assignment\n",
            " |      operation for grouping or passing to `sess.run()` in TF1.\n",
            " |      For example,\n",
            " |      \n",
            " |      ```python\n",
            " |      import tensorflow as tf\n",
            " |      A = tf.Variable([[1,2,3], [4,5,6], [7,8,9]], dtype=tf.float32)\n",
            " |      print(A[:2, :2])  # => [[1,2], [4,5]]\n",
            " |      \n",
            " |      A[:2,:2].assign(22. * tf.ones((2, 2))))\n",
            " |      print(A) # => [[22, 22, 3], [22, 22, 6], [7,8,9]]\n",
            " |      ```\n",
            " |      \n",
            " |      Note that assignments currently do not support NumPy broadcasting\n",
            " |      semantics.\n",
            " |      \n",
            " |      Args:\n",
            " |        var: An `ops.Variable` object.\n",
            " |        slice_spec: The arguments to `Tensor.__getitem__`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
            " |        As an operator. The operator also has a `assign()` method\n",
            " |        that can be used to generate an assignment operator.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If a slice range is negative size.\n",
            " |        TypeError: TypeError: If the slice indices aren't int, slice,\n",
            " |          ellipsis, tf.newaxis or int32/int64 tensors.\n",
            " |  \n",
            " |  __gt__ = greater(x, y, name=None)\n",
            " |      Returns the truth value of (x > y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5, 2, 5])\n",
            " |      tf.math.greater(x, y) ==> [False, True, True]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.greater(x, y) ==> [False, False, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __hash__(self)\n",
            " |      Return hash(self).\n",
            " |  \n",
            " |  __init__(self, initial_value=None, trainable=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, import_scope=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, shape=None, experimental_enable_variable_lifting=True)\n",
            " |      Creates a new variable with value `initial_value`. (deprecated arguments)\n",
            " |      \n",
            " |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(caching_device)`. They will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      A variable's value can be manually cached by calling tf.Variable.read_value() under a tf.device scope. The caching_device argument does not work properly.\n",
            " |      \n",
            " |      Args:\n",
            " |        initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
            " |          which is the initial value for the Variable. The initial value must have\n",
            " |          a shape specified unless `validate_shape` is set to False. Can also be a\n",
            " |          callable with no argument that returns the initial value when called. In\n",
            " |          that case, `dtype` must be specified. (Note that initializer functions\n",
            " |          from init_ops.py must first be bound to a shape before being used here.)\n",
            " |        trainable: If `True`, GradientTapes automatically watch uses of this\n",
            " |          variable. Defaults to `True`, unless `synchronization` is set to\n",
            " |          `ON_READ`, in which case it defaults to `False`.\n",
            " |        validate_shape: If `False`, allows the variable to be initialized with a\n",
            " |          value of unknown shape. If `True`, the default, the shape of\n",
            " |          `initial_value` must be known.\n",
            " |        caching_device: Note: This argument is only valid when using a v1-style\n",
            " |          `Session`. Optional device string describing where the Variable should\n",
            " |          be cached for reading. Defaults to the Variable's device. If not `None`,\n",
            " |          caches on another device. Typical use is to cache on the device where\n",
            " |          the Ops using the Variable reside, to deduplicate copying through\n",
            " |          `Switch` and other conditional statements.\n",
            " |        name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
            " |          uniquified automatically.\n",
            " |        variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
            " |          Variable object with its contents, referencing the variable's nodes in\n",
            " |          the graph, which must already exist. The graph is not changed.\n",
            " |          `variable_def` and the other arguments are mutually exclusive.\n",
            " |        dtype: If set, initial_value will be converted to the given type. If\n",
            " |          `None`, either the datatype will be kept (if `initial_value` is a\n",
            " |          Tensor), or `convert_to_tensor` will decide.\n",
            " |        import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
            " |          used when initializing from protocol buffer.\n",
            " |        constraint: An optional projection function to be applied to the variable\n",
            " |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
            " |          constraints or value constraints for layer weights). The function must\n",
            " |          take as input the unprojected Tensor representing the value of the\n",
            " |          variable and return the Tensor for the projected value (which must have\n",
            " |          the same shape). Constraints are not safe to use when doing asynchronous\n",
            " |          distributed training.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses when to\n",
            " |          synchronize.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        shape: (optional) The shape of this variable. If None, the shape of\n",
            " |          `initial_value` will be used. When setting this argument to\n",
            " |          `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
            " |          can be assigned with values of different shapes.\n",
            " |        experimental_enable_variable_lifting: Whether to lift the variable out if\n",
            " |          it's in a `tf.function`. Default is `True`. When this argument\n",
            " |          is `True`, variable creation will follow the behavior and\n",
            " |          restrictions described\n",
            " |          [here](https://www.tensorflow.org/guide/function#creating_tfvariables).\n",
            " |          If this argument is `False`, that description doesn't apply,\n",
            " |          and you can freely create and use the variable in the\n",
            " |          `tf.function`, as if it's a \"mutable `tf.Tensor`\". You can't\n",
            " |          return the variable though.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If both `variable_def` and initial_value are specified.\n",
            " |        ValueError: If the initial value is not specified, or does not have a\n",
            " |          shape and `validate_shape` is `True`.\n",
            " |  \n",
            " |  __invert__ = invert_(x, name=None)\n",
            " |  \n",
            " |  __iter__(self)\n",
            " |      When executing eagerly, iterates over the value of the variable.\n",
            " |  \n",
            " |  __le__ = less_equal(x, y, name=None)\n",
            " |      Returns the truth value of (x <= y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5, 6, 6])\n",
            " |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __lt__ = less(x, y, name=None)\n",
            " |      Returns the truth value of (x < y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.less(x, y) ==> [False, True, False]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5, 6, 7])\n",
            " |      tf.math.less(x, y) ==> [False, True, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __matmul__ = binary_op_wrapper(x, y)\n",
            " |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
            " |      \n",
            " |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
            " |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
            " |      and any further outer dimensions specify matching batch size.\n",
            " |      \n",
            " |      Both matrices must be of the same type. The supported types are:\n",
            " |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |      `complex64`, `complex128`.\n",
            " |      \n",
            " |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
            " |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
            " |      by default.\n",
            " |      \n",
            " |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
            " |      multiplication algorithm can be used by setting the corresponding\n",
            " |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
            " |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
            " |      datatypes `bfloat16` or `float32`.\n",
            " |      \n",
            " |      A simple 2-D tensor matrix multiplication:\n",
            " |      \n",
            " |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
            " |      >>> a  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            " |      array([[1, 2, 3],\n",
            " |             [4, 5, 6]], dtype=int32)>\n",
            " |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
            " |      >>> b  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            " |      array([[ 7,  8],\n",
            " |             [ 9, 10],\n",
            " |             [11, 12]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
            " |      array([[ 58,  64],\n",
            " |             [139, 154]], dtype=int32)>\n",
            " |      \n",
            " |      A batch matrix multiplication with batch shape [2]:\n",
            " |      \n",
            " |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
            " |      >>> a  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
            " |      array([[[ 1,  2,  3],\n",
            " |              [ 4,  5,  6]],\n",
            " |             [[ 7,  8,  9],\n",
            " |              [10, 11, 12]]], dtype=int32)>\n",
            " |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
            " |      >>> b  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
            " |      array([[[13, 14],\n",
            " |              [15, 16],\n",
            " |              [17, 18]],\n",
            " |             [[19, 20],\n",
            " |              [21, 22],\n",
            " |              [23, 24]]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
            " |      array([[[ 94, 100],\n",
            " |              [229, 244]],\n",
            " |             [[508, 532],\n",
            " |              [697, 730]]], dtype=int32)>\n",
            " |      \n",
            " |      Since python >= 3.5 the @ operator is supported\n",
            " |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
            " |      it simply calls the `tf.matmul()` function, so the following lines are\n",
            " |      equivalent:\n",
            " |      \n",
            " |      >>> d = a @ b @ [[10], [11]]\n",
            " |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
            " |      \n",
            " |      Args:\n",
            " |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
            " |          `complex64`, `complex128` and rank > 1.\n",
            " |        b: `tf.Tensor` with same type and rank as `a`.\n",
            " |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
            " |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
            " |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `a` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `b` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        output_type: The output datatype if needed. Defaults to None in which case\n",
            " |          the output_type is the same as input type. Currently only works when input\n",
            " |          tensors are type (u)int8 and output_type can be int32.\n",
            " |        name: Name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
            " |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
            " |        transpose or adjoint attributes are `False`:\n",
            " |      \n",
            " |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
            " |        for all indices `i`, `j`.\n",
            " |      \n",
            " |        Note: This is matrix product, not element-wise product.\n",
            " |      \n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
            " |          `adjoint_b` are both set to `True`.\n",
            " |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
            " |          `output_type` is not (u)int8, (u)int8 and int32.\n",
            " |  \n",
            " |  __mod__ = binary_op_wrapper(x, y)\n",
            " |      Returns element-wise remainder of division.\n",
            " |      \n",
            " |      This follows Python semantics in that the\n",
            " |      result here is consistent with a flooring divide. E.g.\n",
            " |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
            " |      \n",
            " |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __mul__ = binary_op_wrapper(x, y)\n",
            " |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
            " |  \n",
            " |  __ne__(self, other)\n",
            " |      Compares two variables element-wise for equality.\n",
            " |  \n",
            " |  __neg__ = neg(x, name=None)\n",
            " |      Computes numerical negative value element-wise.\n",
            " |      \n",
            " |      I.e., \\\\(y = -x\\\\).\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __or__ = binary_op_wrapper(x, y)\n",
            " |  \n",
            " |  __pow__ = binary_op_wrapper(x, y)\n",
            " |      Computes the power of one value to another.\n",
            " |      \n",
            " |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
            " |      corresponding elements in `x` and `y`. For example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([[2, 2], [3, 3]])\n",
            " |      y = tf.constant([[8, 16], [2, 3]])\n",
            " |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`.\n",
            " |  \n",
            " |  __radd__ = r_binary_op_wrapper(y, x)\n",
            " |      The operation invoked by the `Tensor.__add__` operator.\n",
            " |      \n",
            " |      Purpose in the API:\n",
            " |      \n",
            " |        This method is exposed in TensorFlow's API so that library developers\n",
            " |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
            " |        custom composite tensors & other custom objects.\n",
            " |      \n",
            " |        The API symbol is not intended to be called by users directly and does\n",
            " |        appear in TensorFlow's generated documentation.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: The left-hand side of the `+` operator.\n",
            " |        y: The right-hand side of the `+` operator.\n",
            " |        name: an optional name for the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of the elementwise `+` operation.\n",
            " |  \n",
            " |  __rand__ = r_binary_op_wrapper(y, x)\n",
            " |  \n",
            " |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
            " |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Deprecated in favor of operator or tf.math.divide.\n",
            " |      \n",
            " |      @compatibility(TF2)\n",
            " |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
            " |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
            " |      semantics.\n",
            " |      @end_compatibility\n",
            " |      \n",
            " |      \n",
            " |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
            " |      and `y` are both integers then the result will be an integer. This is in\n",
            " |      contrast to Python 3, where division with `/` is always a float while division\n",
            " |      with `//` is always an integer.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` returns the quotient of x and y.\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
            " |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
            " |      \n",
            " |      Mathematically, this is equivalent to floor(x / y). For example:\n",
            " |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
            " |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
            " |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
            " |      \n",
            " |      Note: `x` and `y` must have the same type, and the result will have the same\n",
            " |      type as well.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` rounded toward -infinity.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If the inputs are complex.\n",
            " |  \n",
            " |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
            " |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
            " |      \n",
            " |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
            " |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
            " |      and any further outer dimensions specify matching batch size.\n",
            " |      \n",
            " |      Both matrices must be of the same type. The supported types are:\n",
            " |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |      `complex64`, `complex128`.\n",
            " |      \n",
            " |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
            " |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
            " |      by default.\n",
            " |      \n",
            " |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
            " |      multiplication algorithm can be used by setting the corresponding\n",
            " |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
            " |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
            " |      datatypes `bfloat16` or `float32`.\n",
            " |      \n",
            " |      A simple 2-D tensor matrix multiplication:\n",
            " |      \n",
            " |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
            " |      >>> a  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            " |      array([[1, 2, 3],\n",
            " |             [4, 5, 6]], dtype=int32)>\n",
            " |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
            " |      >>> b  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            " |      array([[ 7,  8],\n",
            " |             [ 9, 10],\n",
            " |             [11, 12]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
            " |      array([[ 58,  64],\n",
            " |             [139, 154]], dtype=int32)>\n",
            " |      \n",
            " |      A batch matrix multiplication with batch shape [2]:\n",
            " |      \n",
            " |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
            " |      >>> a  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
            " |      array([[[ 1,  2,  3],\n",
            " |              [ 4,  5,  6]],\n",
            " |             [[ 7,  8,  9],\n",
            " |              [10, 11, 12]]], dtype=int32)>\n",
            " |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
            " |      >>> b  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
            " |      array([[[13, 14],\n",
            " |              [15, 16],\n",
            " |              [17, 18]],\n",
            " |             [[19, 20],\n",
            " |              [21, 22],\n",
            " |              [23, 24]]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
            " |      array([[[ 94, 100],\n",
            " |              [229, 244]],\n",
            " |             [[508, 532],\n",
            " |              [697, 730]]], dtype=int32)>\n",
            " |      \n",
            " |      Since python >= 3.5 the @ operator is supported\n",
            " |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
            " |      it simply calls the `tf.matmul()` function, so the following lines are\n",
            " |      equivalent:\n",
            " |      \n",
            " |      >>> d = a @ b @ [[10], [11]]\n",
            " |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
            " |      \n",
            " |      Args:\n",
            " |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
            " |          `complex64`, `complex128` and rank > 1.\n",
            " |        b: `tf.Tensor` with same type and rank as `a`.\n",
            " |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
            " |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
            " |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `a` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `b` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        output_type: The output datatype if needed. Defaults to None in which case\n",
            " |          the output_type is the same as input type. Currently only works when input\n",
            " |          tensors are type (u)int8 and output_type can be int32.\n",
            " |        name: Name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
            " |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
            " |        transpose or adjoint attributes are `False`:\n",
            " |      \n",
            " |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
            " |        for all indices `i`, `j`.\n",
            " |      \n",
            " |        Note: This is matrix product, not element-wise product.\n",
            " |      \n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
            " |          `adjoint_b` are both set to `True`.\n",
            " |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
            " |          `output_type` is not (u)int8, (u)int8 and int32.\n",
            " |  \n",
            " |  __rmod__ = r_binary_op_wrapper(y, x)\n",
            " |      Returns element-wise remainder of division.\n",
            " |      \n",
            " |      This follows Python semantics in that the\n",
            " |      result here is consistent with a flooring divide. E.g.\n",
            " |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
            " |      \n",
            " |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __rmul__ = r_binary_op_wrapper(y, x)\n",
            " |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
            " |  \n",
            " |  __ror__ = r_binary_op_wrapper(y, x)\n",
            " |  \n",
            " |  __rpow__ = r_binary_op_wrapper(y, x)\n",
            " |      Computes the power of one value to another.\n",
            " |      \n",
            " |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
            " |      corresponding elements in `x` and `y`. For example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([[2, 2], [3, 3]])\n",
            " |      y = tf.constant([[8, 16], [2, 3]])\n",
            " |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`.\n",
            " |  \n",
            " |  __rsub__ = r_binary_op_wrapper(y, x)\n",
            " |      Returns x - y element-wise.\n",
            " |      \n",
            " |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Both input and output have a range `(-inf, inf)`.\n",
            " |      \n",
            " |      Example usages below.\n",
            " |      \n",
            " |      Subtract operation between an array and a scalar:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = 1\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
            " |      \n",
            " |      Note that binary `-` operator can be used instead:\n",
            " |      \n",
            " |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
            " |      >>> y = tf.convert_to_tensor(1)\n",
            " |      >>> x - y\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      \n",
            " |      Subtract operation between an array and a tensor of same shape:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
            " |      \n",
            " |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
            " |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
            " |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
            " |      conversion.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
            " |      >>> y = [2**8 + 1, 2**8 + 2]\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
            " |      \n",
            " |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
            " |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
            " |      . The two input array shapes are compared element-wise. Starting with the\n",
            " |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
            " |      needs to be `1`.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]],\n",
            " |             [[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]]])>\n",
            " |      \n",
            " |      Example with inputs of different dimensions:\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(1, 6)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]],\n",
            " |             [[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]]])>\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
            " |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
            " |      \n",
            " |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
            " |      division operator semantics.\n",
            " |      \n",
            " |      This function forces Python 3 division operator semantics where all integer\n",
            " |      arguments are cast to floating types first.   This op is generated by normal\n",
            " |      `x / y` division in Python 3 and in Python 2.7 with\n",
            " |      `from __future__ import division`.  If you want integer division that rounds\n",
            " |      down, use `x // y` or `tf.math.floordiv`.\n",
            " |      \n",
            " |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
            " |      point, the output will have the same type.  If the inputs are integral, the\n",
            " |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
            " |      and `int64` (matching the behavior of Numpy).\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of numeric type.\n",
            " |        y: `Tensor` denominator of numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` evaluated in floating point.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If `x` and `y` have different dtypes.\n",
            " |  \n",
            " |  __rxor__ = r_binary_op_wrapper(y, x)\n",
            " |  \n",
            " |  __sub__ = binary_op_wrapper(x, y)\n",
            " |      Returns x - y element-wise.\n",
            " |      \n",
            " |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Both input and output have a range `(-inf, inf)`.\n",
            " |      \n",
            " |      Example usages below.\n",
            " |      \n",
            " |      Subtract operation between an array and a scalar:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = 1\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
            " |      \n",
            " |      Note that binary `-` operator can be used instead:\n",
            " |      \n",
            " |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
            " |      >>> y = tf.convert_to_tensor(1)\n",
            " |      >>> x - y\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      \n",
            " |      Subtract operation between an array and a tensor of same shape:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
            " |      \n",
            " |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
            " |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
            " |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
            " |      conversion.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
            " |      >>> y = [2**8 + 1, 2**8 + 2]\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
            " |      \n",
            " |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
            " |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
            " |      . The two input array shapes are compared element-wise. Starting with the\n",
            " |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
            " |      needs to be `1`.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]],\n",
            " |             [[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]]])>\n",
            " |      \n",
            " |      Example with inputs of different dimensions:\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(1, 6)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]],\n",
            " |             [[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]]])>\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __truediv__ = binary_op_wrapper(x, y)\n",
            " |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
            " |      \n",
            " |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
            " |      division operator semantics.\n",
            " |      \n",
            " |      This function forces Python 3 division operator semantics where all integer\n",
            " |      arguments are cast to floating types first.   This op is generated by normal\n",
            " |      `x / y` division in Python 3 and in Python 2.7 with\n",
            " |      `from __future__ import division`.  If you want integer division that rounds\n",
            " |      down, use `x // y` or `tf.math.floordiv`.\n",
            " |      \n",
            " |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
            " |      point, the output will have the same type.  If the inputs are integral, the\n",
            " |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
            " |      and `int64` (matching the behavior of Numpy).\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of numeric type.\n",
            " |        y: `Tensor` denominator of numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` evaluated in floating point.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If `x` and `y` have different dtypes.\n",
            " |  \n",
            " |  __xor__ = binary_op_wrapper(x, y)\n",
            " |  \n",
            " |  assign(self, value, use_locking=False, name=None, read_value=True)\n",
            " |      Assigns a new value to the variable.\n",
            " |      \n",
            " |      This is essentially a shortcut for `assign(self, value)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        value: A `Tensor`. The new value for this variable.\n",
            " |        use_locking: If `True`, use locking during the assignment.\n",
            " |        name: The name of the operation to be created\n",
            " |        read_value: if True, will return something which evaluates to the new\n",
            " |          value of the variable; if False will return the assign op.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable. If `read_value` is false, instead returns None in\n",
            " |        Eager mode and the assign op in graph mode.\n",
            " |  \n",
            " |  assign_add(self, delta, use_locking=False, name=None, read_value=True)\n",
            " |      Adds a value to this variable.\n",
            " |      \n",
            " |       This is essentially a shortcut for `assign_add(self, delta)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        delta: A `Tensor`. The value to add to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: The name of the operation to be created\n",
            " |        read_value: if True, will return something which evaluates to the new\n",
            " |          value of the variable; if False will return the assign op.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable. If `read_value` is false, instead returns None in\n",
            " |        Eager mode and the assign op in graph mode.\n",
            " |  \n",
            " |  assign_sub(self, delta, use_locking=False, name=None, read_value=True)\n",
            " |      Subtracts a value from this variable.\n",
            " |      \n",
            " |      This is essentially a shortcut for `assign_sub(self, delta)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        delta: A `Tensor`. The value to subtract from this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: The name of the operation to be created\n",
            " |        read_value: if True, will return something which evaluates to the new\n",
            " |          value of the variable; if False will return the assign op.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable. If `read_value` is false, instead returns None in\n",
            " |        Eager mode and the assign op in graph mode.\n",
            " |  \n",
            " |  batch_scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Assigns `tf.IndexedSlices` to this variable batch-wise.\n",
            " |      \n",
            " |      Analogous to `batch_gather`. This assumes that this variable and the\n",
            " |      sparse_delta IndexedSlices have a series of leading dimensions that are the\n",
            " |      same for all of them, and the updates are performed on the last dimension of\n",
            " |      indices. In other words, the dimensions should be the following:\n",
            " |      \n",
            " |      `num_prefix_dims = sparse_delta.indices.ndims - 1`\n",
            " |      `batch_dim = num_prefix_dims + 1`\n",
            " |      `sparse_delta.updates.shape = sparse_delta.indices.shape + var.shape[\n",
            " |           batch_dim:]`\n",
            " |      \n",
            " |      where\n",
            " |      \n",
            " |      `sparse_delta.updates.shape[:num_prefix_dims]`\n",
            " |      `== sparse_delta.indices.shape[:num_prefix_dims]`\n",
            " |      `== var.shape[:num_prefix_dims]`\n",
            " |      \n",
            " |      And the operation performed can be expressed as:\n",
            " |      \n",
            " |      `var[i_1, ..., i_n,\n",
            " |           sparse_delta.indices[i_1, ..., i_n, j]] = sparse_delta.updates[\n",
            " |              i_1, ..., i_n, j]`\n",
            " |      \n",
            " |      When sparse_delta.indices is a 1D tensor, this operation is equivalent to\n",
            " |      `scatter_update`.\n",
            " |      \n",
            " |      To avoid this operation one can looping over the first `ndims` of the\n",
            " |      variable and using `scatter_update` on the subtensors that result of slicing\n",
            " |      the first dimension. This is a valid option for `ndims = 1`, but less\n",
            " |      efficient than this implementation.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  count_up_to(self, limit)\n",
            " |      Increments this variable until it reaches `limit`. (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Prefer Dataset.range instead.\n",
            " |      \n",
            " |      When that Op is run it tries to increment the variable by `1`. If\n",
            " |      incrementing the variable would bring it above `limit` then the Op raises\n",
            " |      the exception `OutOfRangeError`.\n",
            " |      \n",
            " |      If no error is raised, the Op outputs the value of the variable before\n",
            " |      the increment.\n",
            " |      \n",
            " |      This is essentially a shortcut for `count_up_to(self, limit)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        limit: value at which incrementing the variable raises an error.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` that will hold the variable value before the increment. If no\n",
            " |        other Op modifies this variable, the values produced will all be\n",
            " |        distinct.\n",
            " |  \n",
            " |  eval(self, session=None)\n",
            " |      In a session, computes and returns the value of this variable.\n",
            " |      \n",
            " |      This is not a graph construction method, it does not add ops to the graph.\n",
            " |      \n",
            " |      This convenience method requires a session where the graph\n",
            " |      containing this variable has been launched. If no session is\n",
            " |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
            " |      information on launching a graph and on sessions.\n",
            " |      \n",
            " |      ```python\n",
            " |      v = tf.Variable([1, 2])\n",
            " |      init = tf.compat.v1.global_variables_initializer()\n",
            " |      \n",
            " |      with tf.compat.v1.Session() as sess:\n",
            " |          sess.run(init)\n",
            " |          # Usage passing the session explicitly.\n",
            " |          print(v.eval(sess))\n",
            " |          # Usage with the default session.  The 'with' block\n",
            " |          # above makes 'sess' the default session.\n",
            " |          print(v.eval())\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        session: The session to use to evaluate this variable. If none, the\n",
            " |          default session is used.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A numpy `ndarray` with a copy of the value of this variable.\n",
            " |  \n",
            " |  experimental_ref(self)\n",
            " |      DEPRECATED FUNCTION\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Use ref() instead.\n",
            " |  \n",
            " |  gather_nd(self, indices, name=None)\n",
            " |      Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
            " |      \n",
            " |      See tf.gather_nd for details.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
            " |          Index tensor.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `params`.\n",
            " |  \n",
            " |  get_shape(self)\n",
            " |      Alias of `Variable.shape`.\n",
            " |  \n",
            " |  initialized_value(self)\n",
            " |      Returns the value of the initialized variable. (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            " |      \n",
            " |      You should use this instead of the variable itself to initialize another\n",
            " |      variable with a value that depends on the value of this variable.\n",
            " |      \n",
            " |      ```python\n",
            " |      # Initialize 'v' with a random tensor.\n",
            " |      v = tf.Variable(tf.random.truncated_normal([10, 40]))\n",
            " |      # Use `initialized_value` to guarantee that `v` has been\n",
            " |      # initialized before its value is used to initialize `w`.\n",
            " |      # The random values are picked only once.\n",
            " |      w = tf.Variable(v.initialized_value() * 2.0)\n",
            " |      ```\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` holding the value of this variable after its initializer\n",
            " |        has run.\n",
            " |  \n",
            " |  load(self, value, session=None)\n",
            " |      Load new value into this variable. (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            " |      \n",
            " |      Writes new value to variable's memory. Doesn't add ops to the graph.\n",
            " |      \n",
            " |      This convenience method requires a session where the graph\n",
            " |      containing this variable has been launched. If no session is\n",
            " |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
            " |      information on launching a graph and on sessions.\n",
            " |      \n",
            " |      ```python\n",
            " |      v = tf.Variable([1, 2])\n",
            " |      init = tf.compat.v1.global_variables_initializer()\n",
            " |      \n",
            " |      with tf.compat.v1.Session() as sess:\n",
            " |          sess.run(init)\n",
            " |          # Usage passing the session explicitly.\n",
            " |          v.load([2, 3], sess)\n",
            " |          print(v.eval(sess)) # prints [2 3]\n",
            " |          # Usage with the default session.  The 'with' block\n",
            " |          # above makes 'sess' the default session.\n",
            " |          v.load([3, 4], sess)\n",
            " |          print(v.eval()) # prints [3 4]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          value: New variable value\n",
            " |          session: The session to use to evaluate this variable. If none, the\n",
            " |            default session is used.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: Session is not passed and no default session\n",
            " |  \n",
            " |  read_value(self)\n",
            " |      Returns the value of this variable, read in the current context.\n",
            " |      \n",
            " |      Can be different from value() if it's on another device, with control\n",
            " |      dependencies, etc.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` containing the value of the variable.\n",
            " |  \n",
            " |  ref(self)\n",
            " |      Returns a hashable reference object to this Variable.\n",
            " |      \n",
            " |      The primary use case for this API is to put variables in a set/dictionary.\n",
            " |      We can't put variables in a set/dictionary as `variable.__hash__()` is no\n",
            " |      longer available starting Tensorflow 2.0.\n",
            " |      \n",
            " |      The following will raise an exception starting 2.0\n",
            " |      \n",
            " |      >>> x = tf.Variable(5)\n",
            " |      >>> y = tf.Variable(10)\n",
            " |      >>> z = tf.Variable(10)\n",
            " |      >>> variable_set = {x, y, z}\n",
            " |      Traceback (most recent call last):\n",
            " |        ...\n",
            " |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
            " |      >>> variable_dict = {x: 'five', y: 'ten'}\n",
            " |      Traceback (most recent call last):\n",
            " |        ...\n",
            " |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
            " |      \n",
            " |      Instead, we can use `variable.ref()`.\n",
            " |      \n",
            " |      >>> variable_set = {x.ref(), y.ref(), z.ref()}\n",
            " |      >>> x.ref() in variable_set\n",
            " |      True\n",
            " |      >>> variable_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
            " |      >>> variable_dict[y.ref()]\n",
            " |      'ten'\n",
            " |      \n",
            " |      Also, the reference object provides `.deref()` function that returns the\n",
            " |      original Variable.\n",
            " |      \n",
            " |      >>> x = tf.Variable(5)\n",
            " |      >>> x.ref().deref()\n",
            " |      <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n",
            " |  \n",
            " |  scatter_add(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Adds `tf.IndexedSlices` to this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be added to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_div(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Divide this variable by `tf.IndexedSlices`.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to divide this variable by.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_max(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Updates this variable with the max of `tf.IndexedSlices` and itself.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to use as an argument of max with this\n",
            " |          variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_min(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Updates this variable with the min of `tf.IndexedSlices` and itself.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to use as an argument of min with this\n",
            " |          variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_mul(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Multiply this variable by `tf.IndexedSlices`.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to multiply this variable by.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_nd_add(self, indices, updates, name=None)\n",
            " |      Applies sparse addition to individual values or slices in a Variable.\n",
            " |      \n",
            " |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
            " |      \n",
            " |      `indices` must be integer tensor, containing indices into self.\n",
            " |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
            " |      \n",
            " |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
            " |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
            " |      dimension of self.\n",
            " |      \n",
            " |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
            " |      \n",
            " |      ```\n",
            " |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
            " |      ```\n",
            " |      \n",
            " |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
            " |      8 elements. In Python, that update would look like this:\n",
            " |      \n",
            " |      ```python\n",
            " |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
            " |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
            " |          updates = tf.constant([9, 10, 11, 12])\n",
            " |          v.scatter_nd_add(indices, updates)\n",
            " |          print(v)\n",
            " |      ```\n",
            " |      \n",
            " |      The resulting update to v would look like this:\n",
            " |      \n",
            " |          [1, 13, 3, 14, 14, 6, 7, 20]\n",
            " |      \n",
            " |      See `tf.scatter_nd` for more details about how to make updates to\n",
            " |      slices.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The indices to be used in the operation.\n",
            " |        updates: The values to be used in the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |  \n",
            " |  scatter_nd_sub(self, indices, updates, name=None)\n",
            " |      Applies sparse subtraction to individual values or slices in a Variable.\n",
            " |      \n",
            " |      Assuming the variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
            " |      \n",
            " |      `indices` must be integer tensor, containing indices into self.\n",
            " |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
            " |      \n",
            " |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
            " |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
            " |      dimension of self.\n",
            " |      \n",
            " |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
            " |      \n",
            " |      ```\n",
            " |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
            " |      ```\n",
            " |      \n",
            " |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
            " |      8 elements. In Python, that update would look like this:\n",
            " |      \n",
            " |      ```python\n",
            " |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
            " |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
            " |          updates = tf.constant([9, 10, 11, 12])\n",
            " |          v.scatter_nd_sub(indices, updates)\n",
            " |          print(v)\n",
            " |      ```\n",
            " |      \n",
            " |      After the update `v` would look like this:\n",
            " |      \n",
            " |          [1, -9, 3, -6, -4, 6, 7, -4]\n",
            " |      \n",
            " |      See `tf.scatter_nd` for more details about how to make updates to\n",
            " |      slices.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The indices to be used in the operation.\n",
            " |        updates: The values to be used in the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |  \n",
            " |  scatter_nd_update(self, indices, updates, name=None)\n",
            " |      Applies sparse assignment to individual values or slices in a Variable.\n",
            " |      \n",
            " |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
            " |      \n",
            " |      `indices` must be integer tensor, containing indices into self.\n",
            " |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
            " |      \n",
            " |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
            " |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
            " |      dimension of self.\n",
            " |      \n",
            " |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
            " |      \n",
            " |      ```\n",
            " |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
            " |      ```\n",
            " |      \n",
            " |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
            " |      8 elements. In Python, that update would look like this:\n",
            " |      \n",
            " |      ```python\n",
            " |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
            " |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
            " |          updates = tf.constant([9, 10, 11, 12])\n",
            " |          v.scatter_nd_update(indices, updates)\n",
            " |          print(v)\n",
            " |      ```\n",
            " |      \n",
            " |      The resulting update to v would look like this:\n",
            " |      \n",
            " |          [1, 11, 3, 10, 9, 6, 7, 12]\n",
            " |      \n",
            " |      See `tf.scatter_nd` for more details about how to make updates to\n",
            " |      slices.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The indices to be used in the operation.\n",
            " |        updates: The values to be used in the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |  \n",
            " |  scatter_sub(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Subtracts `tf.IndexedSlices` from this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be subtracted from this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Assigns `tf.IndexedSlices` to this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  set_shape(self, shape)\n",
            " |      Overrides the shape for this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        shape: the `TensorShape` representing the overridden shape.\n",
            " |  \n",
            " |  sparse_read(self, indices, name=None)\n",
            " |      Gather slices from params axis axis according to indices.\n",
            " |      \n",
            " |      This function supports a subset of tf.gather, see tf.gather for details on\n",
            " |      usage.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
            " |          `int64`. Must be in range `[0, params.shape[axis])`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `params`.\n",
            " |  \n",
            " |  to_proto(self, export_scope=None)\n",
            " |      Converts a `Variable` to a `VariableDef` protocol buffer.\n",
            " |      \n",
            " |      Args:\n",
            " |        export_scope: Optional `string`. Name scope to remove.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `VariableDef` protocol buffer, or `None` if the `Variable` is not\n",
            " |        in the specified name scope.\n",
            " |  \n",
            " |  value(self)\n",
            " |      Returns the last snapshot of this variable.\n",
            " |      \n",
            " |      You usually do not need to call this method as all ops that need the value\n",
            " |      of the variable call it automatically through a `convert_to_tensor()` call.\n",
            " |      \n",
            " |      Returns a `Tensor` which holds the value of the variable.  You can not\n",
            " |      assign a new value to this tensor as it is not a reference to the variable.\n",
            " |      \n",
            " |      To avoid copies, if the consumer of the returned value is on the same device\n",
            " |      as the variable, this actually returns the live value of the variable, not\n",
            " |      a copy.  Updates to the variable are seen by the consumer.  If the consumer\n",
            " |      is on a different device it will get a copy of the variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` containing the value of the variable.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  from_proto(variable_def, import_scope=None)\n",
            " |      Returns a `Variable` object created from `variable_def`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  aggregation\n",
            " |  \n",
            " |  constraint\n",
            " |      Returns the constraint function associated with this variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The constraint function that was passed to the variable constructor.\n",
            " |        Can be `None` if no constraint was passed.\n",
            " |  \n",
            " |  device\n",
            " |      The device of this variable.\n",
            " |  \n",
            " |  dtype\n",
            " |      The `DType` of this variable.\n",
            " |  \n",
            " |  graph\n",
            " |      The `Graph` of this variable.\n",
            " |  \n",
            " |  initial_value\n",
            " |      Returns the Tensor used as the initial value for the variable.\n",
            " |      \n",
            " |      Note that this is different from `initialized_value()` which runs\n",
            " |      the op that initializes the variable before returning its value.\n",
            " |      This method returns the tensor that is used by the op that initializes\n",
            " |      the variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`.\n",
            " |  \n",
            " |  initializer\n",
            " |      The initializer operation for this variable.\n",
            " |  \n",
            " |  name\n",
            " |      The name of this variable.\n",
            " |  \n",
            " |  op\n",
            " |      The `Operation` of this variable.\n",
            " |  \n",
            " |  shape\n",
            " |      The `TensorShape` of this variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `TensorShape`.\n",
            " |  \n",
            " |  synchronization\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  SaveSliceInfo = <class 'tensorflow.python.ops.variables.Variable.SaveS...\n",
            " |      Information on how to save this Variable as a slice.\n",
            " |      \n",
            " |      Provides internal support for saving variables as slices of a larger\n",
            " |      variable.  This API is not public and is subject to change.\n",
            " |      \n",
            " |      Available properties:\n",
            " |      \n",
            " |      * full_name\n",
            " |      * full_shape\n",
            " |      * var_offset\n",
            " |      * var_shape\n",
            " |  \n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __array_priority__ = 100\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.Variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bv1SBbDe4TxN",
        "outputId": "2af43a4e-9d28-4788-f5f9-ab33c95a6551"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Variable 'changeable_tensor:0' shape=(2,) dtype=int32, numpy=array([10,  7], dtype=int32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7], dtype=int32)>)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the same tensor with tf.Variable() and tf.constant()\n",
        "changeable_tensor = tf.Variable(initial_value=[10, 7], \n",
        "                                trainable=None, \n",
        "                                validate_shape=True, \n",
        "                                caching_device=None, \n",
        "                                name='changeable_tensor', \n",
        "                                variable_def=None, \n",
        "                                dtype=None, \n",
        "                                import_scope=None, \n",
        "                                constraint=None, \n",
        "                                synchronization=tf.VariableSynchronization.AUTO, \n",
        "                                aggregation=tf.VariableAggregation.NONE)\n",
        "\n",
        "unchangeable_tensor = tf.constant(value=[10, 7], \n",
        "                                  dtype=None, \n",
        "                                  shape=None, \n",
        "                                  name='unchangeable_tensor')\n",
        "\n",
        "changeable_tensor, unchangeable_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4WrQ8c2ux15"
      },
      "source": [
        "Now let's try to change one of the elements of the changeable tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "dfDwbF6i5Sy3",
        "outputId": "087b7aa3-d371-4741-d798-9aef73895635"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cannot modify a tf.Variable without using the .assign() method\n"
          ]
        }
      ],
      "source": [
        "# Will error (requires the .assign() method)\n",
        "try:\n",
        "    changeable_tensor[0] = 7\n",
        "except TypeError as e:\n",
        "    print(\"Cannot modify a tf.Variable without using the .assign() method\")\n",
        "finally:\n",
        "    changeable_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWP-kZEVvGm8"
      },
      "source": [
        "To change an element of a `tf.Variable()` tensor requires the `assign()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on method assign in module tensorflow.python.ops.resource_variable_ops:\n",
            "\n",
            "assign(value, use_locking=None, name=None, read_value=True) method of tensorflow.python.ops.resource_variable_ops.ResourceVariable instance\n",
            "    Assigns a new value to this variable.\n",
            "    \n",
            "    Args:\n",
            "      value: A `Tensor`. The new value for this variable.\n",
            "      use_locking: If `True`, use locking during the assignment.\n",
            "      name: The name to use for the assignment.\n",
            "      read_value: A `bool`. Whether to read and return the new value of the\n",
            "        variable or not.\n",
            "    \n",
            "    Returns:\n",
            "      If `read_value` is `True`, this method will return the new value of the\n",
            "      variable after the assignment has completed. Otherwise, when in graph mode\n",
            "      it will return the `Operation` that does the assignment, and when in eager\n",
            "      mode it will return `None`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(changeable_tensor.assign)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJV3iwvG4jg4",
        "outputId": "d110b678-03ff-49e8-dee6-9974ab75ba24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'changeable_tensor:0' shape=(2,) dtype=int32, numpy=array([7, 7], dtype=int32)>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Won't error\n",
        "changeable_tensor[0].assign(7, \n",
        "                            # use_locking=False, \n",
        "                            # read_value=True,\n",
        "                            name=None)\n",
        "                            \n",
        "changeable_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UiV1Z0XvZ_B"
      },
      "source": [
        "Now let's try to change a value in a `tf.constant()` tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "5j_rOo8X5N9f",
        "outputId": "095cb0dc-dda0-41bc-e8dc-995934535957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cannot modify a tf.constant()!\n"
          ]
        }
      ],
      "source": [
        "# Will error (can't change tf.constant())\n",
        "try:\n",
        "    unchangeable_tensor[0].assign(7, \n",
        "                              # use_locking=False,\n",
        "                              # read_value=True,\n",
        "                              name=None)\n",
        "except AttributeError as e:\n",
        "    print(\"Cannot modify a tf.constant()!\")\n",
        "finally:\n",
        "    unchangeable_tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t21IcYpverQ"
      },
      "source": [
        "Which one should you use? `tf.constant()` or `tf.Variable()`?\n",
        "\n",
        "It will depend on what your problem requires. However, most of the time, TensorFlow will automatically choose for you (when loading data or modelling data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAAT59Ay0J0l"
      },
      "source": [
        "### Creating random tensors\n",
        "\n",
        "Random tensors are tensors of some arbitrary size which contain random numbers.\n",
        "\n",
        "Why would you want to create random tensors? \n",
        "\n",
        "This is what neural networks use to intialize their weights (patterns) that they're trying to learn in the data.\n",
        "\n",
        "For example, the process of a neural network learning often involves taking a random n-dimensional array of numbers and refining them until they represent some kind of pattern (a compressed way to represent the original data).\n",
        "\n",
        "**How a network learns**\n",
        "![how a network learns](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-how-a-network-learns.png)\n",
        "*A network learns by starting with random patterns (1) then going through demonstrative examples of data (2) whilst trying to update its random patterns to represent the examples (3).*\n",
        "\n",
        "We can create random tensors by using the [`tf.random.Generator`](https://www.tensorflow.org/guide/random_numbers#the_tfrandomgenerator_class) class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on method from_seed in module tensorflow.python.ops.stateful_random_ops:\n",
            "\n",
            "from_seed(seed, alg=None) method of builtins.type instance\n",
            "    Creates a generator from a seed.\n",
            "    \n",
            "    A seed is a 1024-bit unsigned integer represented either as a Python\n",
            "    integer or a vector of integers. Seeds shorter than 1024-bit will be\n",
            "    padded. The padding, the internal structure of a seed and the way a seed\n",
            "    is converted to a state are all opaque (unspecified). The only semantics\n",
            "    specification of seeds is that two different seeds are likely to produce\n",
            "    two independent generators (but no guarantee).\n",
            "    \n",
            "    Args:\n",
            "      seed: the seed for the RNG.\n",
            "      alg: (optional) the RNG algorithm. If None, it will be auto-selected. See\n",
            "        `__init__` for its possible values.\n",
            "    \n",
            "    Returns:\n",
            "      The new generator.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.random.Generator.from_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create two random (but the same) tensors\n",
        "# Set the seed for reproducibility\n",
        "random_generator_1 = tf.random.Generator.from_seed(seed=42, alg=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensorflow.python.ops.stateful_random_ops.Generator"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(random_generator_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "algorithm\n",
            "binomial\n",
            "from_key_counter\n",
            "from_non_deterministic_state\n",
            "from_seed\n",
            "from_state\n",
            "key\n",
            "make_seeds\n",
            "normal\n",
            "reset\n",
            "reset_from_key_counter\n",
            "reset_from_seed\n",
            "skip\n",
            "split\n",
            "state\n",
            "truncated_normal\n",
            "uniform\n",
            "uniform_full_int\n"
          ]
        }
      ],
      "source": [
        "# Check the methods available for `random_generator_1`\n",
        "for e in dir(random_generator_1):\n",
        "    if not e.startswith(\"_\"):\n",
        "        print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on method normal in module tensorflow.python.ops.stateful_random_ops:\n",
            "\n",
            "normal(shape, mean=0.0, stddev=1.0, dtype=tf.float32, name=None) method of tensorflow.python.ops.stateful_random_ops.Generator instance\n",
            "    Outputs random values from a normal distribution.\n",
            "    \n",
            "    Args:\n",
            "      shape: A 1-D integer Tensor or Python array. The shape of the output\n",
            "        tensor.\n",
            "      mean: A 0-D Tensor or Python value of type `dtype`. The mean of the normal\n",
            "        distribution.\n",
            "      stddev: A 0-D Tensor or Python value of type `dtype`. The standard\n",
            "        deviation of the normal distribution.\n",
            "      dtype: The type of the output.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A tensor of the specified shape filled with random normal values.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(random_generator_1.normal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZ7Zu5Z178JL",
        "outputId": "79b4497d-0404-4171-f42f-050c854b9019"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
              " array([[ True,  True],\n",
              "        [ True,  True],\n",
              "        [ True,  True]])>)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor of size 3 x 2 from a normal distribution\n",
        "random_1 = random_generator_1.normal(shape=(3, 2), \n",
        "                                     mean=0.0, \n",
        "                                     stddev=1.0, \n",
        "                                     dtype=tf.float32, \n",
        "                                     name='random_1')  \n",
        "\n",
        "random_generator_2 = tf.random.Generator.from_seed(seed=42, alg=None)\n",
        "random_2 = random_generator_2.normal(shape=(3, 2), \n",
        "                                     mean=0.0, \n",
        "                                     stddev=1.0, \n",
        "                                     dtype=tf.float32, \n",
        "                                     name='random_2')\n",
        "\n",
        "# Are they equal?\n",
        "random_1, random_2, random_1 == random_2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6Od5fpZ-S--"
      },
      "source": [
        "The random tensors we've made are actually [pseudorandom numbers](https://www.computerhope.com/jargon/p/pseudo-random.htm) (they appear as random, but really aren't).\n",
        "\n",
        "If we set a seed we'll get the same random numbers (if you've ever used NumPy, this is similar to `np.random.seed(42)`). \n",
        "\n",
        "Setting the seed says, \"hey, create some random numbers, but flavour them with X\" (X is the seed).\n",
        "\n",
        "What do you think will happen when we change the seed?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9eStLqr1F4ZP",
        "outputId": "cf545015-ce96-46dd-9d43-fbb148a04782"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[-0.7565803 , -0.06854702],\n",
              "        [ 0.07595026, -1.2573844 ],\n",
              "        [-0.23193765, -1.8107855 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              " array([[ 0.2730574 , -0.29925638],\n",
              "        [-0.3652325 ,  0.61883307],\n",
              "        [-1.0130816 ,  0.2829171 ]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
              " array([[ True,  True],\n",
              "        [ True,  True],\n",
              "        [ True,  True]])>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=bool, numpy=\n",
              " array([[False, False],\n",
              "        [False, False],\n",
              "        [False, False]])>)"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create two random (and different) tensors\n",
        "random_generator_3 = tf.random.Generator.from_seed(seed=42, alg=None)\n",
        "random_3 = random_generator_3.normal(shape=(3, 2), \n",
        "                                     mean=0.0, \n",
        "                                     stddev=1.0, \n",
        "                                     dtype=tf.float32, \n",
        "                                     name='random_3')\n",
        "\n",
        "random_generator_4 = tf.random.Generator.from_seed(seed=11, alg=None)\n",
        "random_4 = random_generator_4.normal(shape=(3, 2), \n",
        "                                     mean=0.0, \n",
        "                                     stddev=1.0, \n",
        "                                     dtype=tf.float32, \n",
        "                                     name='random_4')\n",
        "\n",
        "# Check the tensors and see if they are equal\n",
        "random_3, random_4, random_1 == random_3, random_3 == random_4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nji9AdFRIhBi"
      },
      "source": [
        "What if you wanted to shuffle the order of a tensor?\n",
        "\n",
        "Wait, why would you want to do that?\n",
        "\n",
        "Let's say you working with 15,000 images of cats and dogs and the first 10,000 images were of cats and the next 5,000 were of dogs. This order could effect how a neural network learns (it may overfit by learning the order of the data), instead, it might be a good idea to move your data around."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function random_shuffle in module tensorflow.python.ops.random_ops:\n",
            "\n",
            "random_shuffle(value, seed=None, name=None)\n",
            "    Randomly shuffles a tensor along its first dimension.\n",
            "    \n",
            "    The tensor is shuffled along dimension 0, such that each `value[j]` is mapped\n",
            "    to one and only one `output[i]`. For example, a mapping that might occur for a\n",
            "    3x2 tensor is:\n",
            "    \n",
            "    ```python\n",
            "    [[1, 2],       [[5, 6],\n",
            "     [3, 4],  ==>   [1, 2],\n",
            "     [5, 6]]        [3, 4]]\n",
            "    ```\n",
            "    \n",
            "    Args:\n",
            "      value: A Tensor to be shuffled.\n",
            "      seed: A Python integer. Used to create a random seed for the distribution.\n",
            "        See\n",
            "        `tf.random.set_seed`\n",
            "        for behavior.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A tensor of same shape and type as `value`, shuffled along its first\n",
            "      dimension.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.random.shuffle)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sl4HYEWMBI6x",
        "outputId": "195d45c3-9c2e-4e7d-ea71-f3382b4dc6b0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 2,  5],\n",
              "       [ 3,  4]], dtype=int32)>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shuffle a tensor (valuable for when you want to shuffle your data)\n",
        "not_shuffled = tf.constant(value=[[10, 7],\n",
        "                            [3, 4],\n",
        "                            [2, 5]], \n",
        "                            dtype=None, \n",
        "                            shape=None, \n",
        "                            name='not_shuffled')\n",
        "\n",
        "# Gets different results each time\n",
        "tf.random.shuffle(value=not_shuffled, \n",
        "                  seed=None, \n",
        "                  name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HYn0ME_H1SY",
        "outputId": "1a5c9383-9ca8-47c2-90a8-d2002dbf4ef8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 2,  5],\n",
              "       [ 3,  4],\n",
              "       [10,  7]], dtype=int32)>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shuffle in the same order every time using the seed parameter (won't acutally be the same)\n",
        "tf.random.shuffle(value=not_shuffled, \n",
        "                  seed=42,\n",
        "                  name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmC3qGIHjAx6"
      },
      "source": [
        "Wait... why didn't the numbers come out the same?\n",
        "\n",
        "It's due to rule #4 of the [`tf.random.set_seed()`](https://www.tensorflow.org/api_docs/python/tf/random/set_seed) documentation.\n",
        "\n",
        "> \"4. If both the global and the operation seed are set: Both seeds are used in conjunction to determine the random sequence.\"\n",
        "\n",
        "`tf.random.set_seed(42)` sets the global seed, and the `seed` parameter in `tf.random.shuffle(seed=42)` sets the operation seed.\n",
        "\n",
        "Because, \"Operations that rely on a random seed actually derive it from two seeds: the global and operation-level seeds. This sets the global seed.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM6S8set-ixV",
        "outputId": "3ab2f553-5818-46eb-d276-a14853693bdc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[10,  7],\n",
              "       [ 3,  4],\n",
              "       [ 2,  5]], dtype=int32)>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Shuffle in the same order every time\n",
        "\n",
        "# Set the global random seed\n",
        "tf.random.set_seed(seed=42)\n",
        "\n",
        "# Set the operation random seed\n",
        "tf.random.shuffle(value=not_shuffled, \n",
        "                  seed=42,\n",
        "                  name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function set_seed in module tensorflow.python.framework.random_seed:\n",
            "\n",
            "set_seed(seed)\n",
            "    Sets the global random seed.\n",
            "    \n",
            "    Operations that rely on a random seed actually derive it from two seeds:\n",
            "    the global and operation-level seeds. This sets the global seed.\n",
            "    \n",
            "    Its interactions with operation-level seeds is as follows:\n",
            "    \n",
            "      1. If neither the global seed nor the operation seed is set: A randomly\n",
            "        picked seed is used for this op.\n",
            "      2. If the global seed is set, but the operation seed is not:\n",
            "        The system deterministically picks an operation seed in conjunction with\n",
            "        the global seed so that it gets a unique random sequence. Within the\n",
            "        same version of tensorflow and user code, this sequence is deterministic.\n",
            "        However across different versions, this sequence might change. If the\n",
            "        code depends on particular seeds to work, specify both global\n",
            "        and operation-level seeds explicitly.\n",
            "      3. If the operation seed is set, but the global seed is not set:\n",
            "        A default global seed and the specified operation seed are used to\n",
            "        determine the random sequence.\n",
            "      4. If both the global and the operation seed are set:\n",
            "        Both seeds are used in conjunction to determine the random sequence.\n",
            "    \n",
            "    To illustrate the user-visible effects, consider these examples:\n",
            "    \n",
            "    If neither the global seed nor the operation seed is set, we get different\n",
            "    results for every call to the random op and every re-run of the program:\n",
            "    \n",
            "    ```python\n",
            "    print(tf.random.uniform([1]))  # generates 'A1'\n",
            "    print(tf.random.uniform([1]))  # generates 'A2'\n",
            "    ```\n",
            "    \n",
            "    (now close the program and run it again)\n",
            "    \n",
            "    ```python\n",
            "    print(tf.random.uniform([1]))  # generates 'A3'\n",
            "    print(tf.random.uniform([1]))  # generates 'A4'\n",
            "    ```\n",
            "    \n",
            "    If the global seed is set but the operation seed is not set, we get different\n",
            "    results for every call to the random op, but the same sequence for every\n",
            "    re-run of the program:\n",
            "    \n",
            "    ```python\n",
            "    tf.random.set_seed(1234)\n",
            "    print(tf.random.uniform([1]))  # generates 'A1'\n",
            "    print(tf.random.uniform([1]))  # generates 'A2'\n",
            "    ```\n",
            "    \n",
            "    (now close the program and run it again)\n",
            "    \n",
            "    ```python\n",
            "    tf.random.set_seed(1234)\n",
            "    print(tf.random.uniform([1]))  # generates 'A1'\n",
            "    print(tf.random.uniform([1]))  # generates 'A2'\n",
            "    ```\n",
            "    \n",
            "    The reason we get 'A2' instead 'A1' on the second call of `tf.random.uniform`\n",
            "    above is because the second call uses a different operation seed.\n",
            "    \n",
            "    Note that `tf.function` acts like a re-run of a program in this case. When\n",
            "    the global seed is set but operation seeds are not set, the sequence of random\n",
            "    numbers are the same for each `tf.function`. For example:\n",
            "    \n",
            "    ```python\n",
            "    tf.random.set_seed(1234)\n",
            "    \n",
            "    @tf.function\n",
            "    def f():\n",
            "      a = tf.random.uniform([1])\n",
            "      b = tf.random.uniform([1])\n",
            "      return a, b\n",
            "    \n",
            "    @tf.function\n",
            "    def g():\n",
            "      a = tf.random.uniform([1])\n",
            "      b = tf.random.uniform([1])\n",
            "      return a, b\n",
            "    \n",
            "    print(f())  # prints '(A1, A2)'\n",
            "    print(g())  # prints '(A1, A2)'\n",
            "    ```\n",
            "    \n",
            "    If the operation seed is set, we get different results for every call to the\n",
            "    random op, but the same sequence for every re-run of the program:\n",
            "    \n",
            "    ```python\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A1'\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A2'\n",
            "    ```\n",
            "    \n",
            "    (now close the program and run it again)\n",
            "    \n",
            "    ```python\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A1'\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A2'\n",
            "    ```\n",
            "    \n",
            "    The reason we get 'A2' instead 'A1' on the second call of `tf.random.uniform`\n",
            "    above is because the same `tf.random.uniform` kernel (i.e. internal\n",
            "    representation) is used by TensorFlow for all calls of it with the same\n",
            "    arguments, and the kernel maintains an internal counter which is incremented\n",
            "    every time it is executed, generating different results.\n",
            "    \n",
            "    Calling `tf.random.set_seed` will reset any such counters:\n",
            "    \n",
            "    ```python\n",
            "    tf.random.set_seed(1234)\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A1'\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A2'\n",
            "    tf.random.set_seed(1234)\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A1'\n",
            "    print(tf.random.uniform([1], seed=1))  # generates 'A2'\n",
            "    ```\n",
            "    \n",
            "    When multiple identical random ops are wrapped in a `tf.function`, their\n",
            "    behaviors change because the ops no long share the same counter. For example:\n",
            "    \n",
            "    ```python\n",
            "    @tf.function\n",
            "    def foo():\n",
            "      a = tf.random.uniform([1], seed=1)\n",
            "      b = tf.random.uniform([1], seed=1)\n",
            "      return a, b\n",
            "    print(foo())  # prints '(A1, A1)'\n",
            "    print(foo())  # prints '(A2, A2)'\n",
            "    \n",
            "    @tf.function\n",
            "    def bar():\n",
            "      a = tf.random.uniform([1])\n",
            "      b = tf.random.uniform([1])\n",
            "      return a, b\n",
            "    print(bar())  # prints '(A1, A2)'\n",
            "    print(bar())  # prints '(A3, A4)'\n",
            "    ```\n",
            "    \n",
            "    The second call of `foo` returns '(A2, A2)' instead of '(A1, A1)' because\n",
            "    `tf.random.uniform` maintains an internal counter. If you want `foo` to return\n",
            "    '(A1, A1)' every time, use the stateless random ops such as\n",
            "    `tf.random.stateless_uniform`. Also see `tf.random.experimental.Generator` for\n",
            "    a new set of stateful random ops that use external variables to manage their\n",
            "    states.\n",
            "    \n",
            "    Args:\n",
            "      seed: integer.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.random.set_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKJOsdE8yCn4",
        "outputId": "9cd2788b-95a7-4f31-997c-313a2297541d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              "array([[ 3,  4],\n",
              "       [ 2,  5],\n",
              "       [10,  7]], dtype=int32)>"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Set the global random seed\n",
        "tf.random.set_seed(seed=42)\n",
        "\n",
        "# Set the operation random seed\n",
        "tf.random.shuffle(value=not_shuffled, \n",
        "                  name=None,\n",
        "                  seed=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouZ1fpJk0R3h"
      },
      "source": [
        "### Other ways to make tensors\n",
        "\n",
        "Though you might rarely use these (remember, many tensor operations are done behind the scenes for you), you can use [`tf.ones()`](https://www.tensorflow.org/api_docs/python/tf/ones) to create a tensor of all ones and [`tf.zeros()`](https://www.tensorflow.org/api_docs/python/tf/zeros) to create a tensor of all zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function ones in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "ones(shape, dtype=tf.float32, name=None)\n",
            "    Creates a tensor with all elements set to one (1).\n",
            "    \n",
            "    See also `tf.ones_like`, `tf.zeros`, `tf.fill`, `tf.eye`.\n",
            "    \n",
            "    This operation returns a tensor of type `dtype` with shape `shape` and\n",
            "    all elements set to one.\n",
            "    \n",
            "    >>> tf.ones([3, 4], tf.int32)\n",
            "    <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
            "    array([[1, 1, 1, 1],\n",
            "           [1, 1, 1, 1],\n",
            "           [1, 1, 1, 1]], dtype=int32)>\n",
            "    \n",
            "    Args:\n",
            "      shape: A `list` of integers, a `tuple` of integers, or\n",
            "        a 1-D `Tensor` of type `int32`.\n",
            "      dtype: Optional DType of an element in the resulting `Tensor`. Default is\n",
            "        `tf.float32`.\n",
            "      name: Optional string. A name for the operation.\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` with all elements set to one (1).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.ones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG8QNZP7kEe1",
        "outputId": "9ab2ec05-8b1d-45b0-a886-392e63d69149"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[1., 1.],\n",
              "       [1., 1.],\n",
              "       [1., 1.]], dtype=float32)>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make a tensor of all ones\n",
        "tf.ones(shape=(3, 2), \n",
        "        dtype=tf.float32, \n",
        "        name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function zeros in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "zeros(shape, dtype=tf.float32, name=None)\n",
            "    Creates a tensor with all elements set to zero.\n",
            "    \n",
            "    See also `tf.zeros_like`, `tf.ones`, `tf.fill`, `tf.eye`.\n",
            "    \n",
            "    This operation returns a tensor of type `dtype` with shape `shape` and\n",
            "    all elements set to zero.\n",
            "    \n",
            "    >>> tf.zeros([3, 4], tf.int32)\n",
            "    <tf.Tensor: shape=(3, 4), dtype=int32, numpy=\n",
            "    array([[0, 0, 0, 0],\n",
            "           [0, 0, 0, 0],\n",
            "           [0, 0, 0, 0]], dtype=int32)>\n",
            "    \n",
            "    Args:\n",
            "      shape: A `list` of integers, a `tuple` of integers, or\n",
            "        a 1-D `Tensor` of type `int32`.\n",
            "      dtype: The DType of an element in the resulting `Tensor`.\n",
            "      name: Optional string. A name for the operation.\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` with all elements set to zero.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.zeros)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQKiWrB9kprj",
        "outputId": "8cd8ccee-2546-4473-ca89-0789100fbc1c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
              "array([[0., 0.],\n",
              "       [0., 0.],\n",
              "       [0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Make a tensor of all zeros\n",
        "tf.zeros(shape=(3, 2), \n",
        "         dtype=tf.float32, \n",
        "         name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slcLTK5D7kc2"
      },
      "source": [
        "You can also turn NumPy arrays in into tensors.\n",
        "\n",
        "Remember, the main difference between tensors and NumPy arrays is that tensors can be run on GPUs.\n",
        "\n",
        "> ðŸ”‘ **Note:** A matrix or tensor is typically represented by a capital letter (e.g. `X` or `A`) where as a vector is typically represented by a lowercase letter (e.g. `y` or `b`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0XP37xi7mn4",
        "outputId": "f59af147-58d8-4239-bbc1-1f140a858118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "        18, 19, 20, 21, 22, 23, 24], dtype=int32),\n",
              " <tf.Tensor: shape=(2, 4, 3), dtype=int32, numpy=\n",
              " array([[[ 1,  2,  3],\n",
              "         [ 4,  5,  6],\n",
              "         [ 7,  8,  9],\n",
              "         [10, 11, 12]],\n",
              " \n",
              "        [[13, 14, 15],\n",
              "         [16, 17, 18],\n",
              "         [19, 20, 21],\n",
              "         [22, 23, 24]]], dtype=int32)>)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create a NumPy array between 1 and 25\n",
        "numpy_A = np.arange(start=1, \n",
        "                    stop=25, \n",
        "                    dtype=np.int32) \n",
        "\n",
        "# NOTE: The shape total (2*4*3) has to match the number of elements in the array\n",
        "A = tf.constant(value=numpy_A,  \n",
        "                shape=[2, 4, 3], \n",
        "                dtype=tf.int32, \n",
        "                name='A')\n",
        " \n",
        "numpy_A, A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on built-in function arange in module numpy:\n",
            "\n",
            "arange(...)\n",
            "    arange([start,] stop[, step,], dtype=None, *, like=None)\n",
            "    \n",
            "    Return evenly spaced values within a given interval.\n",
            "    \n",
            "    ``arange`` can be called with a varying number of positional arguments:\n",
            "    \n",
            "    * ``arange(stop)``: Values are generated within the half-open interval\n",
            "      ``[0, stop)`` (in other words, the interval including `start` but\n",
            "      excluding `stop`).\n",
            "    * ``arange(start, stop)``: Values are generated within the half-open\n",
            "      interval ``[start, stop)``.\n",
            "    * ``arange(start, stop, step)`` Values are generated within the half-open\n",
            "      interval ``[start, stop)``, with spacing between values given by\n",
            "      ``step``.\n",
            "    \n",
            "    For integer arguments the function is roughly equivalent to the Python\n",
            "    built-in :py:class:`range`, but returns an ndarray rather than a ``range``\n",
            "    instance.\n",
            "    \n",
            "    When using a non-integer step, such as 0.1, it is often better to use\n",
            "    `numpy.linspace`.\n",
            "    \n",
            "    See the Warning sections below for more information.\n",
            "    \n",
            "    Parameters\n",
            "    ----------\n",
            "    start : integer or real, optional\n",
            "        Start of interval.  The interval includes this value.  The default\n",
            "        start value is 0.\n",
            "    stop : integer or real\n",
            "        End of interval.  The interval does not include this value, except\n",
            "        in some cases where `step` is not an integer and floating point\n",
            "        round-off affects the length of `out`.\n",
            "    step : integer or real, optional\n",
            "        Spacing between values.  For any output `out`, this is the distance\n",
            "        between two adjacent values, ``out[i+1] - out[i]``.  The default\n",
            "        step size is 1.  If `step` is specified as a position argument,\n",
            "        `start` must also be given.\n",
            "    dtype : dtype, optional\n",
            "        The type of the output array.  If `dtype` is not given, infer the data\n",
            "        type from the other input arguments.\n",
            "    like : array_like, optional\n",
            "        Reference object to allow the creation of arrays which are not\n",
            "        NumPy arrays. If an array-like passed in as ``like`` supports\n",
            "        the ``__array_function__`` protocol, the result will be defined\n",
            "        by it. In this case, it ensures the creation of an array object\n",
            "        compatible with that passed in via this argument.\n",
            "    \n",
            "        .. versionadded:: 1.20.0\n",
            "    \n",
            "    Returns\n",
            "    -------\n",
            "    arange : ndarray\n",
            "        Array of evenly spaced values.\n",
            "    \n",
            "        For floating point arguments, the length of the result is\n",
            "        ``ceil((stop - start)/step)``.  Because of floating point overflow,\n",
            "        this rule may result in the last element of `out` being greater\n",
            "        than `stop`.\n",
            "    \n",
            "    Warnings\n",
            "    --------\n",
            "    The length of the output might not be numerically stable.\n",
            "    \n",
            "    Another stability issue is due to the internal implementation of\n",
            "    `numpy.arange`.\n",
            "    The actual step value used to populate the array is\n",
            "    ``dtype(start + step) - dtype(start)`` and not `step`. Precision loss\n",
            "    can occur here, due to casting or due to using floating points when\n",
            "    `start` is much larger than `step`. This can lead to unexpected\n",
            "    behaviour. For example::\n",
            "    \n",
            "      >>> np.arange(0, 5, 0.5, dtype=int)\n",
            "      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
            "      >>> np.arange(-3, 3, 0.5, dtype=int)\n",
            "      array([-3, -2, -1,  0,  1,  2,  3,  4,  5,  6,  7,  8])\n",
            "    \n",
            "    In such cases, the use of `numpy.linspace` should be preferred.\n",
            "    \n",
            "    The built-in :py:class:`range` generates :std:doc:`Python built-in integers\n",
            "    that have arbitrary size <c-api/long>`, while `numpy.arange` produces\n",
            "    `numpy.int32` or `numpy.int64` numbers. This may result in incorrect\n",
            "    results for large integer values::\n",
            "    \n",
            "      >>> power = 40\n",
            "      >>> modulo = 10000\n",
            "      >>> x1 = [(n ** power) % modulo for n in range(8)]\n",
            "      >>> x2 = [(n ** power) % modulo for n in np.arange(8)]\n",
            "      >>> print(x1)\n",
            "      [0, 1, 7776, 8801, 6176, 625, 6576, 4001]  # correct\n",
            "      >>> print(x2)\n",
            "      [0, 1, 7776, 7185, 0, 5969, 4816, 3361]  # incorrect\n",
            "    \n",
            "    See Also\n",
            "    --------\n",
            "    numpy.linspace : Evenly spaced numbers with careful handling of endpoints.\n",
            "    numpy.ogrid: Arrays of evenly spaced numbers in N-dimensions.\n",
            "    numpy.mgrid: Grid-shaped arrays of evenly spaced numbers in N-dimensions.\n",
            "    \n",
            "    Examples\n",
            "    --------\n",
            "    >>> np.arange(3)\n",
            "    array([0, 1, 2])\n",
            "    >>> np.arange(3.0)\n",
            "    array([ 0.,  1.,  2.])\n",
            "    >>> np.arange(3,7)\n",
            "    array([3, 4, 5, 6])\n",
            "    >>> np.arange(3,7,2)\n",
            "    array([3, 5])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(np.arange)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1JLXa2P0wpx"
      },
      "source": [
        "## Getting information from tensors (shape, rank, size)\n",
        "\n",
        "There will be times when you'll want to get different pieces of information from your tensors, in particular, you should know the following tensor vocabulary:\n",
        "* **Shape:** The length (number of elements) of each of the dimensions of a tensor.\n",
        "* **Rank:** The number of tensor dimensions. A scalar has rank 0, a vector has rank 1, a matrix is rank 2, a tensor has rank n.\n",
        "* **Axis** or **Dimension:** A particular dimension of a tensor.\n",
        "* **Size:** The total number of items in the tensor.\n",
        "\n",
        "You'll use these especially when you're trying to line up the shapes of your data to the shapes of your model. For example, making sure the shape of your image tensors are the same shape as your models input layer.\n",
        "\n",
        "We've already seen one of these before using the `ndim` attribute. Let's see the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhckrmovCaAA",
        "outputId": "ac4307f8-d850-4c45-eaff-7cfa8a3919e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a rank 4 tensor (4 dimensions)\n",
        "rank_4_tensor = tf.zeros(shape=[2, 3, 4, 5], \n",
        "                         dtype=tf.float32, \n",
        "                         name='rank_4_tensor')\n",
        "rank_4_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function size_v2 in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "size_v2(input, out_type=tf.int32, name=None)\n",
            "    Returns the size of a tensor.\n",
            "    \n",
            "    See also `tf.shape`.\n",
            "    \n",
            "    Returns a 0-D `Tensor` representing the number of elements in `input`\n",
            "    of type `out_type`. Defaults to tf.int32.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> t = tf.constant([[[1, 1, 1], [2, 2, 2]], [[3, 3, 3], [4, 4, 4]]])\n",
            "    >>> tf.size(t)\n",
            "    <tf.Tensor: shape=(), dtype=int32, numpy=12>\n",
            "    \n",
            "    Args:\n",
            "      input: A `Tensor` or `SparseTensor`.\n",
            "      name: A name for the operation (optional).\n",
            "      out_type: (Optional) The specified non-quantized numeric output type of the\n",
            "        operation. Defaults to `tf.int32`.\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` of type `out_type`. Defaults to `tf.int32`.\n",
            "    \n",
            "    @compatibility(numpy)\n",
            "    Equivalent to np.size()\n",
            "    @end_compatibility\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImJdhWnLtZ_2",
        "outputId": "92b9e814-51b1-4374-ae81-516dcc2e0c49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(input=rank_4_tensor, out_type=tf.int32, name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvb-4ZYdpI9f",
        "outputId": "0f1b35eb-b93f-422e-8979-17260c621ffb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datatype of every element: <dtype: 'float32'>\n",
            "Number of dimensions (rank): 4\n",
            "Shape of tensor: (2, 3, 4, 5)\n",
            "Elements along axis 0 of tensor: 2\n",
            "Elements along last axis of tensor: 5\n",
            "Total number of elements (2*3*4*5): 120\n"
          ]
        }
      ],
      "source": [
        "# Get various attributes of tensor\n",
        "print(\"Datatype of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elements along last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "# NOTE: .numpy() converts to NumPy array\n",
        "print(\"Total number of elements (2*3*4*5):\", tf.size(input=rank_4_tensor, out_type=tf.int32, name=None).numpy()) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0SMO2ZOqL0G"
      },
      "source": [
        "You can also index tensors just like Python lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFzOo-7QqLJf",
        "outputId": "2629d691-a8de-4488-915a-b06868f5218d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
              "array([[[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0.],\n",
              "         [0., 0.]],\n",
              "\n",
              "        [[0., 0.],\n",
              "         [0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the first 2 items of each dimension\n",
        "rank_4_tensor[:2, :2, :2, :2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weQe2bBUqknd",
        "outputId": "16c61a8c-2ba3-42a3-d4b8-d19185553300"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the dimension from each index except for the final one\n",
        "rank_4_tensor[:1, :1, :1, :]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQKcZWz5rFXG",
        "outputId": "15a0bee6-6467-46b7-c315-e5ec963de8bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([7., 4.], dtype=float32)>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a rank 2 tensor (2 dimensions)\n",
        "rank_2_tensor = tf.constant(value=[[10, 7],\n",
        "                             [3, 4]], \n",
        "                             dtype=tf.float32, \n",
        "                             shape=None,\n",
        "                             name='rank_2_tensor')\n",
        "\n",
        "# Get the last item of each row\n",
        "rank_2_tensor[:, -1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLZq3sHKrVdS"
      },
      "source": [
        "You can also add dimensions to your tensor whilst keeping the same information present using `tf.newaxis`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on NoneType object:\n",
            "\n",
            "class NoneType(object)\n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __bool__(self, /)\n",
            " |      True if self else False\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  __new__(*args, **kwargs) from builtins.type\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.newaxis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuEEEQa4w1id",
        "outputId": "998dcc25-889f-4c5b-e417-f9e45dcaa350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              " array([[10.,  7.],\n",
              "        [ 3.,  4.]], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2, 2, 1), dtype=float32, numpy=\n",
              " array([[[10.],\n",
              "         [ 7.]],\n",
              " \n",
              "        [[ 3.],\n",
              "         [ 4.]]], dtype=float32)>)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add an extra dimension (to the end)\n",
        "# NOTE: in Python \"...\" means \"all dimensions prior to\"\n",
        "rank_3_tensor = rank_2_tensor[..., tf.newaxis] \n",
        "# shape (2, 2), shape (2, 2, 1)\n",
        "rank_2_tensor, rank_3_tensor "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5_KyB-6r7z7"
      },
      "source": [
        "You can achieve the same using [`tf.expand_dims()`](https://www.tensorflow.org/api_docs/python/tf/expand_dims)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function expand_dims_v2 in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "expand_dims_v2(input, axis, name=None)\n",
            "    Returns a tensor with a length 1 axis inserted at index `axis`.\n",
            "    \n",
            "    Given a tensor `input`, this operation inserts a dimension of length 1 at the\n",
            "    dimension index `axis` of `input`'s shape. The dimension index follows Python\n",
            "    indexing rules: It's zero-based, a negative index it is counted backward\n",
            "    from the end.\n",
            "    \n",
            "    This operation is useful to:\n",
            "    \n",
            "    * Add an outer \"batch\" dimension to a single element.\n",
            "    * Align axes for broadcasting.\n",
            "    * To add an inner vector length axis to a tensor of scalars.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    If you have a single image of shape `[height, width, channels]`:\n",
            "    \n",
            "    >>> image = tf.zeros([10,10,3])\n",
            "    \n",
            "    You can add an outer `batch` axis by passing `axis=0`:\n",
            "    \n",
            "    >>> tf.expand_dims(image, axis=0).shape.as_list()\n",
            "    [1, 10, 10, 3]\n",
            "    \n",
            "    The new axis location matches Python `list.insert(axis, 1)`:\n",
            "    \n",
            "    >>> tf.expand_dims(image, axis=1).shape.as_list()\n",
            "    [10, 1, 10, 3]\n",
            "    \n",
            "    Following standard Python indexing rules, a negative `axis` counts from the\n",
            "    end so `axis=-1` adds an inner most dimension:\n",
            "    \n",
            "    >>> tf.expand_dims(image, -1).shape.as_list()\n",
            "    [10, 10, 3, 1]\n",
            "    \n",
            "    This operation requires that `axis` is a valid index for `input.shape`,\n",
            "    following Python indexing rules:\n",
            "    \n",
            "    ```\n",
            "    -1-tf.rank(input) <= axis <= tf.rank(input)\n",
            "    ```\n",
            "    \n",
            "    This operation is related to:\n",
            "    \n",
            "    * `tf.squeeze`, which removes dimensions of size 1.\n",
            "    * `tf.reshape`, which provides more flexible reshaping capability.\n",
            "    * `tf.sparse.expand_dims`, which provides this functionality for\n",
            "      `tf.SparseTensor`\n",
            "    \n",
            "    Args:\n",
            "      input: A `Tensor`.\n",
            "      axis: Integer specifying the dimension index at which to expand the\n",
            "        shape of `input`. Given an input of D dimensions, `axis` must be in range\n",
            "        `[-(D+1), D]` (inclusive).\n",
            "      name: Optional string. The name of the output `Tensor`.\n",
            "    \n",
            "    Returns:\n",
            "      A tensor with the same data as `input`, with an additional dimension\n",
            "      inserted at the index specified by `axis`.\n",
            "    \n",
            "    Raises:\n",
            "      TypeError: If `axis` is not specified.\n",
            "      InvalidArgumentError: If `axis` is out of range `[-(D+1), D]`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.expand_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpPTBqt4rvr9",
        "outputId": "47a95be1-ba16-475f-b2cd-437f115cd5ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2, 1), dtype=float32, numpy=\n",
              "array([[[10.],\n",
              "        [ 7.]],\n",
              "\n",
              "       [[ 3.],\n",
              "        [ 4.]]], dtype=float32)>"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NOTE: \"-1\" means last axis\n",
        "tf.expand_dims(input=rank_2_tensor, \n",
        "               axis=-1, \n",
        "               name=None) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4EHae9iA04Ok"
      },
      "source": [
        "## Manipulating tensors (tensor operations)\n",
        "\n",
        "Finding patterns in tensors (numerical representation of data) requires manipulating them.\n",
        "\n",
        "Again, when building models in TensorFlow, much of this pattern discovery is done for you."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NzdbYDqs1Ex"
      },
      "source": [
        "### Basic operations\n",
        "\n",
        "You can perform many of the basic mathematical operations directly on tensors using Python operators such as, `+`, `-`, `*`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tu3zJirLsMVw",
        "outputId": "7dce405b-292e-4d7a-efdd-eeda89807887"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[20., 17.],\n",
              "       [13., 14.]], dtype=float32)>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can add values to a tensor using the addition operator\n",
        "tensor = tf.constant(value=[[10, 7], [3, 4]], \n",
        "                     dtype=tf.float32, \n",
        "                     shape=None,\n",
        "                     name='tensor')\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_smxbIkYwYY3"
      },
      "source": [
        "Since we used `tf.constant()`, the original tensor is unchanged (the addition gets done on a copy)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BhJn3puhwOlM",
        "outputId": "92ce1cbe-e4c8-4f4e-c50b-c21d4ea57d43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[10.,  7.],\n",
              "       [ 3.,  4.]], dtype=float32)>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Original tensor unchanged\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N6tUM16xq9d"
      },
      "source": [
        "Other operators also work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6TW0_ZC_xoEC",
        "outputId": "f6aa4f99-a9e8-4e13-c06c-5c9450ef99c4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[100.,  70.],\n",
              "       [ 30.,  40.]], dtype=float32)>"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Multiplication (known as element-wise multiplication)\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN6XjwWfxu66",
        "outputId": "ca0a775c-e2e3-4a53-fbae-e4ced3f2c91c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[ 0., -3.],\n",
              "       [-7., -6.]], dtype=float32)>"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Subtraction\n",
        "tensor - 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kMJe4GlyuZR"
      },
      "source": [
        "You can also use the equivalent TensorFlow function. Using the TensorFlow function (where possible) has the advantage of being sped up later down the line when running as part of a [TensorFlow graph](https://www.tensorflow.org/tensorboard/graphs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function multiply in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "multiply(x, y, name=None)\n",
            "    Returns an element-wise x * y.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> x = tf.constant(([1, 2, 3, 4]))\n",
            "    >>> tf.math.multiply(x, x)\n",
            "    <tf.Tensor: shape=(4,), dtype=..., numpy=array([ 1,  4,  9, 16], dtype=int32)>\n",
            "    \n",
            "    Since `tf.math.multiply` will convert its arguments to `Tensor`s, you can also\n",
            "    pass in non-`Tensor` arguments:\n",
            "    \n",
            "    >>> tf.math.multiply(7,6)\n",
            "    <tf.Tensor: shape=(), dtype=int32, numpy=42>\n",
            "    \n",
            "    If `x.shape` is not the same as `y.shape`, they will be broadcast to a\n",
            "    compatible shape. (More about broadcasting\n",
            "    [here](https://docs.scipy.org/doc/numpy/user/basics.broadcasting.html).)\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> x = tf.ones([1, 2]);\n",
            "    >>> y = tf.ones([2, 1]);\n",
            "    >>> x * y  # Taking advantage of operator overriding\n",
            "    <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
            "    array([[1., 1.],\n",
            "         [1., 1.]], dtype=float32)>\n",
            "    \n",
            "    The reduction version of this elementwise operation is `tf.math.reduce_prod`\n",
            "    \n",
            "    Args:\n",
            "      x: A Tensor. Must be one of the following types: `bfloat16`,\n",
            "        `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`,\n",
            "        `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
            "      y: A `Tensor`. Must have the same type as `x`.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "    \n",
            "    A `Tensor`.  Has the same type as `x`.\n",
            "    \n",
            "    Raises:\n",
            "    \n",
            "     * InvalidArgumentError: When `x` and `y` have incompatible shapes or types.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.multiply)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2NDjqYIyyMc",
        "outputId": "b811b7c6-2c4a-4f89-fae6-89ceaf8dfa5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[100.,  70.],\n",
              "       [ 30.,  40.]], dtype=float32)>"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use the tensorflow function equivalent of the '*' (multiply) operator\n",
        "tf.multiply(x=tensor, \n",
        "            y=10, \n",
        "            name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKEuDBFD49w7",
        "outputId": "99300b75-0f81-432b-f3d0-b32e4c651b5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[10.,  7.],\n",
              "       [ 3.,  4.]], dtype=float32)>"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The original tensor is still unchanged\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M-0dhjtzHoZ"
      },
      "source": [
        "### Matrix mutliplication\n",
        "\n",
        "One of the most common operations in machine learning algorithms is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
        "\n",
        "TensorFlow implements this matrix multiplication functionality in the [`tf.matmul()`](https://www.tensorflow.org/api_docs/python/tf/linalg/matmul) method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "1. The inner dimensions must match:\n",
        "  * `(3, 5) @ (3, 5)` won't work\n",
        "  * `(5, 3) @ (3, 5)` will work\n",
        "  * `(3, 5) @ (5, 3)` will work\n",
        "2. The resulting matrix has the shape of the outer dimensions:\n",
        " * `(5, 3) @ (3, 5)` -> `(5, 5)`\n",
        " * `(3, 5) @ (5, 3)` -> `(3, 3)`\n",
        "\n",
        "> ðŸ”‘ **Note:** '`@`' in Python is the symbol for matrix multiplication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function matmul in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "matmul(a, b, transpose_a=False, transpose_b=False, adjoint_a=False, adjoint_b=False, a_is_sparse=False, b_is_sparse=False, output_type=None, name=None)\n",
            "    Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
            "    \n",
            "    The inputs must, following any transpositions, be tensors of rank >= 2\n",
            "    where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
            "    and any further outer dimensions specify matching batch size.\n",
            "    \n",
            "    Both matrices must be of the same type. The supported types are:\n",
            "    `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            "    `complex64`, `complex128`.\n",
            "    \n",
            "    Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
            "    the fly by setting one of the corresponding flag to `True`. These are `False`\n",
            "    by default.\n",
            "    \n",
            "    If one or both of the matrices contain a lot of zeros, a more efficient\n",
            "    multiplication algorithm can be used by setting the corresponding\n",
            "    `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
            "    This optimization is only available for plain matrices (rank-2 tensors) with\n",
            "    datatypes `bfloat16` or `float32`.\n",
            "    \n",
            "    A simple 2-D tensor matrix multiplication:\n",
            "    \n",
            "    >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
            "    >>> a  # 2-D tensor\n",
            "    <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            "    array([[1, 2, 3],\n",
            "           [4, 5, 6]], dtype=int32)>\n",
            "    >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
            "    >>> b  # 2-D tensor\n",
            "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            "    array([[ 7,  8],\n",
            "           [ 9, 10],\n",
            "           [11, 12]], dtype=int32)>\n",
            "    >>> c = tf.matmul(a, b)\n",
            "    >>> c  # `a` * `b`\n",
            "    <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
            "    array([[ 58,  64],\n",
            "           [139, 154]], dtype=int32)>\n",
            "    \n",
            "    A batch matrix multiplication with batch shape [2]:\n",
            "    \n",
            "    >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
            "    >>> a  # 3-D tensor\n",
            "    <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
            "    array([[[ 1,  2,  3],\n",
            "            [ 4,  5,  6]],\n",
            "           [[ 7,  8,  9],\n",
            "            [10, 11, 12]]], dtype=int32)>\n",
            "    >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
            "    >>> b  # 3-D tensor\n",
            "    <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
            "    array([[[13, 14],\n",
            "            [15, 16],\n",
            "            [17, 18]],\n",
            "           [[19, 20],\n",
            "            [21, 22],\n",
            "            [23, 24]]], dtype=int32)>\n",
            "    >>> c = tf.matmul(a, b)\n",
            "    >>> c  # `a` * `b`\n",
            "    <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
            "    array([[[ 94, 100],\n",
            "            [229, 244]],\n",
            "           [[508, 532],\n",
            "            [697, 730]]], dtype=int32)>\n",
            "    \n",
            "    Since python >= 3.5 the @ operator is supported\n",
            "    (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
            "    it simply calls the `tf.matmul()` function, so the following lines are\n",
            "    equivalent:\n",
            "    \n",
            "    >>> d = a @ b @ [[10], [11]]\n",
            "    >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
            "    \n",
            "    Args:\n",
            "      a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
            "        `complex64`, `complex128` and rank > 1.\n",
            "      b: `tf.Tensor` with same type and rank as `a`.\n",
            "      transpose_a: If `True`, `a` is transposed before multiplication.\n",
            "      transpose_b: If `True`, `b` is transposed before multiplication.\n",
            "      adjoint_a: If `True`, `a` is conjugated and transposed before\n",
            "        multiplication.\n",
            "      adjoint_b: If `True`, `b` is conjugated and transposed before\n",
            "        multiplication.\n",
            "      a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
            "        **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            "        that assume most values in `a` are zero.\n",
            "        See `tf.sparse.sparse_dense_matmul`\n",
            "        for some support for `tf.sparse.SparseTensor` multiplication.\n",
            "      b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
            "        **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            "        that assume most values in `b` are zero.\n",
            "        See `tf.sparse.sparse_dense_matmul`\n",
            "        for some support for `tf.sparse.SparseTensor` multiplication.\n",
            "      output_type: The output datatype if needed. Defaults to None in which case\n",
            "        the output_type is the same as input type. Currently only works when input\n",
            "        tensors are type (u)int8 and output_type can be int32.\n",
            "      name: Name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
            "      is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
            "      transpose or adjoint attributes are `False`:\n",
            "    \n",
            "      `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
            "      for all indices `i`, `j`.\n",
            "    \n",
            "      Note: This is matrix product, not element-wise product.\n",
            "    \n",
            "    \n",
            "    Raises:\n",
            "      ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
            "        `adjoint_b` are both set to `True`.\n",
            "      TypeError: If output_type is specified but the types of `a`, `b` and\n",
            "        `output_type` is not (u)int8, (u)int8 and int32.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.matmul)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbpwVJrAsPpA",
        "outputId": "580b001a-f0c1-45ef-9918-cc5538b0fb1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[10.  7.]\n",
            " [ 3.  4.]], shape=(2, 2), dtype=float32)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[121.,  98.],\n",
              "       [ 42.,  37.]], dtype=float32)>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication in TensorFlow\n",
        "print(tensor)\n",
        "tf.matmul(a=tensor, \n",
        "          b=tensor, \n",
        "          transpose_a=False, \n",
        "          transpose_b=False, \n",
        "          adjoint_a=False, \n",
        "          adjoint_b=False, \n",
        "          a_is_sparse=False, \n",
        "          b_is_sparse=False, \n",
        "          name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vpDnpb10G7U",
        "outputId": "6693b6f2-e529-41f3-b08b-c19a90df1137"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
              "array([[121.,  98.],\n",
              "       [ 42.,  37.]], dtype=float32)>"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Matrix multiplication with Python operator '@'\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAV3S5YV0cDQ"
      },
      "source": [
        "Both of these examples work because our `tensor` variable is of shape (2, 2).\n",
        "\n",
        "What if we created some tensors which had mismatched shapes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXSE6q1o0amm",
        "outputId": "77694ca8-b6c5-4997-8e0e-9cb43bd78145"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[1, 2],\n",
              "        [3, 4],\n",
              "        [5, 6]], dtype=int32)>,\n",
              " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
              " array([[ 7,  8],\n",
              "        [ 9, 10],\n",
              "        [11, 12]], dtype=int32)>)"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create (3, 2) tensor\n",
        "X = tf.constant(value=[[1, 2],\n",
        "                 [3, 4],\n",
        "                 [5, 6]], \n",
        "                 dtype=None, \n",
        "                 shape=None,\n",
        "                 name='X')\n",
        "\n",
        "# Create another (3, 2) tensor\n",
        "Y = tf.constant(value=[[7, 8],\n",
        "                 [9, 10],\n",
        "                 [11, 12]], \n",
        "                 dtype=None, \n",
        "                 shape=None,\n",
        "                 name='Y')\n",
        "X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "3J4DGQa309Hc",
        "outputId": "d7a867bd-6c5f-4ef9-b9a9-b00c89b1cba1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: {{function_node __wrapped__MatMul_device_/job:localhost/replica:0/task:0/device:CPU:0}} Matrix size-incompatible: In[0]: [3,2], In[1]: [3,2] [Op:MatMul]\n"
          ]
        }
      ],
      "source": [
        "# Try to matrix multiply them (will error)\n",
        "from tensorflow.errors import InvalidArgumentError\n",
        "\n",
        "try:\n",
        "    X @ Y\n",
        "except InvalidArgumentError as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v27FQ59v1N-H"
      },
      "source": [
        "Trying to matrix multiply two tensors with the shape `(3, 2)` errors because the inner dimensions don't match.\n",
        "\n",
        "We need to either:\n",
        "* Reshape X to `(2, 3)` so it's `(2, 3) @ (3, 2)`.\n",
        "* Reshape Y to `(3, 2)` so it's `(3, 2) @ (2, 3)`.\n",
        "\n",
        "We can do this with either:\n",
        "* [`tf.reshape()`](https://www.tensorflow.org/api_docs/python/tf/reshape) - allows us to reshape a tensor into a defined shape.\n",
        "* [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) - switches the dimensions of a given tensor.\n",
        "\n",
        "![lining up dimensions for dot products](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-lining-up-dot-products.png)\n",
        "\n",
        "Let's try `tf.reshape()` first."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function reshape in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "reshape(tensor, shape, name=None)\n",
            "    Reshapes a tensor.\n",
            "    \n",
            "    Given `tensor`, this operation returns a new `tf.Tensor` that has the same\n",
            "    values as `tensor` in the same order, except with a new shape given by\n",
            "    `shape`.\n",
            "    \n",
            "    >>> t1 = [[1, 2, 3],\n",
            "    ...       [4, 5, 6]]\n",
            "    >>> print(tf.shape(t1).numpy())\n",
            "    [2 3]\n",
            "    >>> t2 = tf.reshape(t1, [6])\n",
            "    >>> t2\n",
            "    <tf.Tensor: shape=(6,), dtype=int32,\n",
            "      numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
            "    >>> tf.reshape(t2, [3, 2])\n",
            "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            "      array([[1, 2],\n",
            "             [3, 4],\n",
            "             [5, 6]], dtype=int32)>\n",
            "    \n",
            "    The `tf.reshape` does not change the order of or the total number of elements\n",
            "    in the tensor, and so it can reuse the underlying data buffer. This makes it\n",
            "    a fast operation independent of how big of a tensor it is operating on.\n",
            "    \n",
            "    >>> tf.reshape([1, 2, 3], [2, 2])\n",
            "    Traceback (most recent call last):\n",
            "    ...\n",
            "    InvalidArgumentError: Input to reshape is a tensor with 3 values, but the\n",
            "    requested shape has 4\n",
            "    \n",
            "    To instead reorder the data to rearrange the dimensions of a tensor, see\n",
            "    `tf.transpose`.\n",
            "    \n",
            "    >>> t = [[1, 2, 3],\n",
            "    ...      [4, 5, 6]]\n",
            "    >>> tf.reshape(t, [3, 2]).numpy()\n",
            "    array([[1, 2],\n",
            "           [3, 4],\n",
            "           [5, 6]], dtype=int32)\n",
            "    >>> tf.transpose(t, perm=[1, 0]).numpy()\n",
            "    array([[1, 4],\n",
            "           [2, 5],\n",
            "           [3, 6]], dtype=int32)\n",
            "    \n",
            "    If one component of `shape` is the special value -1, the size of that\n",
            "    dimension is computed so that the total size remains constant.  In particular,\n",
            "    a `shape` of `[-1]` flattens into 1-D.  At most one component of `shape` can\n",
            "    be -1.\n",
            "    \n",
            "    >>> t = [[1, 2, 3],\n",
            "    ...      [4, 5, 6]]\n",
            "    >>> tf.reshape(t, [-1])\n",
            "    <tf.Tensor: shape=(6,), dtype=int32,\n",
            "      numpy=array([1, 2, 3, 4, 5, 6], dtype=int32)>\n",
            "    >>> tf.reshape(t, [3, -1])\n",
            "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            "      array([[1, 2],\n",
            "             [3, 4],\n",
            "             [5, 6]], dtype=int32)>\n",
            "    >>> tf.reshape(t, [-1, 2])\n",
            "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            "      array([[1, 2],\n",
            "             [3, 4],\n",
            "             [5, 6]], dtype=int32)>\n",
            "    \n",
            "    `tf.reshape(t, [])` reshapes a tensor `t` with one element to a scalar.\n",
            "    \n",
            "    >>> tf.reshape([7], []).numpy()\n",
            "    7\n",
            "    \n",
            "    More examples:\n",
            "    \n",
            "    >>> t = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "    >>> print(tf.shape(t).numpy())\n",
            "    [9]\n",
            "    >>> tf.reshape(t, [3, 3])\n",
            "    <tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
            "      array([[1, 2, 3],\n",
            "             [4, 5, 6],\n",
            "             [7, 8, 9]], dtype=int32)>\n",
            "    \n",
            "    >>> t = [[[1, 1], [2, 2]],\n",
            "    ...      [[3, 3], [4, 4]]]\n",
            "    >>> print(tf.shape(t).numpy())\n",
            "    [2 2 2]\n",
            "    >>> tf.reshape(t, [2, 4])\n",
            "    <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
            "      array([[1, 1, 2, 2],\n",
            "             [3, 3, 4, 4]], dtype=int32)>\n",
            "    \n",
            "    >>> t = [[[1, 1, 1],\n",
            "    ...       [2, 2, 2]],\n",
            "    ...      [[3, 3, 3],\n",
            "    ...       [4, 4, 4]],\n",
            "    ...      [[5, 5, 5],\n",
            "    ...       [6, 6, 6]]]\n",
            "    >>> print(tf.shape(t).numpy())\n",
            "    [3 2 3]\n",
            "    >>> # Pass '[-1]' to flatten 't'.\n",
            "    >>> tf.reshape(t, [-1])\n",
            "    <tf.Tensor: shape=(18,), dtype=int32,\n",
            "      numpy=array([1, 1, 1, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 6, 6, 6],\n",
            "      dtype=int32)>\n",
            "    >>> # -- Using -1 to infer the shape --\n",
            "    >>> # Here -1 is inferred to be 9:\n",
            "    >>> tf.reshape(t, [2, -1])\n",
            "    <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
            "      array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
            "             [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
            "    >>> # -1 is inferred to be 2:\n",
            "    >>> tf.reshape(t, [-1, 9])\n",
            "    <tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
            "      array([[1, 1, 1, 2, 2, 2, 3, 3, 3],\n",
            "             [4, 4, 4, 5, 5, 5, 6, 6, 6]], dtype=int32)>\n",
            "    >>> # -1 is inferred to be 3:\n",
            "    >>> tf.reshape(t, [ 2, -1, 3])\n",
            "    <tf.Tensor: shape=(2, 3, 3), dtype=int32, numpy=\n",
            "      array([[[1, 1, 1],\n",
            "              [2, 2, 2],\n",
            "              [3, 3, 3]],\n",
            "             [[4, 4, 4],\n",
            "              [5, 5, 5],\n",
            "              [6, 6, 6]]], dtype=int32)>\n",
            "    \n",
            "    Args:\n",
            "      tensor: A `Tensor`.\n",
            "      shape: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
            "        Defines the shape of the output tensor.\n",
            "      name: Optional string. A name for the operation.\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor`. Has the same type as `tensor`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.reshape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwvVl-k_2W9u",
        "outputId": "e408fd19-4705-476d-f1c5-302ff6859e54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[ 7,  8,  9],\n",
              "       [10, 11, 12]], dtype=int32)>"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of reshape (3, 2) -> (2, 3)\n",
        "tf.reshape(tensor=Y, \n",
        "           shape=(2, 3), \n",
        "           name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jBKPQVn1Nep",
        "outputId": "19906c7b-3e3b-4611-a639-7c8a3fff1d6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 27,  30,  33],\n",
              "       [ 61,  68,  75],\n",
              "       [ 95, 106, 117]], dtype=int32)>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try matrix multiplication with reshaped Y\n",
        "X @ tf.reshape(tensor=Y, shape=(2, 3), name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWAgHKNk2_TO"
      },
      "source": [
        "It worked, let's try the same with a reshaped `X`, except this time we'll use [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) and `tf.matmul()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function transpose_v2 in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "transpose_v2(a, perm=None, conjugate=False, name='transpose')\n",
            "    Transposes `a`, where `a` is a Tensor.\n",
            "    \n",
            "    Permutes the dimensions according to the value of `perm`.\n",
            "    \n",
            "    The returned tensor's dimension `i` will correspond to the input dimension\n",
            "    `perm[i]`. If `perm` is not given, it is set to (n-1...0), where n is the rank\n",
            "    of the input tensor. Hence, by default, this operation performs a regular\n",
            "    matrix transpose on 2-D input Tensors.\n",
            "    \n",
            "    If conjugate is `True` and `a.dtype` is either `complex64` or `complex128`\n",
            "    then the values of `a` are conjugated and transposed.\n",
            "    \n",
            "    @compatibility(numpy)\n",
            "    In `numpy` transposes are memory-efficient constant time operations as they\n",
            "    simply return a new view of the same data with adjusted `strides`.\n",
            "    \n",
            "    TensorFlow does not support strides, so `transpose` returns a new tensor with\n",
            "    the items permuted.\n",
            "    @end_compatibility\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> x = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
            "    >>> tf.transpose(x)\n",
            "    <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            "    array([[1, 4],\n",
            "           [2, 5],\n",
            "           [3, 6]], dtype=int32)>\n",
            "    \n",
            "    Equivalently, you could call `tf.transpose(x, perm=[1, 0])`.\n",
            "    \n",
            "    If `x` is complex, setting conjugate=True gives the conjugate transpose:\n",
            "    \n",
            "    >>> x = tf.constant([[1 + 1j, 2 + 2j, 3 + 3j],\n",
            "    ...                  [4 + 4j, 5 + 5j, 6 + 6j]])\n",
            "    >>> tf.transpose(x, conjugate=True)\n",
            "    <tf.Tensor: shape=(3, 2), dtype=complex128, numpy=\n",
            "    array([[1.-1.j, 4.-4.j],\n",
            "           [2.-2.j, 5.-5.j],\n",
            "           [3.-3.j, 6.-6.j]])>\n",
            "    \n",
            "    'perm' is more useful for n-dimensional tensors where n > 2:\n",
            "    \n",
            "    >>> x = tf.constant([[[ 1,  2,  3],\n",
            "    ...                   [ 4,  5,  6]],\n",
            "    ...                  [[ 7,  8,  9],\n",
            "    ...                   [10, 11, 12]]])\n",
            "    \n",
            "    As above, simply calling `tf.transpose` will default to `perm=[2,1,0]`.\n",
            "    \n",
            "    To take the transpose of the matrices in dimension-0 (such as when you are\n",
            "    transposing matrices where 0 is the batch dimension), you would set\n",
            "    `perm=[0,2,1]`.\n",
            "    \n",
            "    >>> tf.transpose(x, perm=[0, 2, 1])\n",
            "    <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
            "    array([[[ 1,  4],\n",
            "            [ 2,  5],\n",
            "            [ 3,  6]],\n",
            "            [[ 7, 10],\n",
            "            [ 8, 11],\n",
            "            [ 9, 12]]], dtype=int32)>\n",
            "    \n",
            "    Note: This has a shorthand `linalg.matrix_transpose`):\n",
            "    \n",
            "    Args:\n",
            "      a: A `Tensor`.\n",
            "      perm: A permutation of the dimensions of `a`.  This should be a vector.\n",
            "      conjugate: Optional bool. Setting it to `True` is mathematically equivalent\n",
            "        to tf.math.conj(tf.transpose(input)).\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A transposed `Tensor`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.transpose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qA2rCnik2OnQ",
        "outputId": "f23907d3-f052-4702-dcbb-371e0ccb8df3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
              "array([[1, 3, 5],\n",
              "       [2, 4, 6]], dtype=int32)>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example of transpose (3, 2) -> (2, 3)\n",
        "tf.transpose(a=X, \n",
        "             perm=None, \n",
        "             conjugate=False, \n",
        "             name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR8YdMfh3G0S",
        "outputId": "cd2fbe33-97c6-4e54-c27f-8febe63c8e4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 89,  98],\n",
              "       [116, 128]], dtype=int32)>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Try matrix multiplication \n",
        "tf.matmul(a=tf.transpose(a=X, perm=None, conjugate=False, name=None), \n",
        "          b=Y, \n",
        "          transpose_a=False, \n",
        "          transpose_b=False, \n",
        "          adjoint_a=False, \n",
        "          adjoint_b=False, \n",
        "          a_is_sparse=False, \n",
        "          b_is_sparse=False, \n",
        "          name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SL45P1cC5tnJ",
        "outputId": "b2aa00a3-c1e2-44a5-a574-48a0a721f0ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 89,  98],\n",
              "       [116, 128]], dtype=int32)>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You can achieve the same result with parameters\n",
        "tf.matmul(a=X, \n",
        "          b=Y, \n",
        "          transpose_a=True, \n",
        "          transpose_b=False, \n",
        "          adjoint_a=False, \n",
        "          adjoint_b=False, \n",
        "          a_is_sparse=False, \n",
        "          b_is_sparse=False, \n",
        "          name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqE518TJ3GXG"
      },
      "source": [
        "Notice the difference in the resulting shapes when tranposing `X` or reshaping `Y`.\n",
        "\n",
        "This is because of the 2nd rule mentioned above:\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)` done with `X @ tf.reshape(Y, shape=(2, 3))` \n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)` done with `tf.matmul(tf.transpose(X), Y)`\n",
        "\n",
        "This kind of data manipulation is a reminder: you'll spend a lot of your time in machine learning and working with neural networks reshaping data (in the form of tensors) to prepare it to be used with various operations (such as feeding it to a model).\n",
        "\n",
        "### The dot product\n",
        "\n",
        "Multiplying matrices by each other is also referred to as the dot product.\n",
        "\n",
        "You can perform the `tf.matmul()` operation using [`tf.tensordot()`](https://www.tensorflow.org/api_docs/python/tf/tensordot). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function tensordot in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "tensordot(a, b, axes, name=None)\n",
            "    Tensor contraction of a and b along specified axes and outer product.\n",
            "    \n",
            "    Tensordot (also known as tensor contraction) sums the product of elements\n",
            "    from `a` and `b` over the indices specified by `axes`.\n",
            "    \n",
            "    This operation corresponds to `numpy.tensordot(a, b, axes)`.\n",
            "    \n",
            "    Example 1: When `a` and `b` are matrices (order 2), the case `axes=1`\n",
            "    is equivalent to matrix multiplication.\n",
            "    \n",
            "    Example 2: When `a` and `b` are matrices (order 2), the case\n",
            "    `axes = [[1], [0]]` is equivalent to matrix multiplication.\n",
            "    \n",
            "    Example 3: When `a` and `b` are matrices (order 2), the case `axes=0` gives\n",
            "    the outer product, a tensor of order 4.\n",
            "    \n",
            "    Example 4: Suppose that \\\\(a_{ijk}\\\\) and \\\\(b_{lmn}\\\\) represent two\n",
            "    tensors of order 3. Then, `contract(a, b, [[0], [2]])` is the order 4 tensor\n",
            "    \\\\(c_{jklm}\\\\) whose entry\n",
            "    corresponding to the indices \\\\((j,k,l,m)\\\\) is given by:\n",
            "    \n",
            "    \\\\( c_{jklm} = \\sum_i a_{ijk} b_{lmi} \\\\).\n",
            "    \n",
            "    In general, `order(c) = order(a) + order(b) - 2*len(axes[0])`.\n",
            "    \n",
            "    Args:\n",
            "      a: `Tensor` of type `float32` or `float64`.\n",
            "      b: `Tensor` with the same type as `a`.\n",
            "      axes: Either a scalar `N`, or a list or an `int32` `Tensor` of shape [2, k].\n",
            "        If axes is a scalar, sum over the last N axes of a and the first N axes of\n",
            "        b in order. If axes is a list or `Tensor` the first and second row contain\n",
            "        the set of unique integers specifying axes along which the contraction is\n",
            "        computed, for `a` and `b`, respectively. The number of axes for `a` and\n",
            "        `b` must be equal. If `axes=0`, computes the outer product between `a` and\n",
            "        `b`.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` with the same type as `a`.\n",
            "    \n",
            "    Raises:\n",
            "      ValueError: If the shapes of `a`, `b`, and `axes` are incompatible.\n",
            "      IndexError: If the values in axes exceed the rank of the corresponding\n",
            "        tensor.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.tensordot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfSJHDpe2Oe9",
        "outputId": "67aab203-89c1-4b2f-afe5-b96416f043d9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
              "array([[ 89,  98],\n",
              "       [116, 128]], dtype=int32)>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform the dot product on X and Y (requires X to be transposed)\n",
        "tf.tensordot(a=tf.transpose(a=X, perm=None, conjugate=False, name=None), \n",
        "             b=Y, \n",
        "             axes=1, \n",
        "             name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waJcSOGf_Fg7"
      },
      "source": [
        "You might notice that although using both `reshape` and `tranpose` work, you get different results when using each.\n",
        "\n",
        "Let's see an example, first with `tf.transpose()` then with `tf.reshape()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAzB-F4l6Dc0",
        "outputId": "f2c1545c-e2e5-4e03-9319-65985cd299da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 23,  29,  35],\n",
              "       [ 53,  67,  81],\n",
              "       [ 83, 105, 127]], dtype=int32)>"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform matrix multiplication between X and Y (transposed)\n",
        "tf.matmul(a=X, \n",
        "          b=tf.transpose(a=Y, perm=None, conjugate=False, name=None), \n",
        "          transpose_a=False, \n",
        "          transpose_b=False, \n",
        "          adjoint_a=False, \n",
        "          adjoint_b=False, \n",
        "          a_is_sparse=False, \n",
        "          b_is_sparse=False, \n",
        "          name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-kQH7qh69PV",
        "outputId": "f8ff25a7-a7e6-4fbc-c1b7-91059ca8cfa7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
              "array([[ 27,  30,  33],\n",
              "       [ 61,  68,  75],\n",
              "       [ 95, 106, 117]], dtype=int32)>"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Perform matrix multiplication between X and Y (reshaped)\n",
        "tf.matmul(a=X, \n",
        "          b=tf.reshape(tensor=Y, shape=(2, 3), name=None), \n",
        "          transpose_a=False, \n",
        "          transpose_b=False, \n",
        "          adjoint_a=False, \n",
        "          adjoint_b=False, \n",
        "          a_is_sparse=False, \n",
        "          b_is_sparse=False, \n",
        "          name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eCDnCX6AhbF"
      },
      "source": [
        "Hmm... they result in different values.\n",
        "\n",
        "Which is strange because when dealing with `Y` (a `(3x2)` matrix), reshaping to `(2, 3)` and tranposing it result in the same shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_RLV373ATAb",
        "outputId": "202e1c47-504a-4254-bcab-faac96ab9f86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([3, 2]), TensorShape([2, 3]), TensorShape([2, 3]))"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check shapes of Y, reshaped Y and tranposed Y\n",
        "Y.shape, tf.reshape(tensor=Y, shape=(2, 3), name=None).shape, tf.transpose(a=Y, perm=None, conjugate=False, name=None).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OilqUMBKAevX"
      },
      "source": [
        "But calling `tf.reshape()` and `tf.transpose()` on `Y` don't necessarily result in the same values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5_aYjqeA_w_",
        "outputId": "39d8c934-c06e-4442-8a9d-fb91a7fb82e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Normal Y:\n",
            "tf.Tensor(\n",
            "[[ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]], shape=(3, 2), dtype=int32)\n",
            "Y reshaped to (2, 3):\n",
            "tf.Tensor(\n",
            "[[ 7  8  9]\n",
            " [10 11 12]], shape=(2, 3), dtype=int32)\n",
            "Y transposed:\n",
            "tf.Tensor(\n",
            "[[ 7  9 11]\n",
            " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "# Check values of Y, reshape Y and tranposed Y\n",
        "print(\"Normal Y:\")\n",
        "print(Y, end=\"\\n\") # \"\\n\" for newline\n",
        "\n",
        "print(\"Y reshaped to (2, 3):\")\n",
        "print(tf.reshape(tensor=Y, shape=(2, 3), name=None), end=\"\\n\")\n",
        "\n",
        "print(\"Y transposed:\")\n",
        "print(tf.transpose(a=Y, perm=None, conjugate=False, name=None))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9g3l45LFO7K"
      },
      "source": [
        "As you can see, the outputs of `tf.reshape()` and `tf.transpose()` when called on `Y`, even though they have the same shape, are different.\n",
        "\n",
        "This can be explained by the default behaviour of each method:\n",
        "* [`tf.reshape()`](https://www.tensorflow.org/api_docs/python/tf/reshape) - change the shape of the given tensor (first) and then insert values in order they appear (in our case, 7, 8, 9, 10, 11, 12).\n",
        "* [`tf.transpose()`](https://www.tensorflow.org/api_docs/python/tf/transpose) - swap the order of the axes, by default the last axis becomes the first, however the order can be changed using the [`perm` parameter](https://www.tensorflow.org/api_docs/python/tf/transpose)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzjcZ4FHCOb5"
      },
      "source": [
        "So which should you use?\n",
        "\n",
        "Again, most of the time these operations (when they need to be run, such as during the training a neural network, will be implemented for you).\n",
        "\n",
        "But generally, whenever performing a matrix multiplication and the shapes of two matrices don't line up, you will transpose (not reshape) one of them in order to line them up.\n",
        "\n",
        "### Matrix multiplication tidbits\n",
        "* If we transposed `Y`, it would be represented as $\\mathbf{Y}^\\mathsf{T}$ (note the capital T for tranpose).\n",
        "* Get an illustrative view of matrix multiplication [by Math is Fun](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
        "* Try a hands-on demo of matrix multiplcation: http://matrixmultiplication.xyz/ (shown below).\n",
        "\n",
        "![visual demo of matrix multiplication](https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/images/00-matrix-multiply-crop.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK8Kc94SL-JL"
      },
      "source": [
        "### Changing the datatype of a tensor\n",
        "\n",
        "Sometimes you'll want to alter the default datatype of your tensor. \n",
        "\n",
        "This is common when you want to compute using less precision (e.g. 16-bit floating point numbers vs. 32-bit floating point numbers). \n",
        "\n",
        "Computing with less precision is useful on devices with less computing capacity such as mobile devices (because the less bits, the less space the computations require).\n",
        "\n",
        "You can change the datatype of a tensor using [`tf.cast()`](https://www.tensorflow.org/api_docs/python/tf/cast)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function cast in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "cast(x, dtype, name=None)\n",
            "    Casts a tensor to a new type.\n",
            "    \n",
            "    The operation casts `x` (in case of `Tensor`) or `x.values`\n",
            "    (in case of `SparseTensor` or `IndexedSlices`) to `dtype`.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
            "    >>> tf.cast(x, tf.int32)\n",
            "    <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
            "    \n",
            "    Notice `tf.cast` has an alias `tf.dtypes.cast`:\n",
            "    \n",
            "    >>> x = tf.constant([1.8, 2.2], dtype=tf.float32)\n",
            "    >>> tf.dtypes.cast(x, tf.int32)\n",
            "    <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 2], dtype=int32)>\n",
            "    \n",
            "    The operation supports data types (for `x` and `dtype`) of\n",
            "    `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`, `int64`,\n",
            "    `float16`, `float32`, `float64`, `complex64`, `complex128`, `bfloat16`.\n",
            "    In case of casting from complex types (`complex64`, `complex128`) to real\n",
            "    types, only the real part of `x` is returned. In case of casting from real\n",
            "    types to complex types (`complex64`, `complex128`), the imaginary part of the\n",
            "    returned value is set to `0`. The handling of complex types here matches the\n",
            "    behavior of numpy.\n",
            "    \n",
            "    Note casting nan and inf values to integral types has undefined behavior.\n",
            "    \n",
            "    Note this operation can lead to a loss of precision when converting native\n",
            "    Python `float` and `complex` variables to `tf.float64` or `tf.complex128`\n",
            "    tensors, since the input is first converted to the `float32` data type and\n",
            "    then widened. It is recommended to use `tf.convert_to_tensor` instead of\n",
            "    `tf.cast` for any non-tensor inputs.\n",
            "    \n",
            "    Args:\n",
            "      x: A `Tensor` or `SparseTensor` or `IndexedSlices` of numeric type. It could\n",
            "        be `uint8`, `uint16`, `uint32`, `uint64`, `int8`, `int16`, `int32`,\n",
            "        `int64`, `float16`, `float32`, `float64`, `complex64`, `complex128`,\n",
            "        `bfloat16`.\n",
            "      dtype: The destination type. The list of supported dtypes is the same as\n",
            "        `x`.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` or `SparseTensor` or `IndexedSlices` with same shape as `x` and\n",
            "        same type as `dtype`.\n",
            "    \n",
            "    Raises:\n",
            "      TypeError: If `x` cannot be cast to the `dtype`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.cast)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRkZhW35Lge_",
        "outputId": "a205ee88-9f2f-485c-e6e5-3be0b080fb6f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.7, 7.4], dtype=float32)>,\n",
              " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 7], dtype=int32)>)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a new tensor with default datatype (float32)\n",
        "B = tf.constant(value=[1.7, 7.4], \n",
        "                dtype=tf.float32, \n",
        "                shape=None,\n",
        "                name='B')\n",
        "\n",
        "# Create a new tensor with default datatype (int32)\n",
        "C = tf.constant(value=[1, 7], \n",
        "                dtype=tf.int32,\n",
        "                shape=None, \n",
        "                name='C')\n",
        "B, C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdhV1rgcNpUP",
        "outputId": "83a85f1c-fdd3-44e9-f854-75c36b94af3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change from float32 to float16 (reduced precision)\n",
        "B = tf.cast(x=B, \n",
        "            dtype=tf.float16, \n",
        "            name=None)\n",
        "B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Px2E1ANeNxRv",
        "outputId": "be744bf6-beca-4b27-e63d-ae1255be0593"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 7.], dtype=float32)>"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change from int32 to float32\n",
        "C = tf.cast(x=C, \n",
        "            dtype=tf.float32, \n",
        "            name=None)\n",
        "C"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F3L1BDuQVJz"
      },
      "source": [
        "### Getting the absolute value\n",
        "Sometimes you'll want the absolute values (all values are positive) of elements in your tensors.\n",
        "\n",
        "To do so, you can use [`tf.abs()`](https://www.tensorflow.org/api_docs/python/tf/math/abs)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function abs in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "abs(x, name=None)\n",
            "    Computes the absolute value of a tensor.\n",
            "    \n",
            "    Given a tensor of integer or floating-point values, this operation returns a\n",
            "    tensor of the same type, where each element contains the absolute value of the\n",
            "    corresponding element in the input.\n",
            "    \n",
            "    Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
            "    `float32` or `float64` that is the absolute value of each element in `x`. For\n",
            "    a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
            "    \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> # real number\n",
            "    >>> x = tf.constant([-2.25, 3.25])\n",
            "    >>> tf.abs(x)\n",
            "    <tf.Tensor: shape=(2,), dtype=float32,\n",
            "    numpy=array([2.25, 3.25], dtype=float32)>\n",
            "    \n",
            "    >>> # complex number\n",
            "    >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
            "    >>> tf.abs(x)\n",
            "    <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
            "    array([[5.25594901],\n",
            "           [6.60492241]])>\n",
            "    \n",
            "    Args:\n",
            "      x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
            "        `int32`, `int64`, `complex64` or `complex128`.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
            "        with absolute values. Note, for `complex64` or `complex128` input, the\n",
            "        returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
            "    \n",
            "      If `x` is a `SparseTensor`, returns\n",
            "      `SparseTensor(x.indices, tf.math.abs(x.values, ...), x.dense_shape)`\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.abs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plNBFi51QOvW",
        "outputId": "79dbe7c8-e212-4b0d-9ee1-965c496afe28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ -7., -10.], dtype=float32)>"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create tensor with negative values\n",
        "D = tf.constant(value=[-7, -10], \n",
        "                dtype=tf.float32, \n",
        "                shape=None,\n",
        "                name='D')\n",
        "D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOSYmX37QFHS",
        "outputId": "8aa0a217-54e1-4edf-b812-4b0eb05f61a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 7., 10.], dtype=float32)>"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the absolute values\n",
        "tf.abs(x=D, name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4cnALehQ2CE"
      },
      "source": [
        "### Finding the min, max, mean, sum (aggregation)\n",
        "\n",
        "You can quickly aggregate (perform a calculation on a whole tensor) tensors to find things like the minimum value, maximum value, mean and sum of all the elements.\n",
        "\n",
        "To do so, aggregation methods typically have the syntax `reduce()_[action]`, such as:\n",
        "* [`tf.reduce_min()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_min) - find the minimum value in a tensor.\n",
        "* [`tf.reduce_max()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_max) - find the maximum value in a tensor (helpful for when you want to find the highest prediction probability).\n",
        "* [`tf.reduce_mean()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_mean) - find the mean of all elements in a tensor.\n",
        "* [`tf.reduce_sum()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_sum) - find the sum of all elements in a tensor.\n",
        "* **Note:** typically, each of these is under the `math` module, e.g. `tf.math.reduce_min()` but you can use the alias `tf.reduce_min()`.\n",
        "\n",
        "Let's see them in action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjW5_6i6Q7oo",
        "outputId": "7145a7b4-d9da-4120-a2cb-5ebe2bbc0f17"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=int64, numpy=\n",
              "array([64, 10, 45, 26,  7, 27, 32, 90,  1, 95, 71, 68,  8,  4, 27, 84, 46,\n",
              "       43, 78, 20, 72, 93, 81, 99, 99, 90, 57, 54, 90, 73, 96, 55, 56,  2,\n",
              "       80, 31, 79, 68,  2, 96, 57,  0, 96, 77,  2, 40, 81, 93, 35, 51])>"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor with 50 random values between 0 and 100\n",
        "E = tf.constant(value=np.random.randint(low=0, high=100, size=50), \n",
        "                dtype=None, \n",
        "                shape=None,\n",
        "                name='E')\n",
        "E"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function reduce_min in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "reduce_min(input_tensor, axis=None, keepdims=False, name=None)\n",
            "    Computes the `tf.math.minimum` of elements across dimensions of a tensor.\n",
            "    \n",
            "    This is the reduction operation for the elementwise `tf.math.minimum` op.\n",
            "    \n",
            "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
            "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
            "    of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
            "    reduced dimensions are retained with length 1.\n",
            "    \n",
            "    If `axis` is None, all dimensions are reduced, and a\n",
            "    tensor with a single element is returned.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> a = tf.constant([\n",
            "    ...   [[1, 2], [3, 4]],\n",
            "    ...   [[1, 2], [3, 4]]\n",
            "    ... ])\n",
            "    >>> tf.reduce_min(a)\n",
            "    <tf.Tensor: shape=(), dtype=int32, numpy=1>\n",
            "    \n",
            "    Choosing a specific axis returns minimum element in the given axis:\n",
            "    \n",
            "    >>> b = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
            "    >>> tf.reduce_min(b, axis=0)\n",
            "    <tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>\n",
            "    >>> tf.reduce_min(b, axis=1)\n",
            "    <tf.Tensor: shape=(2,), dtype=int32, numpy=array([1, 4], dtype=int32)>\n",
            "    \n",
            "    Setting `keepdims` to `True` retains the dimension of `input_tensor`:\n",
            "    \n",
            "    >>> tf.reduce_min(a, keepdims=True)\n",
            "    <tf.Tensor: shape=(1, 1, 1), dtype=int32, numpy=array([[[1]]], dtype=int32)>\n",
            "    >>> tf.math.reduce_min(a, axis=0, keepdims=True)\n",
            "    <tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
            "    array([[[1, 2],\n",
            "            [3, 4]]], dtype=int32)>\n",
            "    \n",
            "    Args:\n",
            "      input_tensor: The tensor to reduce. Should have real numeric type.\n",
            "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
            "        dimensions. Must be in the range `[-rank(input_tensor),\n",
            "        rank(input_tensor))`.\n",
            "      keepdims: If true, retains reduced dimensions with length 1.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      The reduced tensor.\n",
            "    \n",
            "    @compatibility(numpy)\n",
            "    Equivalent to np.min\n",
            "    @end_compatibility\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.reduce_min)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slwMVgT-Rac0",
        "outputId": "34cf2c05-53b9-44eb-9df5-28df227794d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=0>"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the minimum\n",
        "tf.reduce_min(input_tensor=E, \n",
        "              axis=None, \n",
        "              keepdims=False, \n",
        "              name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function reduce_max in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "reduce_max(input_tensor, axis=None, keepdims=False, name=None)\n",
            "    Computes `tf.math.maximum` of elements across dimensions of a tensor.\n",
            "    \n",
            "    This is the reduction operation for the elementwise `tf.math.maximum` op.\n",
            "    \n",
            "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
            "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
            "    of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
            "    reduced dimensions are retained with length 1.\n",
            "    \n",
            "    If `axis` is None, all dimensions are reduced, and a\n",
            "    tensor with a single element is returned.\n",
            "    \n",
            "    Usage example:\n",
            "    \n",
            "      >>> x = tf.constant([5, 1, 2, 4])\n",
            "      >>> tf.reduce_max(x)\n",
            "      <tf.Tensor: shape=(), dtype=int32, numpy=5>\n",
            "      >>> x = tf.constant([-5, -1, -2, -4])\n",
            "      >>> tf.reduce_max(x)\n",
            "      <tf.Tensor: shape=(), dtype=int32, numpy=-1>\n",
            "      >>> x = tf.constant([4, float('nan')])\n",
            "      >>> tf.reduce_max(x)\n",
            "      <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
            "      >>> x = tf.constant([float('nan'), float('nan')])\n",
            "      >>> tf.reduce_max(x)\n",
            "      <tf.Tensor: shape=(), dtype=float32, numpy=nan>\n",
            "      >>> x = tf.constant([float('-inf'), float('inf')])\n",
            "      >>> tf.reduce_max(x)\n",
            "      <tf.Tensor: shape=(), dtype=float32, numpy=inf>\n",
            "    \n",
            "    See the numpy docs for `np.amax` and `np.nanmax` behavior.\n",
            "    \n",
            "    Args:\n",
            "      input_tensor: The tensor to reduce. Should have real numeric type.\n",
            "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
            "        dimensions. Must be in the range `[-rank(input_tensor),\n",
            "        rank(input_tensor))`.\n",
            "      keepdims: If true, retains reduced dimensions with length 1.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      The reduced tensor.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.reduce_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voLqafGCRYqO",
        "outputId": "8bec8619-45e8-4b95-970b-4ee3b7c55d77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=99>"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the maximum\n",
        "tf.reduce_max(input_tensor=E, \n",
        "              axis=None, \n",
        "              keepdims=False, \n",
        "              name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function reduce_mean in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "reduce_mean(input_tensor, axis=None, keepdims=False, name=None)\n",
            "    Computes the mean of elements across dimensions of a tensor.\n",
            "    \n",
            "    Reduces `input_tensor` along the dimensions given in `axis` by computing the\n",
            "    mean of elements across the dimensions in `axis`.\n",
            "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
            "    of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
            "    reduced dimensions are retained with length 1.\n",
            "    \n",
            "    If `axis` is None, all dimensions are reduced, and a tensor with a single\n",
            "    element is returned.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> x = tf.constant([[1., 1.], [2., 2.]])\n",
            "    >>> tf.reduce_mean(x)\n",
            "    <tf.Tensor: shape=(), dtype=float32, numpy=1.5>\n",
            "    >>> tf.reduce_mean(x, 0)\n",
            "    <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1.5, 1.5], dtype=float32)>\n",
            "    >>> tf.reduce_mean(x, 1)\n",
            "    <tf.Tensor: shape=(2,), dtype=float32, numpy=array([1., 2.], dtype=float32)>\n",
            "    \n",
            "    Args:\n",
            "      input_tensor: The tensor to reduce. Should have numeric type.\n",
            "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
            "        dimensions. Must be in the range `[-rank(input_tensor),\n",
            "        rank(input_tensor))`.\n",
            "      keepdims: If true, retains reduced dimensions with length 1.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      The reduced tensor.\n",
            "    \n",
            "    @compatibility(numpy)\n",
            "    Equivalent to np.mean\n",
            "    \n",
            "    Please note that `np.mean` has a `dtype` parameter that could be used to\n",
            "    specify the output type. By default this is `dtype=float64`. On the other\n",
            "    hand, `tf.reduce_mean` has an aggressive type inference from `input_tensor`,\n",
            "    for example:\n",
            "    \n",
            "    >>> x = tf.constant([1, 0, 1, 0])\n",
            "    >>> tf.reduce_mean(x)\n",
            "    <tf.Tensor: shape=(), dtype=int32, numpy=0>\n",
            "    >>> y = tf.constant([1., 0., 1., 0.])\n",
            "    >>> tf.reduce_mean(y)\n",
            "    <tf.Tensor: shape=(), dtype=float32, numpy=0.5>\n",
            "    \n",
            "    @end_compatibility\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.reduce_mean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPqwvy6TRYN3",
        "outputId": "905c4bf8-5d3f-443f-f92b-74752800987a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=55>"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the mean\n",
        "tf.reduce_mean(input_tensor=E, \n",
        "               axis=None, \n",
        "               keepdims=False, \n",
        "               name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function reduce_sum in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "reduce_sum(input_tensor, axis=None, keepdims=False, name=None)\n",
            "    Computes the sum of elements across dimensions of a tensor.\n",
            "    \n",
            "    This is the reduction operation for the elementwise `tf.math.add` op.\n",
            "    \n",
            "    Reduces `input_tensor` along the dimensions given in `axis`.\n",
            "    Unless `keepdims` is true, the rank of the tensor is reduced by 1 for each\n",
            "    of the entries in `axis`, which must be unique. If `keepdims` is true, the\n",
            "    reduced dimensions are retained with length 1.\n",
            "    \n",
            "    If `axis` is None, all dimensions are reduced, and a\n",
            "    tensor with a single element is returned.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "      >>> # x has a shape of (2, 3) (two rows and three columns):\n",
            "      >>> x = tf.constant([[1, 1, 1], [1, 1, 1]])\n",
            "      >>> x.numpy()\n",
            "      array([[1, 1, 1],\n",
            "             [1, 1, 1]], dtype=int32)\n",
            "      >>> # sum all the elements\n",
            "      >>> # 1 + 1 + 1 + 1 + 1+ 1 = 6\n",
            "      >>> tf.reduce_sum(x).numpy()\n",
            "      6\n",
            "      >>> # reduce along the first dimension\n",
            "      >>> # the result is [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
            "      >>> tf.reduce_sum(x, 0).numpy()\n",
            "      array([2, 2, 2], dtype=int32)\n",
            "      >>> # reduce along the second dimension\n",
            "      >>> # the result is [1, 1] + [1, 1] + [1, 1] = [3, 3]\n",
            "      >>> tf.reduce_sum(x, 1).numpy()\n",
            "      array([3, 3], dtype=int32)\n",
            "      >>> # keep the original dimensions\n",
            "      >>> tf.reduce_sum(x, 1, keepdims=True).numpy()\n",
            "      array([[3],\n",
            "             [3]], dtype=int32)\n",
            "      >>> # reduce along both dimensions\n",
            "      >>> # the result is 1 + 1 + 1 + 1 + 1 + 1 = 6\n",
            "      >>> # or, equivalently, reduce along rows, then reduce the resultant array\n",
            "      >>> # [1, 1, 1] + [1, 1, 1] = [2, 2, 2]\n",
            "      >>> # 2 + 2 + 2 = 6\n",
            "      >>> tf.reduce_sum(x, [0, 1]).numpy()\n",
            "      6\n",
            "    \n",
            "    Args:\n",
            "      input_tensor: The tensor to reduce. Should have numeric type.\n",
            "      axis: The dimensions to reduce. If `None` (the default), reduces all\n",
            "        dimensions. Must be in the range `[-rank(input_tensor),\n",
            "        rank(input_tensor)]`.\n",
            "      keepdims: If true, retains reduced dimensions with length 1.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      The reduced tensor, of the same dtype as the input_tensor.\n",
            "    \n",
            "    @compatibility(numpy)\n",
            "    Equivalent to np.sum apart the fact that numpy upcast uint8 and int32 to\n",
            "    int64 while tensorflow returns the same dtype as the input.\n",
            "    @end_compatibility\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.reduce_sum)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqwCXeD6RhyE",
        "outputId": "4ce00693-124a-4875-a942-5a48672ace3c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=2751>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the sum\n",
        "tf.reduce_sum(input_tensor=E, \n",
        "              axis=None, \n",
        "              keepdims=False, \n",
        "              name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXGyiVPiRqgO"
      },
      "source": [
        "You can also find the standard deviation ([`tf.reduce_std()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_std)) and variance ([`tf.reduce_variance()`](https://www.tensorflow.org/api_docs/python/tf/math/reduce_variance)) of elements in a tensor using similar methods.\n",
        "\n",
        "### Finding the positional maximum and minimum\n",
        "\n",
        "How about finding the position a tensor where the maximum value occurs?\n",
        "\n",
        "This is helpful when you want to line up your labels (say `['Green', 'Blue', 'Red']`) with your prediction probabilities tensor (e.g. `[0.98, 0.01, 0.01]`).\n",
        "\n",
        "In this case, the predicted label (the one with the highest prediction probability) would be `'Green'`.\n",
        "\n",
        "You can do the same for the minimum (if required) with the following:\n",
        "* [`tf.argmax()`](https://www.tensorflow.org/api_docs/python/tf/math/argmax) - find the position of the maximum element in a given tensor.\n",
        "* [`tf.argmin()`](https://www.tensorflow.org/api_docs/python/tf/math/argmin) - find the position of the minimum element in a given tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PspO0Vjp3Nm6",
        "outputId": "74c67bd9-a883-4b67-a7a3-55654d506e77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(50,), dtype=float64, numpy=\n",
              "array([0.46703722, 0.30769016, 0.49587373, 0.33098161, 0.86840723,\n",
              "       0.01577022, 0.21208407, 0.14066191, 0.60157283, 0.95039157,\n",
              "       0.16855741, 0.62989022, 0.65358194, 0.96354637, 0.11921644,\n",
              "       0.30905916, 0.55257737, 0.23852791, 0.23095991, 0.95104391,\n",
              "       0.81443307, 0.60805415, 0.17777842, 0.47697977, 0.36780903,\n",
              "       0.58869448, 0.84112553, 0.18924058, 0.56969802, 0.89971207,\n",
              "       0.39067203, 0.10505641, 0.42397971, 0.87468515, 0.64692981,\n",
              "       0.42156974, 0.12415688, 0.39777026, 0.16953324, 0.17180182,\n",
              "       0.97093791, 0.53140518, 0.70695798, 0.36147223, 0.86551351,\n",
              "       0.17990564, 0.83544696, 0.99521514, 0.33659175, 0.25469952])>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor with 50 values between 0 and 1\n",
        "F = tf.constant(value=np.random.random(size=50), \n",
        "                dtype=None, \n",
        "                shape=None,\n",
        "                name='F')\n",
        "F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function argmax_v2 in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "argmax_v2(input, axis=None, output_type=tf.int64, name=None)\n",
            "    Returns the index with the largest value across axes of a tensor.\n",
            "    \n",
            "    In case of identity returns the smallest index.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    >>> A = tf.constant([2, 20, 30, 3, 6])\n",
            "    >>> tf.math.argmax(A)  # A[2] is maximum in tensor A\n",
            "    <tf.Tensor: shape=(), dtype=int64, numpy=2>\n",
            "    >>> B = tf.constant([[2, 20, 30, 3, 6], [3, 11, 16, 1, 8],\n",
            "    ...                  [14, 45, 23, 5, 27]])\n",
            "    >>> tf.math.argmax(B, 0)\n",
            "    <tf.Tensor: shape=(5,), dtype=int64, numpy=array([2, 2, 0, 2, 2])>\n",
            "    >>> tf.math.argmax(B, 1)\n",
            "    <tf.Tensor: shape=(3,), dtype=int64, numpy=array([2, 2, 1])>\n",
            "    >>> C = tf.constant([0, 0, 0, 0])\n",
            "    >>> tf.math.argmax(C) # Returns smallest index in case of ties\n",
            "    <tf.Tensor: shape=(), dtype=int64, numpy=0>\n",
            "    \n",
            "    Args:\n",
            "      input: A `Tensor`.\n",
            "      axis: An integer, the axis to reduce across. Default to 0.\n",
            "      output_type: An optional output dtype (`tf.int32` or `tf.int64`). Defaults\n",
            "        to `tf.int64`.\n",
            "      name: An optional name for the operation.\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor` of type `output_type`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.argmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADbAMm9N3Zlb",
        "outputId": "6fc95755-3b77-495e-f382-0a8b7f2cdef2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=47>"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the maximum element position of F\n",
        "tf.argmax(input=F, \n",
        "          axis=None, \n",
        "          output_type=tf.int64, \n",
        "          name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQrv1nVE3ckx",
        "outputId": "0a78d68f-6804-4125-da7c-d12a6811258e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int64, numpy=5>"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the minimum element position of F\n",
        "tf.argmin(input=F, \n",
        "          axis=None, \n",
        "          output_type=tf.int64, \n",
        "          name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFHzARFwLmIf",
        "outputId": "2fbf3ccb-5ae2-4f20-c351-ed98401a135d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The maximum value of F is at position: 47\n",
            "The maximum value of F is: 0.9952151418596201\n",
            "Using tf.argmax() to index F, the maximum value of F is: 0.9952151418596201\n",
            "Are the two max values the same (they should be)? True\n"
          ]
        }
      ],
      "source": [
        "# Find the maximum element position of F\n",
        "print(f\"The maximum value of F is at position: {tf.argmax(input=F, axis=None, output_type=None, name=None).numpy()}\") \n",
        "print(f\"The maximum value of F is: {tf.reduce_max(input_tensor=F, axis=None, keepdims=False, name=None).numpy()}\") \n",
        "print(f\"Using tf.argmax() to index F, the maximum value of F is: {F[tf.argmax(input=F, axis=None, output_type=None, name=None)].numpy()}\")\n",
        "print(f\"Are the two max values the same (they should be)? {F[tf.argmax(input=F, axis=None, output_type=None, name=None)].numpy() == tf.reduce_max(input_tensor=F, axis=None, keepdims=False, name=None).numpy()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSGIuNwm5QHM"
      },
      "source": [
        "### Squeezing a tensor (removing all single dimensions)\n",
        "\n",
        "If you need to remove single-dimensions from a tensor (dimensions with size 1), you can use `tf.squeeze()`.\n",
        "\n",
        "* [`tf.squeeze()`](https://www.tensorflow.org/api_docs/python/tf/squeeze) - remove all dimensions of 1 from a tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function squeeze_v2 in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "squeeze_v2(input, axis=None, name=None)\n",
            "    Removes dimensions of size 1 from the shape of a tensor.\n",
            "    \n",
            "    Given a tensor `input`, this operation returns a tensor of the same type with\n",
            "    all dimensions of size 1 removed. If you don't want to remove all size 1\n",
            "    dimensions, you can remove specific size 1 dimensions by specifying\n",
            "    `axis`.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    ```python\n",
            "    # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
            "    tf.shape(tf.squeeze(t))  # [2, 3]\n",
            "    ```\n",
            "    \n",
            "    Or, to remove specific size 1 dimensions:\n",
            "    \n",
            "    ```python\n",
            "    # 't' is a tensor of shape [1, 2, 1, 3, 1, 1]\n",
            "    tf.shape(tf.squeeze(t, [2, 4]))  # [1, 2, 3, 1]\n",
            "    ```\n",
            "    \n",
            "    Unlike the older op `tf.compat.v1.squeeze`, this op does not accept a\n",
            "    deprecated `squeeze_dims` argument.\n",
            "    \n",
            "    Note: if `input` is a `tf.RaggedTensor`, then this operation takes `O(N)`\n",
            "    time, where `N` is the number of elements in the squeezed dimensions.\n",
            "    \n",
            "    Note: If squeeze is performed on dimensions of unknown sizes, then the\n",
            "    returned Tensor will be of unknown shape. A common situation is when the\n",
            "    first (batch) dimension is of size `None`, `tf.squeeze` returns\n",
            "    `<unknown>` shape which may be a surprise. Specify the `axis=` argument\n",
            "    to get the expected result, as illustrated in the following example:\n",
            "    \n",
            "    ```python\n",
            "    @tf.function\n",
            "    def func(x):\n",
            "      print('x.shape:', x.shape)\n",
            "      known_axes = [i for i, size in enumerate(x.shape) if size == 1]\n",
            "      y = tf.squeeze(x, axis=known_axes)\n",
            "      print('shape of tf.squeeze(x, axis=known_axes):', y.shape)\n",
            "      y = tf.squeeze(x)\n",
            "      print('shape of tf.squeeze(x):', y.shape)\n",
            "      return 0\n",
            "    \n",
            "    _ = func.get_concrete_function(tf.TensorSpec([None, 1, 2], dtype=tf.int32))\n",
            "    # Output is.\n",
            "    # x.shape: (None, 1, 2)\n",
            "    # shape of tf.squeeze(x, axis=known_axes): (None, 2)\n",
            "    # shape of tf.squeeze(x): <unknown>\n",
            "    ```\n",
            "    \n",
            "    Args:\n",
            "      input: A `Tensor`. The `input` to squeeze.\n",
            "      axis: An optional list of `ints`. Defaults to `[]`. If specified, only\n",
            "        squeezes the dimensions listed. The dimension index starts at 0. It is an\n",
            "        error to squeeze a dimension that is not 1. Must be in the range\n",
            "        `[-rank(input), rank(input))`. Must be specified if `input` is a\n",
            "        `RaggedTensor`.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor`. Has the same type as `input`.\n",
            "      Contains the same data as `input`, but has one or more dimensions of\n",
            "      size 1 removed.\n",
            "    \n",
            "    Raises:\n",
            "      ValueError: The input cannot be converted to a tensor, or the specified\n",
            "        axis cannot be squeezed.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.squeeze)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xDZLtNu5wUZ",
        "outputId": "b86ca328-b539-4701-e729-b7dc5c80dc49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([1, 1, 1, 1, 50]), 5)"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a rank 5 (5 dimensions) tensor of 50 numbers between 0 and 100\n",
        "G = tf.constant(value=np.random.randint(0, 100, 50), \n",
        "                shape=(1, 1, 1, 1, 50), \n",
        "                dtype=None, \n",
        "                name='G')\n",
        "G.shape, G.ndim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS91XOgO6lai",
        "outputId": "0359d710-ca66-40c1-ac48-cd60c164f5fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(TensorShape([50]), 1)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Squeeze tensor G (remove all 1 dimensions)\n",
        "G_squeezed = tf.squeeze(input=G, \n",
        "                        axis=None, \n",
        "                        name='G_squeezed')\n",
        "G_squeezed.shape, G_squeezed.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46cKe32W65Ox"
      },
      "source": [
        "### One-hot encoding\n",
        "\n",
        "If you have a tensor of indicies and would like to one-hot encode it, you can use [`tf.one_hot()`](https://www.tensorflow.org/api_docs/python/tf/one_hot).\n",
        "\n",
        "You should also specify the `depth` parameter (the level which you want to one-hot encode to)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function one_hot in module tensorflow.python.ops.array_ops:\n",
            "\n",
            "one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)\n",
            "    Returns a one-hot tensor.\n",
            "    \n",
            "    See also `tf.fill`, `tf.eye`.\n",
            "    \n",
            "    The locations represented by indices in `indices` take value `on_value`,\n",
            "    while all other locations take value `off_value`.\n",
            "    \n",
            "    `on_value` and `off_value` must have matching data types. If `dtype` is also\n",
            "    provided, they must be the same data type as specified by `dtype`.\n",
            "    \n",
            "    If `on_value` is not provided, it will default to the value `1` with type\n",
            "    `dtype`\n",
            "    \n",
            "    If `off_value` is not provided, it will default to the value `0` with type\n",
            "    `dtype`\n",
            "    \n",
            "    If the input `indices` is rank `N`, the output will have rank `N+1`. The\n",
            "    new axis is created at dimension `axis` (default: the new axis is appended\n",
            "    at the end).\n",
            "    \n",
            "    If `indices` is a scalar the output shape will be a vector of length `depth`\n",
            "    \n",
            "    If `indices` is a vector of length `features`, the output shape will be:\n",
            "    \n",
            "    ```\n",
            "      features x depth if axis == -1\n",
            "      depth x features if axis == 0\n",
            "    ```\n",
            "    \n",
            "    If `indices` is a matrix (batch) with shape `[batch, features]`, the output\n",
            "    shape will be:\n",
            "    \n",
            "    ```\n",
            "      batch x features x depth if axis == -1\n",
            "      batch x depth x features if axis == 1\n",
            "      depth x batch x features if axis == 0\n",
            "    ```\n",
            "    \n",
            "    If `indices` is a RaggedTensor, the 'axis' argument must be positive and refer\n",
            "    to a non-ragged axis. The output will be equivalent to applying 'one_hot' on\n",
            "    the values of the RaggedTensor, and creating a new RaggedTensor from the\n",
            "    result.\n",
            "    \n",
            "    If `dtype` is not provided, it will attempt to assume the data type of\n",
            "    `on_value` or `off_value`, if one or both are passed in. If none of\n",
            "    `on_value`, `off_value`, or `dtype` are provided, `dtype` will default to the\n",
            "    value `tf.float32`.\n",
            "    \n",
            "    Note: If a non-numeric data type output is desired (`tf.string`, `tf.bool`,\n",
            "    etc.), both `on_value` and `off_value` _must_ be provided to `one_hot`.\n",
            "    \n",
            "    For example:\n",
            "    \n",
            "    ```python\n",
            "    indices = [0, 1, 2]\n",
            "    depth = 3\n",
            "    tf.one_hot(indices, depth)  # output: [3 x 3]\n",
            "    # [[1., 0., 0.],\n",
            "    #  [0., 1., 0.],\n",
            "    #  [0., 0., 1.]]\n",
            "    \n",
            "    indices = [0, 2, -1, 1]\n",
            "    depth = 3\n",
            "    tf.one_hot(indices, depth,\n",
            "               on_value=5.0, off_value=0.0,\n",
            "               axis=-1)  # output: [4 x 3]\n",
            "    # [[5.0, 0.0, 0.0],  # one_hot(0)\n",
            "    #  [0.0, 0.0, 5.0],  # one_hot(2)\n",
            "    #  [0.0, 0.0, 0.0],  # one_hot(-1)\n",
            "    #  [0.0, 5.0, 0.0]]  # one_hot(1)\n",
            "    \n",
            "    indices = [[0, 2], [1, -1]]\n",
            "    depth = 3\n",
            "    tf.one_hot(indices, depth,\n",
            "               on_value=1.0, off_value=0.0,\n",
            "               axis=-1)  # output: [2 x 2 x 3]\n",
            "    # [[[1.0, 0.0, 0.0],   # one_hot(0)\n",
            "    #   [0.0, 0.0, 1.0]],  # one_hot(2)\n",
            "    #  [[0.0, 1.0, 0.0],   # one_hot(1)\n",
            "    #   [0.0, 0.0, 0.0]]]  # one_hot(-1)\n",
            "    \n",
            "    indices = tf.ragged.constant([[0, 1], [2]])\n",
            "    depth = 3\n",
            "    tf.one_hot(indices, depth)  # output: [2 x None x 3]\n",
            "    # [[[1., 0., 0.],\n",
            "    #   [0., 1., 0.]],\n",
            "    #  [[0., 0., 1.]]]\n",
            "    ```\n",
            "    \n",
            "    Args:\n",
            "      indices: A `Tensor` of indices.\n",
            "      depth: A scalar defining the depth of the one hot dimension.\n",
            "      on_value: A scalar defining the value to fill in output when `indices[j]\n",
            "        = i`. (default: 1)\n",
            "      off_value: A scalar defining the value to fill in output when `indices[j]\n",
            "        != i`. (default: 0)\n",
            "      axis: The axis to fill (default: -1, a new inner-most axis).\n",
            "      dtype: The data type of the output tensor.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      output: The one-hot tensor.\n",
            "    \n",
            "    Raises:\n",
            "      TypeError: If dtype of either `on_value` or `off_value` don't match `dtype`\n",
            "      TypeError: If dtype of `on_value` and `off_value` don't match one another\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlRkMjL-646U",
        "outputId": "f49a6bee-e62a-4175-b84c-e4f8b5500d4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a list of indices\n",
        "some_list = [0, 1, 2, 3]\n",
        "\n",
        "# One hot encode them\n",
        "tf.one_hot(indices=some_list, \n",
        "           depth=4, \n",
        "           on_value=None, \n",
        "           off_value=None, \n",
        "           axis=None, \n",
        "           dtype=None, \n",
        "           name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYxYV0r08THk"
      },
      "source": [
        "You can also specify values for `on_value` and `off_value` instead of the default `0` and `1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZluadm88EcN",
        "outputId": "a129f06b-b23f-40d8-ed3a-ddbee35be070"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
              "array([[b\"We're live!\", b'Offline', b'Offline', b'Offline'],\n",
              "       [b'Offline', b\"We're live!\", b'Offline', b'Offline'],\n",
              "       [b'Offline', b'Offline', b\"We're live!\", b'Offline'],\n",
              "       [b'Offline', b'Offline', b'Offline', b\"We're live!\"]], dtype=object)>"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Specify custom values for on and off encoding\n",
        "tf.one_hot(indices=some_list, \n",
        "           depth=4, \n",
        "           on_value=\"We're live!\", \n",
        "           off_value=\"Offline\", \n",
        "           dtype=tf.string, \n",
        "           name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-E-I1jFC84Qi"
      },
      "source": [
        "### Squaring, log, square root\n",
        "\n",
        "Many other common mathematical operations you'd like to perform at some stage, probably exist.\n",
        "\n",
        "Let's take a look at:\n",
        "* [`tf.square()`](https://www.tensorflow.org/api_docs/python/tf/math/square) - get the square of every value in a tensor. \n",
        "* [`tf.sqrt()`](https://www.tensorflow.org/api_docs/python/tf/math/sqrt) - get the squareroot of every value in a tensor (**note:** the elements need to be floats or this will error).\n",
        "* [`tf.math.log()`](https://www.tensorflow.org/api_docs/python/tf/math/log) - get the natural log of every value in a tensor (elements need to floats)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTOvziCBLqhZ",
        "outputId": "9ef46ed1-6bd2-4e61-9068-11f5bb183150"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9])>"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a new tensor\n",
        "H = tf.constant(value=np.arange(start=1, stop=10), \n",
        "                dtype=None, \n",
        "                shape=None,\n",
        "                name='H')\n",
        "H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function square in module tensorflow.python.ops.gen_math_ops:\n",
            "\n",
            "square(x, name=None)\n",
            "    Computes square of x element-wise.\n",
            "    \n",
            "    I.e., \\\\(y = x * x = x^2\\\\).\n",
            "    \n",
            "    >>> tf.math.square([-2., 0., 3.])\n",
            "    <tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 0., 9.], dtype=float32)>\n",
            "    \n",
            "    Args:\n",
            "      x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `complex64`, `complex128`.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor`. Has the same type as `x`.\n",
            "    \n",
            "      If `x` is a `SparseTensor`, returns\n",
            "      `SparseTensor(x.indices, tf.math.square(x.values, ...), x.dense_shape)`\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.square)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvPS3xbk9JBK",
        "outputId": "999851d2-5a61-4768-8a43-1b1862ffb0bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81])>"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Square it\n",
        "tf.square(x=H, name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function sqrt in module tensorflow.python.ops.math_ops:\n",
            "\n",
            "sqrt(x, name=None)\n",
            "    Computes element-wise square root of the input tensor.\n",
            "    \n",
            "    Note: This operation does not support integer types.\n",
            "    \n",
            "    >>> x = tf.constant([[4.0], [16.0]])\n",
            "    >>> tf.sqrt(x)\n",
            "    <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
            "      array([[2.],\n",
            "             [4.]], dtype=float32)>\n",
            "    >>> y = tf.constant([[-4.0], [16.0]])\n",
            "    >>> tf.sqrt(y)\n",
            "    <tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
            "      array([[nan],\n",
            "             [ 4.]], dtype=float32)>\n",
            "    >>> z = tf.constant([[-1.0], [16.0]], dtype=tf.complex128)\n",
            "    >>> tf.sqrt(z)\n",
            "    <tf.Tensor: shape=(2, 1), dtype=complex128, numpy=\n",
            "      array([[0.0+1.j],\n",
            "             [4.0+0.j]])>\n",
            "    \n",
            "    Note: In order to support complex type, please provide an input tensor\n",
            "    of `complex64` or `complex128`.\n",
            "    \n",
            "    Args:\n",
            "      x: A `tf.Tensor` of type `bfloat16`, `half`, `float32`, `float64`,\n",
            "        `complex64`, `complex128`\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `tf.Tensor` of same size, type and sparsity as `x`.\n",
            "    \n",
            "      If `x` is a `SparseTensor`, returns\n",
            "      `SparseTensor(x.indices, tf.math.sqrt(x.values, ...), x.dense_shape)`\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.sqrt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "SJibI0GO9uf4",
        "outputId": "0a50bff8-6654-470c-dad8-7177cdf29d7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: Value for attr 'T' of int64 is not in the list of allowed values: bfloat16, half, float, double, complex64, complex128\n",
            "\t; NodeDef: {{node Sqrt}}; Op<name=Sqrt; signature=x:T -> y:T; attr=T:type,allowed=[DT_BFLOAT16, DT_HALF, DT_FLOAT, DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128]> [Op:Sqrt]\n"
          ]
        }
      ],
      "source": [
        "# Find the squareroot (will error), needs to be non-integer\n",
        "try:\n",
        "    tf.sqrt(x=H, name=None)\n",
        "except InvalidArgumentError as e:\n",
        "    print(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlxRWy6Q-NHK",
        "outputId": "f61c7c31-34da-4c8f-8040-be761e939f95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=array([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=float32)>"
            ]
          },
          "execution_count": 111,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Change H to float32\n",
        "H = tf.cast(x=H, dtype=tf.float32, name='H')\n",
        "H"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S73eO0p--TtN",
        "outputId": "6ae3c553-1df5-4f5a-a5a1-e3597300c583"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
              "array([1.       , 1.4142135, 1.7320508, 2.       , 2.2360678, 2.4494896,\n",
              "       2.6457512, 2.828427 , 3.       ], dtype=float32)>"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the square root\n",
        "tf.sqrt(x=H, name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function log in module tensorflow.python.ops.gen_math_ops:\n",
            "\n",
            "log(x, name=None)\n",
            "    Computes natural logarithm of x element-wise.\n",
            "    \n",
            "    I.e., \\\\(y = \\log_e x\\\\).\n",
            "    \n",
            "    Example:\n",
            "    >>> x = tf.constant([0, 0.5, 1, 5])\n",
            "    >>> tf.math.log(x)\n",
            "    <tf.Tensor: shape=(4,), dtype=float32, numpy=array([      -inf, -0.6931472,  0.       ,  1.609438 ], dtype=float32)>\n",
            "    \n",
            "    See: https://en.wikipedia.org/wiki/Logarithm\n",
            "    \n",
            "    Args:\n",
            "      x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `complex64`, `complex128`.\n",
            "      name: A name for the operation (optional).\n",
            "    \n",
            "    Returns:\n",
            "      A `Tensor`. Has the same type as `x`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.math.log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyCo55vz9u4f",
        "outputId": "3a8f9f11-4a00-482b-dde5-b5cebee8dcde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
              "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
              "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Find the log (input also needs to be float)\n",
        "tf.math.log(x=H, name=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urq3bx3l_Y4K"
      },
      "source": [
        "### Manipulating `tf.Variable` tensors\n",
        "\n",
        "Tensors created with `tf.Variable()` can be changed in place using methods such as:\n",
        "\n",
        "* [`.assign()`](https://www.tensorflow.org/api_docs/python/tf/Variable#assign) - assign a different value to a particular index of a variable tensor.\n",
        "* [`.add_assign()`](https://www.tensorflow.org/api_docs/python/tf/Variable#assign_add) - add to an existing value and reassign it at a particular index of a variable tensor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class Variable in module tensorflow.python.ops.variables:\n",
            "\n",
            "class Variable(tensorflow.python.trackable.base.Trackable)\n",
            " |  Variable(*args, **kwargs)\n",
            " |  \n",
            " |  See the [variable guide](https://tensorflow.org/guide/variable).\n",
            " |  \n",
            " |  A variable maintains shared, persistent state manipulated by a program.\n",
            " |  \n",
            " |  The `Variable()` constructor requires an initial value for the variable, which\n",
            " |  can be a `Tensor` of any type and shape. This initial value defines the type\n",
            " |  and shape of the variable. After construction, the type and shape of the\n",
            " |  variable are fixed. The value can be changed using one of the assign methods.\n",
            " |  \n",
            " |  >>> v = tf.Variable(1.)\n",
            " |  >>> v.assign(2.)\n",
            " |  <tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
            " |  >>> v.assign_add(0.5)\n",
            " |  <tf.Variable ... shape=() dtype=float32, numpy=2.5>\n",
            " |  \n",
            " |  The `shape` argument to `Variable`'s constructor allows you to construct a\n",
            " |  variable with a less defined shape than its `initial_value`:\n",
            " |  \n",
            " |  >>> v = tf.Variable(1., shape=tf.TensorShape(None))\n",
            " |  >>> v.assign([[1.]])\n",
            " |  <tf.Variable ... shape=<unknown> dtype=float32, numpy=array([[1.]], ...)>\n",
            " |  \n",
            " |  Just like any `Tensor`, variables created with `Variable()` can be used as\n",
            " |  inputs to operations. Additionally, all the operators overloaded for the\n",
            " |  `Tensor` class are carried over to variables.\n",
            " |  \n",
            " |  >>> w = tf.Variable([[1.], [2.]])\n",
            " |  >>> x = tf.constant([[3., 4.]])\n",
            " |  >>> tf.matmul(w, x)\n",
            " |  <tf.Tensor:... shape=(2, 2), ... numpy=\n",
            " |    array([[3., 4.],\n",
            " |           [6., 8.]], dtype=float32)>\n",
            " |  >>> tf.sigmoid(w + x)\n",
            " |  <tf.Tensor:... shape=(2, 2), ...>\n",
            " |  \n",
            " |  When building a machine learning model it is often convenient to distinguish\n",
            " |  between variables holding trainable model parameters and other variables such\n",
            " |  as a `step` variable used to count training steps. To make this easier, the\n",
            " |  variable constructor supports a `trainable=<bool>`\n",
            " |  parameter. `tf.GradientTape` watches trainable variables by default:\n",
            " |  \n",
            " |  >>> with tf.GradientTape(persistent=True) as tape:\n",
            " |  ...   trainable = tf.Variable(1.)\n",
            " |  ...   non_trainable = tf.Variable(2., trainable=False)\n",
            " |  ...   x1 = trainable * 2.\n",
            " |  ...   x2 = non_trainable * 3.\n",
            " |  >>> tape.gradient(x1, trainable)\n",
            " |  <tf.Tensor:... shape=(), dtype=float32, numpy=2.0>\n",
            " |  >>> assert tape.gradient(x2, non_trainable) is None  # Unwatched\n",
            " |  \n",
            " |  Variables are automatically tracked when assigned to attributes of types\n",
            " |  inheriting from `tf.Module`.\n",
            " |  \n",
            " |  >>> m = tf.Module()\n",
            " |  >>> m.v = tf.Variable([1.])\n",
            " |  >>> m.trainable_variables\n",
            " |  (<tf.Variable ... shape=(1,) ... numpy=array([1.], dtype=float32)>,)\n",
            " |  \n",
            " |  This tracking then allows saving variable values to\n",
            " |  [training checkpoints](https://www.tensorflow.org/guide/checkpoint), or to\n",
            " |  [SavedModels](https://www.tensorflow.org/guide/saved_model) which include\n",
            " |  serialized TensorFlow graphs.\n",
            " |  \n",
            " |  Variables are often captured and manipulated by `tf.function`s. This works the\n",
            " |  same way the un-decorated function would have:\n",
            " |  \n",
            " |  >>> v = tf.Variable(0.)\n",
            " |  >>> read_and_decrement = tf.function(lambda: v.assign_sub(0.1))\n",
            " |  >>> read_and_decrement()\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=-0.1>\n",
            " |  >>> read_and_decrement()\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=-0.2>\n",
            " |  \n",
            " |  Variables created inside a `tf.function` must be owned outside the function\n",
            " |  and be created only once:\n",
            " |  \n",
            " |  >>> class M(tf.Module):\n",
            " |  ...   @tf.function\n",
            " |  ...   def __call__(self, x):\n",
            " |  ...     if not hasattr(self, \"v\"):  # Or set self.v to None in __init__\n",
            " |  ...       self.v = tf.Variable(x)\n",
            " |  ...     return self.v * x\n",
            " |  >>> m = M()\n",
            " |  >>> m(2.)\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=4.0>\n",
            " |  >>> m(3.)\n",
            " |  <tf.Tensor: shape=(), dtype=float32, numpy=6.0>\n",
            " |  >>> m.v\n",
            " |  <tf.Variable ... shape=() dtype=float32, numpy=2.0>\n",
            " |  \n",
            " |  See the `tf.function` documentation for details.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Variable\n",
            " |      tensorflow.python.trackable.base.Trackable\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __abs__ = abs(x, name=None)\n",
            " |      Computes the absolute value of a tensor.\n",
            " |      \n",
            " |      Given a tensor of integer or floating-point values, this operation returns a\n",
            " |      tensor of the same type, where each element contains the absolute value of the\n",
            " |      corresponding element in the input.\n",
            " |      \n",
            " |      Given a tensor `x` of complex numbers, this operation returns a tensor of type\n",
            " |      `float32` or `float64` that is the absolute value of each element in `x`. For\n",
            " |      a complex number \\\\(a + bj\\\\), its absolute value is computed as\n",
            " |      \\\\(\\sqrt{a^2 + b^2}\\\\).\n",
            " |      \n",
            " |      For example:\n",
            " |      \n",
            " |      >>> # real number\n",
            " |      >>> x = tf.constant([-2.25, 3.25])\n",
            " |      >>> tf.abs(x)\n",
            " |      <tf.Tensor: shape=(2,), dtype=float32,\n",
            " |      numpy=array([2.25, 3.25], dtype=float32)>\n",
            " |      \n",
            " |      >>> # complex number\n",
            " |      >>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\n",
            " |      >>> tf.abs(x)\n",
            " |      <tf.Tensor: shape=(2, 1), dtype=float64, numpy=\n",
            " |      array([[5.25594901],\n",
            " |             [6.60492241]])>\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor` or `SparseTensor` of type `float16`, `float32`, `float64`,\n",
            " |          `int32`, `int64`, `complex64` or `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` or `SparseTensor` of the same size, type and sparsity as `x`,\n",
            " |          with absolute values. Note, for `complex64` or `complex128` input, the\n",
            " |          returned `Tensor` will be of type `float32` or `float64`, respectively.\n",
            " |  \n",
            " |  __add__ = binary_op_wrapper(x, y)\n",
            " |      The operation invoked by the `Tensor.__add__` operator.\n",
            " |      \n",
            " |      Purpose in the API:\n",
            " |      \n",
            " |        This method is exposed in TensorFlow's API so that library developers\n",
            " |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
            " |        custom composite tensors & other custom objects.\n",
            " |      \n",
            " |        The API symbol is not intended to be called by users directly and does\n",
            " |        appear in TensorFlow's generated documentation.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: The left-hand side of the `+` operator.\n",
            " |        y: The right-hand side of the `+` operator.\n",
            " |        name: an optional name for the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of the elementwise `+` operation.\n",
            " |  \n",
            " |  __and__ = binary_op_wrapper(x, y)\n",
            " |  \n",
            " |  __div__ = binary_op_wrapper(x, y)\n",
            " |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Deprecated in favor of operator or tf.math.divide.\n",
            " |      \n",
            " |      @compatibility(TF2)\n",
            " |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
            " |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
            " |      semantics.\n",
            " |      @end_compatibility\n",
            " |      \n",
            " |      \n",
            " |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
            " |      and `y` are both integers then the result will be an integer. This is in\n",
            " |      contrast to Python 3, where division with `/` is always a float while division\n",
            " |      with `//` is always an integer.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` returns the quotient of x and y.\n",
            " |  \n",
            " |  __eq__(self, other)\n",
            " |      Compares two variables element-wise for equality.\n",
            " |  \n",
            " |  __floordiv__ = binary_op_wrapper(x, y)\n",
            " |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
            " |      \n",
            " |      Mathematically, this is equivalent to floor(x / y). For example:\n",
            " |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
            " |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
            " |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
            " |      \n",
            " |      Note: `x` and `y` must have the same type, and the result will have the same\n",
            " |      type as well.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` rounded toward -infinity.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If the inputs are complex.\n",
            " |  \n",
            " |  __ge__ = greater_equal(x, y, name=None)\n",
            " |      Returns the truth value of (x >= y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.greater_equal` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6, 7])\n",
            " |      y = tf.constant([5, 2, 5, 10])\n",
            " |      tf.math.greater_equal(x, y) ==> [True, True, True, False]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6, 7])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.greater_equal(x, y) ==> [True, False, True, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __getitem__ = _SliceHelperVar(var, slice_spec)\n",
            " |      Creates a slice helper object given a variable.\n",
            " |      \n",
            " |      This allows creating a sub-tensor from part of the current contents\n",
            " |      of a variable. See `tf.Tensor.__getitem__` for detailed examples\n",
            " |      of slicing.\n",
            " |      \n",
            " |      This function in addition also allows assignment to a sliced range.\n",
            " |      This is similar to `__setitem__` functionality in Python. However,\n",
            " |      the syntax is different so that the user can capture the assignment\n",
            " |      operation for grouping or passing to `sess.run()` in TF1.\n",
            " |      For example,\n",
            " |      \n",
            " |      ```python\n",
            " |      import tensorflow as tf\n",
            " |      A = tf.Variable([[1,2,3], [4,5,6], [7,8,9]], dtype=tf.float32)\n",
            " |      print(A[:2, :2])  # => [[1,2], [4,5]]\n",
            " |      \n",
            " |      A[:2,:2].assign(22. * tf.ones((2, 2))))\n",
            " |      print(A) # => [[22, 22, 3], [22, 22, 6], [7,8,9]]\n",
            " |      ```\n",
            " |      \n",
            " |      Note that assignments currently do not support NumPy broadcasting\n",
            " |      semantics.\n",
            " |      \n",
            " |      Args:\n",
            " |        var: An `ops.Variable` object.\n",
            " |        slice_spec: The arguments to `Tensor.__getitem__`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The appropriate slice of \"tensor\", based on \"slice_spec\".\n",
            " |        As an operator. The operator also has a `assign()` method\n",
            " |        that can be used to generate an assignment operator.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If a slice range is negative size.\n",
            " |        TypeError: TypeError: If the slice indices aren't int, slice,\n",
            " |          ellipsis, tf.newaxis or int32/int64 tensors.\n",
            " |  \n",
            " |  __gt__ = greater(x, y, name=None)\n",
            " |      Returns the truth value of (x > y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.greater` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5, 2, 5])\n",
            " |      tf.math.greater(x, y) ==> [False, True, True]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.greater(x, y) ==> [False, False, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __hash__(self)\n",
            " |      Return hash(self).\n",
            " |  \n",
            " |  __init__(self, initial_value=None, trainable=None, validate_shape=True, caching_device=None, name=None, variable_def=None, dtype=None, import_scope=None, constraint=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, shape=None, experimental_enable_variable_lifting=True)\n",
            " |      Creates a new variable with value `initial_value`. (deprecated arguments)\n",
            " |      \n",
            " |      Deprecated: SOME ARGUMENTS ARE DEPRECATED: `(caching_device)`. They will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      A variable's value can be manually cached by calling tf.Variable.read_value() under a tf.device scope. The caching_device argument does not work properly.\n",
            " |      \n",
            " |      Args:\n",
            " |        initial_value: A `Tensor`, or Python object convertible to a `Tensor`,\n",
            " |          which is the initial value for the Variable. The initial value must have\n",
            " |          a shape specified unless `validate_shape` is set to False. Can also be a\n",
            " |          callable with no argument that returns the initial value when called. In\n",
            " |          that case, `dtype` must be specified. (Note that initializer functions\n",
            " |          from init_ops.py must first be bound to a shape before being used here.)\n",
            " |        trainable: If `True`, GradientTapes automatically watch uses of this\n",
            " |          variable. Defaults to `True`, unless `synchronization` is set to\n",
            " |          `ON_READ`, in which case it defaults to `False`.\n",
            " |        validate_shape: If `False`, allows the variable to be initialized with a\n",
            " |          value of unknown shape. If `True`, the default, the shape of\n",
            " |          `initial_value` must be known.\n",
            " |        caching_device: Note: This argument is only valid when using a v1-style\n",
            " |          `Session`. Optional device string describing where the Variable should\n",
            " |          be cached for reading. Defaults to the Variable's device. If not `None`,\n",
            " |          caches on another device. Typical use is to cache on the device where\n",
            " |          the Ops using the Variable reside, to deduplicate copying through\n",
            " |          `Switch` and other conditional statements.\n",
            " |        name: Optional name for the variable. Defaults to `'Variable'` and gets\n",
            " |          uniquified automatically.\n",
            " |        variable_def: `VariableDef` protocol buffer. If not `None`, recreates the\n",
            " |          Variable object with its contents, referencing the variable's nodes in\n",
            " |          the graph, which must already exist. The graph is not changed.\n",
            " |          `variable_def` and the other arguments are mutually exclusive.\n",
            " |        dtype: If set, initial_value will be converted to the given type. If\n",
            " |          `None`, either the datatype will be kept (if `initial_value` is a\n",
            " |          Tensor), or `convert_to_tensor` will decide.\n",
            " |        import_scope: Optional `string`. Name scope to add to the `Variable.` Only\n",
            " |          used when initializing from protocol buffer.\n",
            " |        constraint: An optional projection function to be applied to the variable\n",
            " |          after being updated by an `Optimizer` (e.g. used to implement norm\n",
            " |          constraints or value constraints for layer weights). The function must\n",
            " |          take as input the unprojected Tensor representing the value of the\n",
            " |          variable and return the Tensor for the projected value (which must have\n",
            " |          the same shape). Constraints are not safe to use when doing asynchronous\n",
            " |          distributed training.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses when to\n",
            " |          synchronize.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        shape: (optional) The shape of this variable. If None, the shape of\n",
            " |          `initial_value` will be used. When setting this argument to\n",
            " |          `tf.TensorShape(None)` (representing an unspecified shape), the variable\n",
            " |          can be assigned with values of different shapes.\n",
            " |        experimental_enable_variable_lifting: Whether to lift the variable out if\n",
            " |          it's in a `tf.function`. Default is `True`. When this argument\n",
            " |          is `True`, variable creation will follow the behavior and\n",
            " |          restrictions described\n",
            " |          [here](https://www.tensorflow.org/guide/function#creating_tfvariables).\n",
            " |          If this argument is `False`, that description doesn't apply,\n",
            " |          and you can freely create and use the variable in the\n",
            " |          `tf.function`, as if it's a \"mutable `tf.Tensor`\". You can't\n",
            " |          return the variable though.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If both `variable_def` and initial_value are specified.\n",
            " |        ValueError: If the initial value is not specified, or does not have a\n",
            " |          shape and `validate_shape` is `True`.\n",
            " |  \n",
            " |  __invert__ = invert_(x, name=None)\n",
            " |  \n",
            " |  __iter__(self)\n",
            " |      When executing eagerly, iterates over the value of the variable.\n",
            " |  \n",
            " |  __le__ = less_equal(x, y, name=None)\n",
            " |      Returns the truth value of (x <= y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.less_equal` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.less_equal(x, y) ==> [True, True, False]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5, 6, 6])\n",
            " |      tf.math.less_equal(x, y) ==> [True, True, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __lt__ = less(x, y, name=None)\n",
            " |      Returns the truth value of (x < y) element-wise.\n",
            " |      \n",
            " |      *NOTE*: `math.less` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5])\n",
            " |      tf.math.less(x, y) ==> [False, True, False]\n",
            " |      \n",
            " |      x = tf.constant([5, 4, 6])\n",
            " |      y = tf.constant([5, 6, 7])\n",
            " |      tf.math.less(x, y) ==> [False, True, True]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `float32`, `float64`, `int32`, `uint8`, `int16`, `int8`, `int64`, `bfloat16`, `uint16`, `half`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` of type `bool`.\n",
            " |  \n",
            " |  __matmul__ = binary_op_wrapper(x, y)\n",
            " |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
            " |      \n",
            " |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
            " |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
            " |      and any further outer dimensions specify matching batch size.\n",
            " |      \n",
            " |      Both matrices must be of the same type. The supported types are:\n",
            " |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |      `complex64`, `complex128`.\n",
            " |      \n",
            " |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
            " |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
            " |      by default.\n",
            " |      \n",
            " |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
            " |      multiplication algorithm can be used by setting the corresponding\n",
            " |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
            " |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
            " |      datatypes `bfloat16` or `float32`.\n",
            " |      \n",
            " |      A simple 2-D tensor matrix multiplication:\n",
            " |      \n",
            " |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
            " |      >>> a  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            " |      array([[1, 2, 3],\n",
            " |             [4, 5, 6]], dtype=int32)>\n",
            " |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
            " |      >>> b  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            " |      array([[ 7,  8],\n",
            " |             [ 9, 10],\n",
            " |             [11, 12]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
            " |      array([[ 58,  64],\n",
            " |             [139, 154]], dtype=int32)>\n",
            " |      \n",
            " |      A batch matrix multiplication with batch shape [2]:\n",
            " |      \n",
            " |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
            " |      >>> a  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
            " |      array([[[ 1,  2,  3],\n",
            " |              [ 4,  5,  6]],\n",
            " |             [[ 7,  8,  9],\n",
            " |              [10, 11, 12]]], dtype=int32)>\n",
            " |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
            " |      >>> b  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
            " |      array([[[13, 14],\n",
            " |              [15, 16],\n",
            " |              [17, 18]],\n",
            " |             [[19, 20],\n",
            " |              [21, 22],\n",
            " |              [23, 24]]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
            " |      array([[[ 94, 100],\n",
            " |              [229, 244]],\n",
            " |             [[508, 532],\n",
            " |              [697, 730]]], dtype=int32)>\n",
            " |      \n",
            " |      Since python >= 3.5 the @ operator is supported\n",
            " |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
            " |      it simply calls the `tf.matmul()` function, so the following lines are\n",
            " |      equivalent:\n",
            " |      \n",
            " |      >>> d = a @ b @ [[10], [11]]\n",
            " |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
            " |      \n",
            " |      Args:\n",
            " |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
            " |          `complex64`, `complex128` and rank > 1.\n",
            " |        b: `tf.Tensor` with same type and rank as `a`.\n",
            " |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
            " |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
            " |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `a` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `b` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        output_type: The output datatype if needed. Defaults to None in which case\n",
            " |          the output_type is the same as input type. Currently only works when input\n",
            " |          tensors are type (u)int8 and output_type can be int32.\n",
            " |        name: Name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
            " |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
            " |        transpose or adjoint attributes are `False`:\n",
            " |      \n",
            " |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
            " |        for all indices `i`, `j`.\n",
            " |      \n",
            " |        Note: This is matrix product, not element-wise product.\n",
            " |      \n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
            " |          `adjoint_b` are both set to `True`.\n",
            " |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
            " |          `output_type` is not (u)int8, (u)int8 and int32.\n",
            " |  \n",
            " |  __mod__ = binary_op_wrapper(x, y)\n",
            " |      Returns element-wise remainder of division.\n",
            " |      \n",
            " |      This follows Python semantics in that the\n",
            " |      result here is consistent with a flooring divide. E.g.\n",
            " |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
            " |      \n",
            " |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __mul__ = binary_op_wrapper(x, y)\n",
            " |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
            " |  \n",
            " |  __ne__(self, other)\n",
            " |      Compares two variables element-wise for equality.\n",
            " |  \n",
            " |  __neg__ = neg(x, name=None)\n",
            " |      Computes numerical negative value element-wise.\n",
            " |      \n",
            " |      I.e., \\\\(y = -x\\\\).\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `int8`, `int16`, `int32`, `int64`, `complex64`, `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __or__ = binary_op_wrapper(x, y)\n",
            " |  \n",
            " |  __pow__ = binary_op_wrapper(x, y)\n",
            " |      Computes the power of one value to another.\n",
            " |      \n",
            " |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
            " |      corresponding elements in `x` and `y`. For example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([[2, 2], [3, 3]])\n",
            " |      y = tf.constant([[8, 16], [2, 3]])\n",
            " |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`.\n",
            " |  \n",
            " |  __radd__ = r_binary_op_wrapper(y, x)\n",
            " |      The operation invoked by the `Tensor.__add__` operator.\n",
            " |      \n",
            " |      Purpose in the API:\n",
            " |      \n",
            " |        This method is exposed in TensorFlow's API so that library developers\n",
            " |        can register dispatching for `Tensor.__add__` to allow it to handle\n",
            " |        custom composite tensors & other custom objects.\n",
            " |      \n",
            " |        The API symbol is not intended to be called by users directly and does\n",
            " |        appear in TensorFlow's generated documentation.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: The left-hand side of the `+` operator.\n",
            " |        y: The right-hand side of the `+` operator.\n",
            " |        name: an optional name for the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The result of the elementwise `+` operation.\n",
            " |  \n",
            " |  __rand__ = r_binary_op_wrapper(y, x)\n",
            " |  \n",
            " |  __rdiv__ = r_binary_op_wrapper(y, x)\n",
            " |      Divides x / y elementwise (using Python 2 division operator semantics). (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Deprecated in favor of operator or tf.math.divide.\n",
            " |      \n",
            " |      @compatibility(TF2)\n",
            " |      This function is deprecated in TF2. Prefer using the Tensor division operator,\n",
            " |      `tf.divide`, or `tf.math.divide`, which obey the Python 3 division operator\n",
            " |      semantics.\n",
            " |      @end_compatibility\n",
            " |      \n",
            " |      \n",
            " |      This function divides `x` and `y`, forcing Python 2 semantics. That is, if `x`\n",
            " |      and `y` are both integers then the result will be an integer. This is in\n",
            " |      contrast to Python 3, where division with `/` is always a float while division\n",
            " |      with `//` is always an integer.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` returns the quotient of x and y.\n",
            " |  \n",
            " |  __repr__(self)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  __rfloordiv__ = r_binary_op_wrapper(y, x)\n",
            " |      Divides `x / y` elementwise, rounding toward the most negative integer.\n",
            " |      \n",
            " |      Mathematically, this is equivalent to floor(x / y). For example:\n",
            " |        floor(8.4 / 4.0) = floor(2.1) = 2.0\n",
            " |        floor(-8.4 / 4.0) = floor(-2.1) = -3.0\n",
            " |      This is equivalent to the '//' operator in Python 3.0 and above.\n",
            " |      \n",
            " |      Note: `x` and `y` must have the same type, and the result will have the same\n",
            " |      type as well.\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of real numeric type.\n",
            " |        y: `Tensor` denominator of real numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` rounded toward -infinity.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If the inputs are complex.\n",
            " |  \n",
            " |  __rmatmul__ = r_binary_op_wrapper(y, x)\n",
            " |      Multiplies matrix `a` by matrix `b`, producing `a` * `b`.\n",
            " |      \n",
            " |      The inputs must, following any transpositions, be tensors of rank >= 2\n",
            " |      where the inner 2 dimensions specify valid matrix multiplication dimensions,\n",
            " |      and any further outer dimensions specify matching batch size.\n",
            " |      \n",
            " |      Both matrices must be of the same type. The supported types are:\n",
            " |      `bfloat16`, `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |      `complex64`, `complex128`.\n",
            " |      \n",
            " |      Either matrix can be transposed or adjointed (conjugated and transposed) on\n",
            " |      the fly by setting one of the corresponding flag to `True`. These are `False`\n",
            " |      by default.\n",
            " |      \n",
            " |      If one or both of the matrices contain a lot of zeros, a more efficient\n",
            " |      multiplication algorithm can be used by setting the corresponding\n",
            " |      `a_is_sparse` or `b_is_sparse` flag to `True`. These are `False` by default.\n",
            " |      This optimization is only available for plain matrices (rank-2 tensors) with\n",
            " |      datatypes `bfloat16` or `float32`.\n",
            " |      \n",
            " |      A simple 2-D tensor matrix multiplication:\n",
            " |      \n",
            " |      >>> a = tf.constant([1, 2, 3, 4, 5, 6], shape=[2, 3])\n",
            " |      >>> a  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
            " |      array([[1, 2, 3],\n",
            " |             [4, 5, 6]], dtype=int32)>\n",
            " |      >>> b = tf.constant([7, 8, 9, 10, 11, 12], shape=[3, 2])\n",
            " |      >>> b  # 2-D tensor\n",
            " |      <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
            " |      array([[ 7,  8],\n",
            " |             [ 9, 10],\n",
            " |             [11, 12]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
            " |      array([[ 58,  64],\n",
            " |             [139, 154]], dtype=int32)>\n",
            " |      \n",
            " |      A batch matrix multiplication with batch shape [2]:\n",
            " |      \n",
            " |      >>> a = tf.constant(np.arange(1, 13, dtype=np.int32), shape=[2, 2, 3])\n",
            " |      >>> a  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
            " |      array([[[ 1,  2,  3],\n",
            " |              [ 4,  5,  6]],\n",
            " |             [[ 7,  8,  9],\n",
            " |              [10, 11, 12]]], dtype=int32)>\n",
            " |      >>> b = tf.constant(np.arange(13, 25, dtype=np.int32), shape=[2, 3, 2])\n",
            " |      >>> b  # 3-D tensor\n",
            " |      <tf.Tensor: shape=(2, 3, 2), dtype=int32, numpy=\n",
            " |      array([[[13, 14],\n",
            " |              [15, 16],\n",
            " |              [17, 18]],\n",
            " |             [[19, 20],\n",
            " |              [21, 22],\n",
            " |              [23, 24]]], dtype=int32)>\n",
            " |      >>> c = tf.matmul(a, b)\n",
            " |      >>> c  # `a` * `b`\n",
            " |      <tf.Tensor: shape=(2, 2, 2), dtype=int32, numpy=\n",
            " |      array([[[ 94, 100],\n",
            " |              [229, 244]],\n",
            " |             [[508, 532],\n",
            " |              [697, 730]]], dtype=int32)>\n",
            " |      \n",
            " |      Since python >= 3.5 the @ operator is supported\n",
            " |      (see [PEP 465](https://www.python.org/dev/peps/pep-0465/)). In TensorFlow,\n",
            " |      it simply calls the `tf.matmul()` function, so the following lines are\n",
            " |      equivalent:\n",
            " |      \n",
            " |      >>> d = a @ b @ [[10], [11]]\n",
            " |      >>> d = tf.matmul(tf.matmul(a, b), [[10], [11]])\n",
            " |      \n",
            " |      Args:\n",
            " |        a: `tf.Tensor` of type `float16`, `float32`, `float64`, `int32`,\n",
            " |          `complex64`, `complex128` and rank > 1.\n",
            " |        b: `tf.Tensor` with same type and rank as `a`.\n",
            " |        transpose_a: If `True`, `a` is transposed before multiplication.\n",
            " |        transpose_b: If `True`, `b` is transposed before multiplication.\n",
            " |        adjoint_a: If `True`, `a` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        adjoint_b: If `True`, `b` is conjugated and transposed before\n",
            " |          multiplication.\n",
            " |        a_is_sparse: If `True`, `a` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `a` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        b_is_sparse: If `True`, `b` is treated as a sparse matrix. Notice, this\n",
            " |          **does not support `tf.sparse.SparseTensor`**, it just makes optimizations\n",
            " |          that assume most values in `b` are zero.\n",
            " |          See `tf.sparse.sparse_dense_matmul`\n",
            " |          for some support for `tf.sparse.SparseTensor` multiplication.\n",
            " |        output_type: The output datatype if needed. Defaults to None in which case\n",
            " |          the output_type is the same as input type. Currently only works when input\n",
            " |          tensors are type (u)int8 and output_type can be int32.\n",
            " |        name: Name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.Tensor` of the same type as `a` and `b` where each inner-most matrix\n",
            " |        is the product of the corresponding matrices in `a` and `b`, e.g. if all\n",
            " |        transpose or adjoint attributes are `False`:\n",
            " |      \n",
            " |        `output[..., i, j] = sum_k (a[..., i, k] * b[..., k, j])`,\n",
            " |        for all indices `i`, `j`.\n",
            " |      \n",
            " |        Note: This is matrix product, not element-wise product.\n",
            " |      \n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If `transpose_a` and `adjoint_a`, or `transpose_b` and\n",
            " |          `adjoint_b` are both set to `True`.\n",
            " |        TypeError: If output_type is specified but the types of `a`, `b` and\n",
            " |          `output_type` is not (u)int8, (u)int8 and int32.\n",
            " |  \n",
            " |  __rmod__ = r_binary_op_wrapper(y, x)\n",
            " |      Returns element-wise remainder of division.\n",
            " |      \n",
            " |      This follows Python semantics in that the\n",
            " |      result here is consistent with a flooring divide. E.g.\n",
            " |      `floor(x / y) * y + floormod(x, y) = x`, regardless of the signs of x and y.\n",
            " |      \n",
            " |      *NOTE*: `math.floormod` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `int8`, `int16`, `int32`, `int64`, `uint8`, `uint16`, `uint32`, `uint64`, `bfloat16`, `half`, `float32`, `float64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __rmul__ = r_binary_op_wrapper(y, x)\n",
            " |      Dispatches cwise mul for \"Dense*Dense\" and \"Dense*Sparse\".\n",
            " |  \n",
            " |  __ror__ = r_binary_op_wrapper(y, x)\n",
            " |  \n",
            " |  __rpow__ = r_binary_op_wrapper(y, x)\n",
            " |      Computes the power of one value to another.\n",
            " |      \n",
            " |      Given a tensor `x` and a tensor `y`, this operation computes \\\\(x^y\\\\) for\n",
            " |      corresponding elements in `x` and `y`. For example:\n",
            " |      \n",
            " |      ```python\n",
            " |      x = tf.constant([[2, 2], [3, 3]])\n",
            " |      y = tf.constant([[8, 16], [2, 3]])\n",
            " |      tf.pow(x, y)  # [[256, 65536], [9, 27]]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        y: A `Tensor` of type `float16`, `float32`, `float64`, `int32`, `int64`,\n",
            " |          `complex64`, or `complex128`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`.\n",
            " |  \n",
            " |  __rsub__ = r_binary_op_wrapper(y, x)\n",
            " |      Returns x - y element-wise.\n",
            " |      \n",
            " |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Both input and output have a range `(-inf, inf)`.\n",
            " |      \n",
            " |      Example usages below.\n",
            " |      \n",
            " |      Subtract operation between an array and a scalar:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = 1\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
            " |      \n",
            " |      Note that binary `-` operator can be used instead:\n",
            " |      \n",
            " |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
            " |      >>> y = tf.convert_to_tensor(1)\n",
            " |      >>> x - y\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      \n",
            " |      Subtract operation between an array and a tensor of same shape:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
            " |      \n",
            " |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
            " |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
            " |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
            " |      conversion.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
            " |      >>> y = [2**8 + 1, 2**8 + 2]\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
            " |      \n",
            " |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
            " |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
            " |      . The two input array shapes are compared element-wise. Starting with the\n",
            " |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
            " |      needs to be `1`.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]],\n",
            " |             [[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]]])>\n",
            " |      \n",
            " |      Example with inputs of different dimensions:\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(1, 6)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]],\n",
            " |             [[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]]])>\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __rtruediv__ = r_binary_op_wrapper(y, x)\n",
            " |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
            " |      \n",
            " |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
            " |      division operator semantics.\n",
            " |      \n",
            " |      This function forces Python 3 division operator semantics where all integer\n",
            " |      arguments are cast to floating types first.   This op is generated by normal\n",
            " |      `x / y` division in Python 3 and in Python 2.7 with\n",
            " |      `from __future__ import division`.  If you want integer division that rounds\n",
            " |      down, use `x // y` or `tf.math.floordiv`.\n",
            " |      \n",
            " |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
            " |      point, the output will have the same type.  If the inputs are integral, the\n",
            " |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
            " |      and `int64` (matching the behavior of Numpy).\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of numeric type.\n",
            " |        y: `Tensor` denominator of numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` evaluated in floating point.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If `x` and `y` have different dtypes.\n",
            " |  \n",
            " |  __rxor__ = r_binary_op_wrapper(y, x)\n",
            " |  \n",
            " |  __sub__ = binary_op_wrapper(x, y)\n",
            " |      Returns x - y element-wise.\n",
            " |      \n",
            " |      *NOTE*: `tf.subtract` supports broadcasting. More about broadcasting\n",
            " |      [here](http://docs.scipy.org/doc/numpy/user/basics.broadcasting.html)\n",
            " |      \n",
            " |      Both input and output have a range `(-inf, inf)`.\n",
            " |      \n",
            " |      Example usages below.\n",
            " |      \n",
            " |      Subtract operation between an array and a scalar:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = 1\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 0, -1, -2, -3, -4], dtype=int32)>\n",
            " |      \n",
            " |      Note that binary `-` operator can be used instead:\n",
            " |      \n",
            " |      >>> x = tf.convert_to_tensor([1, 2, 3, 4, 5])\n",
            " |      >>> y = tf.convert_to_tensor(1)\n",
            " |      >>> x - y\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>\n",
            " |      \n",
            " |      Subtract operation between an array and a tensor of same shape:\n",
            " |      \n",
            " |      >>> x = [1, 2, 3, 4, 5]\n",
            " |      >>> y = tf.constant([5, 4, 3, 2, 1])\n",
            " |      >>> tf.subtract(y, x)\n",
            " |      <tf.Tensor: shape=(5,), dtype=int32,\n",
            " |      numpy=array([ 4,  2,  0, -2, -4], dtype=int32)>\n",
            " |      \n",
            " |      **Warning**: If one of the inputs (`x` or `y`) is a tensor and the other is a\n",
            " |      non-tensor, the non-tensor input will adopt (or get casted to) the data type\n",
            " |      of the tensor input. This can potentially cause unwanted overflow or underflow\n",
            " |      conversion.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = tf.constant([1, 2], dtype=tf.int8)\n",
            " |      >>> y = [2**8 + 1, 2**8 + 2]\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2,), dtype=int8, numpy=array([0, 0], dtype=int8)>\n",
            " |      \n",
            " |      When subtracting two input values of different shapes, `tf.subtract` follows the\n",
            " |      [general broadcasting rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)\n",
            " |      . The two input array shapes are compared element-wise. Starting with the\n",
            " |      trailing dimensions, the two dimensions either have to be equal or one of them\n",
            " |      needs to be `1`.\n",
            " |      \n",
            " |      For example,\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(2, 1, 3)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 3), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]],\n",
            " |             [[0., 0., 0.],\n",
            " |              [0., 0., 0.],\n",
            " |              [0., 0., 0.]]])>\n",
            " |      \n",
            " |      Example with inputs of different dimensions:\n",
            " |      \n",
            " |      >>> x = np.ones(6).reshape(2, 3, 1)\n",
            " |      >>> y = np.ones(6).reshape(1, 6)\n",
            " |      >>> tf.subtract(x, y)\n",
            " |      <tf.Tensor: shape=(2, 3, 6), dtype=float64, numpy=\n",
            " |      array([[[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]],\n",
            " |             [[0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.],\n",
            " |              [0., 0., 0., 0., 0., 0.]]])>\n",
            " |      \n",
            " |      Args:\n",
            " |        x: A `Tensor`. Must be one of the following types: `bfloat16`, `half`, `float32`, `float64`, `uint8`, `int8`, `uint16`, `int16`, `int32`, `int64`, `complex64`, `complex128`, `uint32`, `uint64`.\n",
            " |        y: A `Tensor`. Must have the same type as `x`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `x`.\n",
            " |  \n",
            " |  __truediv__ = binary_op_wrapper(x, y)\n",
            " |      Divides x / y elementwise (using Python 3 division operator semantics).\n",
            " |      \n",
            " |      NOTE: Prefer using the Tensor operator or tf.divide which obey Python\n",
            " |      division operator semantics.\n",
            " |      \n",
            " |      This function forces Python 3 division operator semantics where all integer\n",
            " |      arguments are cast to floating types first.   This op is generated by normal\n",
            " |      `x / y` division in Python 3 and in Python 2.7 with\n",
            " |      `from __future__ import division`.  If you want integer division that rounds\n",
            " |      down, use `x // y` or `tf.math.floordiv`.\n",
            " |      \n",
            " |      `x` and `y` must have the same numeric type.  If the inputs are floating\n",
            " |      point, the output will have the same type.  If the inputs are integral, the\n",
            " |      inputs are cast to `float32` for `int8` and `int16` and `float64` for `int32`\n",
            " |      and `int64` (matching the behavior of Numpy).\n",
            " |      \n",
            " |      Args:\n",
            " |        x: `Tensor` numerator of numeric type.\n",
            " |        y: `Tensor` denominator of numeric type.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        `x / y` evaluated in floating point.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If `x` and `y` have different dtypes.\n",
            " |  \n",
            " |  __xor__ = binary_op_wrapper(x, y)\n",
            " |  \n",
            " |  assign(self, value, use_locking=False, name=None, read_value=True)\n",
            " |      Assigns a new value to the variable.\n",
            " |      \n",
            " |      This is essentially a shortcut for `assign(self, value)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        value: A `Tensor`. The new value for this variable.\n",
            " |        use_locking: If `True`, use locking during the assignment.\n",
            " |        name: The name of the operation to be created\n",
            " |        read_value: if True, will return something which evaluates to the new\n",
            " |          value of the variable; if False will return the assign op.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable. If `read_value` is false, instead returns None in\n",
            " |        Eager mode and the assign op in graph mode.\n",
            " |  \n",
            " |  assign_add(self, delta, use_locking=False, name=None, read_value=True)\n",
            " |      Adds a value to this variable.\n",
            " |      \n",
            " |       This is essentially a shortcut for `assign_add(self, delta)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        delta: A `Tensor`. The value to add to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: The name of the operation to be created\n",
            " |        read_value: if True, will return something which evaluates to the new\n",
            " |          value of the variable; if False will return the assign op.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable. If `read_value` is false, instead returns None in\n",
            " |        Eager mode and the assign op in graph mode.\n",
            " |  \n",
            " |  assign_sub(self, delta, use_locking=False, name=None, read_value=True)\n",
            " |      Subtracts a value from this variable.\n",
            " |      \n",
            " |      This is essentially a shortcut for `assign_sub(self, delta)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        delta: A `Tensor`. The value to subtract from this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: The name of the operation to be created\n",
            " |        read_value: if True, will return something which evaluates to the new\n",
            " |          value of the variable; if False will return the assign op.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable. If `read_value` is false, instead returns None in\n",
            " |        Eager mode and the assign op in graph mode.\n",
            " |  \n",
            " |  batch_scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Assigns `tf.IndexedSlices` to this variable batch-wise.\n",
            " |      \n",
            " |      Analogous to `batch_gather`. This assumes that this variable and the\n",
            " |      sparse_delta IndexedSlices have a series of leading dimensions that are the\n",
            " |      same for all of them, and the updates are performed on the last dimension of\n",
            " |      indices. In other words, the dimensions should be the following:\n",
            " |      \n",
            " |      `num_prefix_dims = sparse_delta.indices.ndims - 1`\n",
            " |      `batch_dim = num_prefix_dims + 1`\n",
            " |      `sparse_delta.updates.shape = sparse_delta.indices.shape + var.shape[\n",
            " |           batch_dim:]`\n",
            " |      \n",
            " |      where\n",
            " |      \n",
            " |      `sparse_delta.updates.shape[:num_prefix_dims]`\n",
            " |      `== sparse_delta.indices.shape[:num_prefix_dims]`\n",
            " |      `== var.shape[:num_prefix_dims]`\n",
            " |      \n",
            " |      And the operation performed can be expressed as:\n",
            " |      \n",
            " |      `var[i_1, ..., i_n,\n",
            " |           sparse_delta.indices[i_1, ..., i_n, j]] = sparse_delta.updates[\n",
            " |              i_1, ..., i_n, j]`\n",
            " |      \n",
            " |      When sparse_delta.indices is a 1D tensor, this operation is equivalent to\n",
            " |      `scatter_update`.\n",
            " |      \n",
            " |      To avoid this operation one can looping over the first `ndims` of the\n",
            " |      variable and using `scatter_update` on the subtensors that result of slicing\n",
            " |      the first dimension. This is a valid option for `ndims = 1`, but less\n",
            " |      efficient than this implementation.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  count_up_to(self, limit)\n",
            " |      Increments this variable until it reaches `limit`. (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Prefer Dataset.range instead.\n",
            " |      \n",
            " |      When that Op is run it tries to increment the variable by `1`. If\n",
            " |      incrementing the variable would bring it above `limit` then the Op raises\n",
            " |      the exception `OutOfRangeError`.\n",
            " |      \n",
            " |      If no error is raised, the Op outputs the value of the variable before\n",
            " |      the increment.\n",
            " |      \n",
            " |      This is essentially a shortcut for `count_up_to(self, limit)`.\n",
            " |      \n",
            " |      Args:\n",
            " |        limit: value at which incrementing the variable raises an error.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` that will hold the variable value before the increment. If no\n",
            " |        other Op modifies this variable, the values produced will all be\n",
            " |        distinct.\n",
            " |  \n",
            " |  eval(self, session=None)\n",
            " |      In a session, computes and returns the value of this variable.\n",
            " |      \n",
            " |      This is not a graph construction method, it does not add ops to the graph.\n",
            " |      \n",
            " |      This convenience method requires a session where the graph\n",
            " |      containing this variable has been launched. If no session is\n",
            " |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
            " |      information on launching a graph and on sessions.\n",
            " |      \n",
            " |      ```python\n",
            " |      v = tf.Variable([1, 2])\n",
            " |      init = tf.compat.v1.global_variables_initializer()\n",
            " |      \n",
            " |      with tf.compat.v1.Session() as sess:\n",
            " |          sess.run(init)\n",
            " |          # Usage passing the session explicitly.\n",
            " |          print(v.eval(sess))\n",
            " |          # Usage with the default session.  The 'with' block\n",
            " |          # above makes 'sess' the default session.\n",
            " |          print(v.eval())\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        session: The session to use to evaluate this variable. If none, the\n",
            " |          default session is used.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A numpy `ndarray` with a copy of the value of this variable.\n",
            " |  \n",
            " |  experimental_ref(self)\n",
            " |      DEPRECATED FUNCTION\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Use ref() instead.\n",
            " |  \n",
            " |  gather_nd(self, indices, name=None)\n",
            " |      Gather slices from `params` into a Tensor with shape specified by `indices`.\n",
            " |      \n",
            " |      See tf.gather_nd for details.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: A `Tensor`. Must be one of the following types: `int32`, `int64`.\n",
            " |          Index tensor.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `params`.\n",
            " |  \n",
            " |  get_shape(self)\n",
            " |      Alias of `Variable.shape`.\n",
            " |  \n",
            " |  initialized_value(self)\n",
            " |      Returns the value of the initialized variable. (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            " |      \n",
            " |      You should use this instead of the variable itself to initialize another\n",
            " |      variable with a value that depends on the value of this variable.\n",
            " |      \n",
            " |      ```python\n",
            " |      # Initialize 'v' with a random tensor.\n",
            " |      v = tf.Variable(tf.random.truncated_normal([10, 40]))\n",
            " |      # Use `initialized_value` to guarantee that `v` has been\n",
            " |      # initialized before its value is used to initialize `w`.\n",
            " |      # The random values are picked only once.\n",
            " |      w = tf.Variable(v.initialized_value() * 2.0)\n",
            " |      ```\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` holding the value of this variable after its initializer\n",
            " |        has run.\n",
            " |  \n",
            " |  load(self, value, session=None)\n",
            " |      Load new value into this variable. (deprecated)\n",
            " |      \n",
            " |      Deprecated: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
            " |      Instructions for updating:\n",
            " |      Prefer Variable.assign which has equivalent behavior in 2.X.\n",
            " |      \n",
            " |      Writes new value to variable's memory. Doesn't add ops to the graph.\n",
            " |      \n",
            " |      This convenience method requires a session where the graph\n",
            " |      containing this variable has been launched. If no session is\n",
            " |      passed, the default session is used.  See `tf.compat.v1.Session` for more\n",
            " |      information on launching a graph and on sessions.\n",
            " |      \n",
            " |      ```python\n",
            " |      v = tf.Variable([1, 2])\n",
            " |      init = tf.compat.v1.global_variables_initializer()\n",
            " |      \n",
            " |      with tf.compat.v1.Session() as sess:\n",
            " |          sess.run(init)\n",
            " |          # Usage passing the session explicitly.\n",
            " |          v.load([2, 3], sess)\n",
            " |          print(v.eval(sess)) # prints [2 3]\n",
            " |          # Usage with the default session.  The 'with' block\n",
            " |          # above makes 'sess' the default session.\n",
            " |          v.load([3, 4], sess)\n",
            " |          print(v.eval()) # prints [3 4]\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |          value: New variable value\n",
            " |          session: The session to use to evaluate this variable. If none, the\n",
            " |            default session is used.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: Session is not passed and no default session\n",
            " |  \n",
            " |  read_value(self)\n",
            " |      Returns the value of this variable, read in the current context.\n",
            " |      \n",
            " |      Can be different from value() if it's on another device, with control\n",
            " |      dependencies, etc.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` containing the value of the variable.\n",
            " |  \n",
            " |  ref(self)\n",
            " |      Returns a hashable reference object to this Variable.\n",
            " |      \n",
            " |      The primary use case for this API is to put variables in a set/dictionary.\n",
            " |      We can't put variables in a set/dictionary as `variable.__hash__()` is no\n",
            " |      longer available starting Tensorflow 2.0.\n",
            " |      \n",
            " |      The following will raise an exception starting 2.0\n",
            " |      \n",
            " |      >>> x = tf.Variable(5)\n",
            " |      >>> y = tf.Variable(10)\n",
            " |      >>> z = tf.Variable(10)\n",
            " |      >>> variable_set = {x, y, z}\n",
            " |      Traceback (most recent call last):\n",
            " |        ...\n",
            " |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
            " |      >>> variable_dict = {x: 'five', y: 'ten'}\n",
            " |      Traceback (most recent call last):\n",
            " |        ...\n",
            " |      TypeError: Variable is unhashable. Instead, use tensor.ref() as the key.\n",
            " |      \n",
            " |      Instead, we can use `variable.ref()`.\n",
            " |      \n",
            " |      >>> variable_set = {x.ref(), y.ref(), z.ref()}\n",
            " |      >>> x.ref() in variable_set\n",
            " |      True\n",
            " |      >>> variable_dict = {x.ref(): 'five', y.ref(): 'ten', z.ref(): 'ten'}\n",
            " |      >>> variable_dict[y.ref()]\n",
            " |      'ten'\n",
            " |      \n",
            " |      Also, the reference object provides `.deref()` function that returns the\n",
            " |      original Variable.\n",
            " |      \n",
            " |      >>> x = tf.Variable(5)\n",
            " |      >>> x.ref().deref()\n",
            " |      <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=5>\n",
            " |  \n",
            " |  scatter_add(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Adds `tf.IndexedSlices` to this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be added to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_div(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Divide this variable by `tf.IndexedSlices`.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to divide this variable by.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_max(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Updates this variable with the max of `tf.IndexedSlices` and itself.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to use as an argument of max with this\n",
            " |          variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_min(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Updates this variable with the min of `tf.IndexedSlices` and itself.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to use as an argument of min with this\n",
            " |          variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_mul(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Multiply this variable by `tf.IndexedSlices`.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to multiply this variable by.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_nd_add(self, indices, updates, name=None)\n",
            " |      Applies sparse addition to individual values or slices in a Variable.\n",
            " |      \n",
            " |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
            " |      \n",
            " |      `indices` must be integer tensor, containing indices into self.\n",
            " |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
            " |      \n",
            " |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
            " |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
            " |      dimension of self.\n",
            " |      \n",
            " |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
            " |      \n",
            " |      ```\n",
            " |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
            " |      ```\n",
            " |      \n",
            " |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
            " |      8 elements. In Python, that update would look like this:\n",
            " |      \n",
            " |      ```python\n",
            " |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
            " |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
            " |          updates = tf.constant([9, 10, 11, 12])\n",
            " |          v.scatter_nd_add(indices, updates)\n",
            " |          print(v)\n",
            " |      ```\n",
            " |      \n",
            " |      The resulting update to v would look like this:\n",
            " |      \n",
            " |          [1, 13, 3, 14, 14, 6, 7, 20]\n",
            " |      \n",
            " |      See `tf.scatter_nd` for more details about how to make updates to\n",
            " |      slices.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The indices to be used in the operation.\n",
            " |        updates: The values to be used in the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |  \n",
            " |  scatter_nd_sub(self, indices, updates, name=None)\n",
            " |      Applies sparse subtraction to individual values or slices in a Variable.\n",
            " |      \n",
            " |      Assuming the variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
            " |      \n",
            " |      `indices` must be integer tensor, containing indices into self.\n",
            " |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
            " |      \n",
            " |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
            " |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
            " |      dimension of self.\n",
            " |      \n",
            " |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
            " |      \n",
            " |      ```\n",
            " |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
            " |      ```\n",
            " |      \n",
            " |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
            " |      8 elements. In Python, that update would look like this:\n",
            " |      \n",
            " |      ```python\n",
            " |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
            " |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
            " |          updates = tf.constant([9, 10, 11, 12])\n",
            " |          v.scatter_nd_sub(indices, updates)\n",
            " |          print(v)\n",
            " |      ```\n",
            " |      \n",
            " |      After the update `v` would look like this:\n",
            " |      \n",
            " |          [1, -9, 3, -6, -4, 6, 7, -4]\n",
            " |      \n",
            " |      See `tf.scatter_nd` for more details about how to make updates to\n",
            " |      slices.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The indices to be used in the operation.\n",
            " |        updates: The values to be used in the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |  \n",
            " |  scatter_nd_update(self, indices, updates, name=None)\n",
            " |      Applies sparse assignment to individual values or slices in a Variable.\n",
            " |      \n",
            " |      The Variable has rank `P` and `indices` is a `Tensor` of rank `Q`.\n",
            " |      \n",
            " |      `indices` must be integer tensor, containing indices into self.\n",
            " |      It must be shape `[d_0, ..., d_{Q-2}, K]` where `0 < K <= P`.\n",
            " |      \n",
            " |      The innermost dimension of `indices` (with length `K`) corresponds to\n",
            " |      indices into elements (if `K = P`) or slices (if `K < P`) along the `K`th\n",
            " |      dimension of self.\n",
            " |      \n",
            " |      `updates` is `Tensor` of rank `Q-1+P-K` with shape:\n",
            " |      \n",
            " |      ```\n",
            " |      [d_0, ..., d_{Q-2}, self.shape[K], ..., self.shape[P-1]].\n",
            " |      ```\n",
            " |      \n",
            " |      For example, say we want to add 4 scattered elements to a rank-1 tensor to\n",
            " |      8 elements. In Python, that update would look like this:\n",
            " |      \n",
            " |      ```python\n",
            " |          v = tf.Variable([1, 2, 3, 4, 5, 6, 7, 8])\n",
            " |          indices = tf.constant([[4], [3], [1] ,[7]])\n",
            " |          updates = tf.constant([9, 10, 11, 12])\n",
            " |          v.scatter_nd_update(indices, updates)\n",
            " |          print(v)\n",
            " |      ```\n",
            " |      \n",
            " |      The resulting update to v would look like this:\n",
            " |      \n",
            " |          [1, 11, 3, 10, 9, 6, 7, 12]\n",
            " |      \n",
            " |      See `tf.scatter_nd` for more details about how to make updates to\n",
            " |      slices.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The indices to be used in the operation.\n",
            " |        updates: The values to be used in the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |  \n",
            " |  scatter_sub(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Subtracts `tf.IndexedSlices` from this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be subtracted from this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  scatter_update(self, sparse_delta, use_locking=False, name=None)\n",
            " |      Assigns `tf.IndexedSlices` to this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        sparse_delta: `tf.IndexedSlices` to be assigned to this variable.\n",
            " |        use_locking: If `True`, use locking during the operation.\n",
            " |        name: the name of the operation.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The updated variable.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: if `sparse_delta` is not an `IndexedSlices`.\n",
            " |  \n",
            " |  set_shape(self, shape)\n",
            " |      Overrides the shape for this variable.\n",
            " |      \n",
            " |      Args:\n",
            " |        shape: the `TensorShape` representing the overridden shape.\n",
            " |  \n",
            " |  sparse_read(self, indices, name=None)\n",
            " |      Gather slices from params axis axis according to indices.\n",
            " |      \n",
            " |      This function supports a subset of tf.gather, see tf.gather for details on\n",
            " |      usage.\n",
            " |      \n",
            " |      Args:\n",
            " |        indices: The index `Tensor`.  Must be one of the following types: `int32`,\n",
            " |          `int64`. Must be in range `[0, params.shape[axis])`.\n",
            " |        name: A name for the operation (optional).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`. Has the same type as `params`.\n",
            " |  \n",
            " |  to_proto(self, export_scope=None)\n",
            " |      Converts a `Variable` to a `VariableDef` protocol buffer.\n",
            " |      \n",
            " |      Args:\n",
            " |        export_scope: Optional `string`. Name scope to remove.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `VariableDef` protocol buffer, or `None` if the `Variable` is not\n",
            " |        in the specified name scope.\n",
            " |  \n",
            " |  value(self)\n",
            " |      Returns the last snapshot of this variable.\n",
            " |      \n",
            " |      You usually do not need to call this method as all ops that need the value\n",
            " |      of the variable call it automatically through a `convert_to_tensor()` call.\n",
            " |      \n",
            " |      Returns a `Tensor` which holds the value of the variable.  You can not\n",
            " |      assign a new value to this tensor as it is not a reference to the variable.\n",
            " |      \n",
            " |      To avoid copies, if the consumer of the returned value is on the same device\n",
            " |      as the variable, this actually returns the live value of the variable, not\n",
            " |      a copy.  Updates to the variable are seen by the consumer.  If the consumer\n",
            " |      is on a different device it will get a copy of the variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor` containing the value of the variable.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods defined here:\n",
            " |  \n",
            " |  from_proto(variable_def, import_scope=None)\n",
            " |      Returns a `Variable` object created from `variable_def`.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  aggregation\n",
            " |  \n",
            " |  constraint\n",
            " |      Returns the constraint function associated with this variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The constraint function that was passed to the variable constructor.\n",
            " |        Can be `None` if no constraint was passed.\n",
            " |  \n",
            " |  device\n",
            " |      The device of this variable.\n",
            " |  \n",
            " |  dtype\n",
            " |      The `DType` of this variable.\n",
            " |  \n",
            " |  graph\n",
            " |      The `Graph` of this variable.\n",
            " |  \n",
            " |  initial_value\n",
            " |      Returns the Tensor used as the initial value for the variable.\n",
            " |      \n",
            " |      Note that this is different from `initialized_value()` which runs\n",
            " |      the op that initializes the variable before returning its value.\n",
            " |      This method returns the tensor that is used by the op that initializes\n",
            " |      the variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `Tensor`.\n",
            " |  \n",
            " |  initializer\n",
            " |      The initializer operation for this variable.\n",
            " |  \n",
            " |  name\n",
            " |      The name of this variable.\n",
            " |  \n",
            " |  op\n",
            " |      The `Operation` of this variable.\n",
            " |  \n",
            " |  shape\n",
            " |      The `TensorShape` of this variable.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `TensorShape`.\n",
            " |  \n",
            " |  synchronization\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  SaveSliceInfo = <class 'tensorflow.python.ops.variables.Variable.SaveS...\n",
            " |      Information on how to save this Variable as a slice.\n",
            " |      \n",
            " |      Provides internal support for saving variables as slices of a larger\n",
            " |      variable.  This API is not public and is subject to change.\n",
            " |      \n",
            " |      Available properties:\n",
            " |      \n",
            " |      * full_name\n",
            " |      * full_shape\n",
            " |      * var_offset\n",
            " |      * var_shape\n",
            " |  \n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  __array_priority__ = 100\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.trackable.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.Variable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV7_uzdR_F4c",
        "outputId": "dbe2bd14-249b-4bf0-c2f1-1af02d98c59a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'I:0' shape=(5,) dtype=int32, numpy=array([0, 1, 2, 3, 4], dtype=int32)>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a variable tensor\n",
        "I = tf.Variable(initial_value=np.arange(start=0, stop=5), \n",
        "                trainable=True, \n",
        "                validate_shape=True, \n",
        "                caching_device=None, \n",
        "                name='I', \n",
        "                variable_def=None, \n",
        "                dtype=tf.int32, \n",
        "                import_scope=None,\n",
        "                constraint=None,\n",
        "                synchronization=tf.VariableSynchronization.AUTO,\n",
        "                experimental_enable_variable_lifting=True)\n",
        "I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on method assign in module tensorflow.python.ops.resource_variable_ops:\n",
            "\n",
            "assign(value, use_locking=None, name=None, read_value=True) method of tensorflow.python.ops.resource_variable_ops.ResourceVariable instance\n",
            "    Assigns a new value to this variable.\n",
            "    \n",
            "    Args:\n",
            "      value: A `Tensor`. The new value for this variable.\n",
            "      use_locking: If `True`, use locking during the assignment.\n",
            "      name: The name to use for the assignment.\n",
            "      read_value: A `bool`. Whether to read and return the new value of the\n",
            "        variable or not.\n",
            "    \n",
            "    Returns:\n",
            "      If `read_value` is `True`, this method will return the new value of the\n",
            "      variable after the assignment has completed. Otherwise, when in graph mode\n",
            "      it will return the `Operation` that does the assignment, and when in eager\n",
            "      mode it will return `None`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(I.assign)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukatOuCG_4CY",
        "outputId": "a6351712-d894-4e23-c57e-2ab45537d566"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int32, numpy=array([ 0,  1,  2,  3, 50], dtype=int32)>"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Assign the final value a new value of 50\n",
        "I.assign(value=[0, 1, 2, 3, 50], \n",
        "         use_locking=None, \n",
        "         name=None, \n",
        "         read_value=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3r2Pya_vAnLz",
        "outputId": "a65b7db9-a0ec-47d7-f3cf-12cb60eb31ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'I:0' shape=(5,) dtype=int32, numpy=array([ 0,  1,  2,  3, 50], dtype=int32)>"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The change happens in place (the last value is now 50, not 4)\n",
        "I"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on method assign_add in module tensorflow.python.ops.resource_variable_ops:\n",
            "\n",
            "assign_add(delta, use_locking=None, name=None, read_value=True) method of tensorflow.python.ops.resource_variable_ops.ResourceVariable instance\n",
            "    Adds a value to this variable.\n",
            "    \n",
            "    Args:\n",
            "      delta: A `Tensor`. The value to add to this variable.\n",
            "      use_locking: If `True`, use locking during the operation.\n",
            "      name: The name to use for the operation.\n",
            "      read_value: A `bool`. Whether to read and return the new value of the\n",
            "        variable or not.\n",
            "    \n",
            "    Returns:\n",
            "      If `read_value` is `True`, this method will return the new value of the\n",
            "      variable after the assignment has completed. Otherwise, when in graph mode\n",
            "      it will return the `Operation` that does the assignment, and when in eager\n",
            "      mode it will return `None`.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(I.assign_add)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZie_FduAo5O",
        "outputId": "0b7d34bf-76e9-429e-ecec-7bb2beedb750"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'UnreadVariable' shape=(5,) dtype=int32, numpy=array([10, 11, 12, 13, 60], dtype=int32)>"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Add 10 to every element in I\n",
        "I.assign_add(delta=[10, 10, 10, 10, 10], \n",
        "             use_locking=None, \n",
        "             name=None, \n",
        "             read_value=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qXODgVOBDzC",
        "outputId": "5fd97dbb-eb43-4e55-b74a-f4e94956b4c2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Variable 'I:0' shape=(5,) dtype=int32, numpy=array([10, 11, 12, 13, 60], dtype=int32)>"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Again, the change happens in place\n",
        "I"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L2IyQhl-Z73"
      },
      "source": [
        "## Tensors and NumPy\n",
        "\n",
        "We've seen some examples of tensors interact with NumPy arrays, such as, using NumPy arrays to create tensors. \n",
        "\n",
        "Tensors can also be converted to NumPy arrays using:\n",
        "\n",
        "* `np.array()` - pass a tensor to convert to an ndarray (NumPy's main datatype).\n",
        "* `tensor.numpy()` - call on a tensor to convert to an ndarray.\n",
        "\n",
        "Doing this is helpful as it makes tensors iterable as well as allows us to use any of NumPy's methods on them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLHrij0vBywD",
        "outputId": "83109e2d-e3be-4e95-e6dd-d84713e9dc70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor from a NumPy array\n",
        "J = tf.constant(value=np.array([3., 7., 10.]), \n",
        "                dtype=None, \n",
        "                shape=None,\n",
        "                name='J')\n",
        "J"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0KBe_FqCKdU",
        "outputId": "c4de5d97-8095-4e0c-86de-67fad637d88d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 3.,  7., 10.]), numpy.ndarray)"
            ]
          },
          "execution_count": 124,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert tensor J to NumPy with np.array()\n",
        "np.array(J), type(np.array(J))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on method numpy in module tensorflow.python.framework.ops:\n",
            "\n",
            "numpy() method of tensorflow.python.framework.ops.EagerTensor instance\n",
            "    Copy of the contents of this Tensor into a NumPy array or scalar.\n",
            "    \n",
            "    Unlike NumPy arrays, Tensors are immutable, so this method has to copy\n",
            "    the contents to ensure safety. Use `memoryview` to get a readonly\n",
            "    view of the contents without doing a copy:\n",
            "    \n",
            "    >>> t = tf.constant([42])\n",
            "    >>> np.array(memoryview(t))\n",
            "    array([42], dtype=int32)\n",
            "    \n",
            "    Note that `memoryview` is only zero-copy for Tensors on CPU. If a Tensor\n",
            "    is on GPU, it will have to be transferred to CPU first in order for\n",
            "    `memoryview` to work.\n",
            "    \n",
            "    Returns:\n",
            "      A NumPy array of the same shape and dtype or a NumPy scalar, if this\n",
            "      Tensor has rank 0.\n",
            "    \n",
            "    Raises:\n",
            "      ValueError: If the dtype of this Tensor does not have a compatible\n",
            "        NumPy dtype.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(J.numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxKsJPvSCUPI",
        "outputId": "39cef6d1-2deb-4ec2-cbdf-b9e6f3b06488"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 3.,  7., 10.]), numpy.ndarray)"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert tensor J to NumPy with .numpy()\n",
        "J.numpy(), type(J.numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SL4xHtNWDIT5"
      },
      "source": [
        "By default tensors have `dtype=float32`, where as NumPy arrays have `dtype=float64`.\n",
        "\n",
        "This is because neural networks (which are usually built with TensorFlow) can generally work very well with less precision (32-bit rather than 64-bit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrQoUeyPCXU9",
        "outputId": "d4790fab-fc39-41d8-bf6b-c628d0f1ada0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tf.float64, tf.float32)"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a tensor from NumPy and from an array\n",
        "# NOTE: Will be float64 (due to NumPy)\n",
        "numpy_J = tf.constant(value=np.array([3., 7., 10.]), dtype=None, shape=None, name='numpy_J')\n",
        "# note: will be float32 (due to being TensorFlow default)\n",
        "tensor_J = tf.constant(value=[3., 7., 10.], dtype=None, shape=None, name=None) \n",
        "numpy_J.dtype, tensor_J.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ytLPBWF1wxt"
      },
      "source": [
        "## Using `@tf.function`\n",
        "\n",
        "In your TensorFlow adventures, you might come across Python functions which have the decorator [`@tf.function`](https://www.tensorflow.org/api_docs/python/tf/function).\n",
        "\n",
        "If you aren't sure what Python decorators do, [read RealPython's guide on them](https://realpython.com/primer-on-python-decorators/).\n",
        "\n",
        "But in short, decorators modify a function in one way or another.\n",
        "\n",
        "In the `@tf.function` decorator case, it turns a Python function into a callable TensorFlow graph. Which is a fancy way of saying, if you've written your own Python function, and you decorate it with `@tf.function`, when you export your code (to potentially run on another device), TensorFlow will attempt to convert it into a fast(er) version of itself (by making it part of a computation graph).\n",
        "\n",
        "For more on this, read the [Better performnace with tf.function](https://www.tensorflow.org/guide/function) guide."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URzFiwPoFDI7",
        "outputId": "a6c7bbe3-4bfb-499a-91e9-f8bd4313b6a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
            ]
          },
          "execution_count": 128,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a simple function\n",
        "def function(x, y):\n",
        "  return x ** 2 + y\n",
        "\n",
        "x = tf.constant(value=np.arange(0, 10), dtype=None, shape=None, name='x')\n",
        "y = tf.constant(value=np.arange(10, 20), dtype=None, shape=None, name='y')\n",
        "function(x, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHGbvlkXF7Gs",
        "outputId": "40f5d83c-f2fc-4c50-fdfe-f37b3fdfa75b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([ 10,  12,  16,  22,  30,  40,  52,  66,  82, 100])>"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the same function and decorate it with tf.function\n",
        "@tf.function\n",
        "def tf_function(x, y):\n",
        "  return x ** 2 + y\n",
        "\n",
        "tf_function(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsiapEnTGBbH"
      },
      "source": [
        "If you noticed no difference between the above two functions (the decorated one and the non-decorated one) you'd be right.\n",
        "\n",
        "Much of the difference happens behind the scenes. One of the main ones being potential code speed-ups where possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8AQmchkxKDn"
      },
      "source": [
        "## Finding access to GPUs\n",
        "\n",
        "We've mentioned GPUs plenty of times throughout this notebook.\n",
        "\n",
        "So how do you check if you've got one available?\n",
        "\n",
        "You can check if you've got access to a GPU using [`tf.config.list_physical_devices()`](https://www.tensorflow.org/guide/gpu)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rFNSeODxi3L",
        "outputId": "7dd6e024-bed3-46ad-d96f-bea634317e24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
          ]
        }
      ],
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8165PtH8xyq5"
      },
      "source": [
        "If the above outputs an empty array (or nothing), it means you don't have access to a GPU (or at least TensorFlow can't find it).\n",
        "\n",
        "If you're running in Google Colab, you can access a GPU by going to *Runtime -> Change Runtime Type -> Select GPU* (**note:** after doing this your notebook will restart and any variables you've saved will be lost).\n",
        "\n",
        "Once you've changed your runtime type, run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iAvMwRbZyULE",
        "outputId": "eaab2fea-5960-43f1-899f-1eee870a76f9"
      },
      "outputs": [],
      "source": [
        "# import tensorflow as tf\n",
        "# print(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3yu0LKiyZlJ"
      },
      "source": [
        "If you've got access to a GPU, the cell above should output something like:\n",
        "\n",
        "`[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]`\n",
        "\n",
        "You can also find information about your GPU using `!nvidia-smi`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOuVvG5kyefS",
        "outputId": "fc734522-6270-447d-cefc-34e9fbe4a89b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: /home/steeve/Anaconda3/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
            "Tue Apr  4 15:40:57 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.89.02    Driver Version: 525.89.02    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA GeForce ...  Off  | 00000000:05:00.0  On |                  N/A |\n",
            "| 41%   72C    P2    70W / 250W |   1298MiB / 11264MiB |      8%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   1  NVIDIA GeForce ...  Off  | 00000000:06:00.0 Off |                  N/A |\n",
            "| 30%   51C    P8    12W / 250W |    307MiB / 11264MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   2  NVIDIA GeForce ...  Off  | 00000000:09:00.0 Off |                  N/A |\n",
            "| 26%   44C    P8    10W / 250W |    307MiB / 11264MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "|   3  NVIDIA GeForce ...  Off  | 00000000:0A:00.0 Off |                  N/A |\n",
            "| 23%   38C    P8    10W / 250W |    307MiB / 11264MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|    0   N/A  N/A      2318      G   /usr/lib/xorg/Xorg                276MiB |\n",
            "|    0   N/A  N/A      2686      G   /usr/bin/gnome-shell               43MiB |\n",
            "|    0   N/A  N/A     21349      G   ...180519303142017936,131072      124MiB |\n",
            "|    0   N/A  N/A    306764      G   ...RendererForSitePerProcess      472MiB |\n",
            "|    0   N/A  N/A    308208      C   ...nsorflow-py310/bin/python      376MiB |\n",
            "|    1   N/A  N/A      2318      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    1   N/A  N/A    308208      C   ...nsorflow-py310/bin/python      298MiB |\n",
            "|    2   N/A  N/A      2318      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    2   N/A  N/A    308208      C   ...nsorflow-py310/bin/python      298MiB |\n",
            "|    3   N/A  N/A      2318      G   /usr/lib/xorg/Xorg                  4MiB |\n",
            "|    3   N/A  N/A    308208      C   ...nsorflow-py310/bin/python      298MiB |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pER7mLFezV9u"
      },
      "source": [
        "> ðŸ”‘ **Note:** If you have access to a GPU, TensorFlow will automatically use it whenever possible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcCZxK61VIv0"
      },
      "source": [
        "## ðŸ›  Exercises\n",
        "\n",
        "1. Create a vector, scalar, matrix and tensor with values of your choosing using `tf.constant()`.\n",
        "2. Find the shape, rank and size of the tensors you created in 1.\n",
        "3. Create two tensors containing random values between 0 and 1 with shape `[5, 300]`.\n",
        "4. Multiply the two tensors you created in 3 using matrix multiplication.\n",
        "5. Multiply the two tensors you created in 3 using dot product.\n",
        "6. Create a tensor with random values between 0 and 1 with shape `[224, 224, 3]`.\n",
        "7. Find the min and max values of the tensor you created in 6.\n",
        "8. Created a tensor with random values of shape `[1, 224, 224, 3]` then squeeze it to change the shape to `[224, 224, 3]`.\n",
        "9. Create a tensor with shape `[10]` using your own choice of values, then find the index which has the maximum value.\n",
        "10. One-hot encode the tensor you created in 9."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1: Create a scalar, vector, matrix and tensor with tf.constant\n",
        "my_scalar = tf.constant(value=1, dtype=None, shape=None, name='my_scalar')\n",
        "my_vector = tf.constant(value=[1, 2, 3], dtype=None, shape=None, name='my_vector')\n",
        "my_matrix = tf.constant(value=[[1, 2, 3], [4, 5, 6]], dtype=None, shape=None, name='my_matrix')\n",
        "my_tensor = tf.constant(value=tf.random.normal(shape=(3, 3, 3)), dtype=None, shape=None, name='my_tensor')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "my_scalar:\n",
            "tf.Tensor(1, shape=(), dtype=int32)\n",
            "my_vector:\n",
            "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
            "my_matrix:\n",
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [4 5 6]], shape=(2, 3), dtype=int32)\n",
            "my_tensor:\n",
            "tf.Tensor(\n",
            "[[[ 8.4224582e-02 -8.6090374e-01  3.7812304e-01]\n",
            "  [-5.1962738e-03 -4.9453196e-01  6.1781919e-01]\n",
            "  [-3.3082047e-01 -1.3840806e-03 -4.2373410e-01]]\n",
            "\n",
            " [[-1.3872087e+00 -1.5488191e+00 -5.3198391e-01]\n",
            "  [-4.4756433e-01 -2.0115814e+00 -5.7926011e-01]\n",
            "  [ 5.7938927e-01  1.3041967e+00  6.7720258e-01]]\n",
            "\n",
            " [[-7.4587613e-01  1.0378964e+00  1.3820479e+00]\n",
            "  [ 1.4319172e+00 -3.7643117e-01  9.8158473e-01]\n",
            "  [-2.3597860e-01 -3.3763257e-01 -8.9593250e-01]]], shape=(3, 3, 3), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "print(\"my_scalar:\", end=\"\\n\")\n",
        "print(my_scalar)\n",
        "print(\"my_vector:\", end=\"\\n\")\n",
        "print(my_vector)\n",
        "print(\"my_matrix:\", end=\"\\n\")\n",
        "print(my_matrix)\n",
        "print(\"my_tensor:\", end=\"\\n\")\n",
        "print(my_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name: my_scalar, shape: (), rank: 0, size: 1\n",
            "name: my_vector, shape: (3,), rank: 1, size: 3\n",
            "name: my_matrix, shape: (2, 3), rank: 2, size: 6\n",
            "name: my_tensor, shape: (3, 3, 3), rank: 3, size: 27\n"
          ]
        }
      ],
      "source": [
        "# 2: Find the shape, rank and size of the tensors you created in 1.\n",
        "print(f\"name: my_scalar, shape: {my_scalar.shape}, rank: {tf.rank(input=my_scalar, name=None)}, size: {tf.size(input=my_scalar, name=None, out_type=tf.int32)}\")\n",
        "print(f\"name: my_vector, shape: {my_vector.shape}, rank: {tf.rank(input=my_vector, name=None)}, size: {tf.size(input=my_vector, name=None, out_type=tf.int32)}\")\n",
        "print(f\"name: my_matrix, shape: {my_matrix.shape}, rank: {tf.rank(input=my_matrix, name=None)}, size: {tf.size(input=my_matrix, name=None, out_type=tf.int32)}\")\n",
        "print(f\"name: my_tensor, shape: {my_tensor.shape}, rank: {tf.rank(input=my_tensor, name=None)}, size: {tf.size(input=my_tensor, name=None, out_type=tf.int32)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor_1:\n",
            "tf.Tensor(\n",
            "[[0.7493447  0.73561966 0.45230794 ... 0.5816356  0.5627874  0.7491298 ]\n",
            " [0.6438937  0.6938418  0.04408407 ... 0.04825139 0.5099728  0.26470542]\n",
            " [0.21373153 0.6683699  0.78474844 ... 0.19658887 0.22030771 0.3766911 ]\n",
            " [0.68190825 0.29304636 0.5415933  ... 0.37111604 0.76053166 0.7538099 ]\n",
            " [0.8011551  0.48830473 0.13867617 ... 0.20301867 0.8378159  0.19984365]], shape=(5, 300), dtype=float32)\n",
            "tensor_2:\n",
            "tf.Tensor(\n",
            "[[0.6932683  0.79913497 0.381521   ... 0.7023829  0.9509897  0.2274468 ]\n",
            " [0.03644454 0.6579336  0.27609527 ... 0.6680317  0.42852902 0.17845905]\n",
            " [0.28606403 0.3063997  0.25755703 ... 0.6562083  0.7018373  0.76578414]\n",
            " [0.71172917 0.7854034  0.6951294  ... 0.03848457 0.6082274  0.23704243]\n",
            " [0.40945458 0.49275637 0.46033657 ... 0.06898165 0.74632454 0.56117034]], shape=(5, 300), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "# 3: Create two tensors containing random values between 0 and 1 with shape [5, 300]\n",
        "random_gen = tf.random.Generator.from_seed(seed=42)\n",
        "tensor_1 = random_gen.uniform(shape=(5, 300), minval=0, maxval=1, dtype=tf.float32, name='tensor_1')\n",
        "tensor_2 = random_gen.uniform(shape=(5, 300), minval=0, maxval=1, dtype=tf.float32, name='tensor_2')\n",
        "print(\"tensor_1:\", end=\"\\n\")\n",
        "print(tensor_1)\n",
        "print(\"tensor_2:\", end=\"\\n\")\n",
        "print(tensor_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[76.06833 , 73.937325, 79.66014 , 72.811935, 80.26073 ],\n",
              "       [73.61879 , 69.42697 , 73.68848 , 67.24058 , 72.295715],\n",
              "       [72.67236 , 73.270164, 73.09715 , 70.96236 , 72.99701 ],\n",
              "       [75.63144 , 73.94716 , 75.9094  , 72.79953 , 75.467705],\n",
              "       [76.59262 , 73.65219 , 77.345085, 68.49897 , 77.61454 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 136,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4: Multiply the two tensors you created in 3 using matrix multiplication\n",
        "tf.matmul(a=tensor_1, b=tensor_2, transpose_a=False, transpose_b=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[76.06833 , 73.937325, 79.66014 , 72.811935, 80.26073 ],\n",
              "       [73.61879 , 69.42697 , 73.68848 , 67.24058 , 72.295715],\n",
              "       [72.67236 , 73.270164, 73.09715 , 70.96236 , 72.99701 ],\n",
              "       [75.63144 , 73.94716 , 75.9094  , 72.79953 , 75.467705],\n",
              "       [76.59262 , 73.65219 , 77.345085, 68.49897 , 77.61454 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 5: Multiply the two tensors you created in 3 using dot product\n",
        "tf.tensordot(a=tensor_1, \n",
        "             b=tf.transpose(a=tensor_2, perm=None, conjugate=False, name=None),\n",
        "             axes=1,\n",
        "             name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor_3:\n",
            "(224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# 6: Create a tensor with random values between 0 and 1 with shape `[224, 224, 3]`.\n",
        "tensor_3 = random_gen.uniform(shape=(224, 224, 3), minval=0, maxval=1, dtype=tf.float32, name='tensor_3')\n",
        "print(\"tensor_3:\", end=\"\\n\")\n",
        "print(tensor_3.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "min: 2.9802322387695312e-06\n",
            "max: 0.9999908208847046\n"
          ]
        }
      ],
      "source": [
        "# 7. Find the min and max values of the tensor you created in 6.\n",
        "print(f\"min: {tf.reduce_min(input_tensor=tensor_3, axis=None, keepdims=False, name=None)}\\nmax: {tf.reduce_max(input_tensor=tensor_3, axis=None, keepdims=False, name=None)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor_4 shape: (1, 224, 224, 3)\n",
            "tensor_4_squeezed shape: (224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# 8. Created a tensor with random values of shape `[1, 224, 224, 3]` then squeeze it to change the shape to `[224, 224, 3]`.\n",
        "tensor_4 = random_gen.uniform(shape=(1, 224, 224, 3), minval=0, maxval=1, dtype=tf.float32, name='tensor_4')\n",
        "tensor_4_squeezed = tf.squeeze(input=tensor_4, axis=None, name='tensor_4_squeezed')\n",
        "print(f\"tensor_4 shape: {tensor_4.shape}\")\n",
        "print(f\"tensor_4_squeezed shape: {tensor_4_squeezed.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum value index: 9\n"
          ]
        }
      ],
      "source": [
        "# 9. Create a tensor with shape `[10]` using your own choice of values, then find the index which has the maximum value.\n",
        "tensor_5 = tf.constant(value=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10], dtype=None, shape=[10], name='tensor_5')\n",
        "print(f\"Maximum value index: {tf.argmax(input=tensor_5, axis=None, output_type=tf.int64, name=None)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10, 10), dtype=float32, numpy=\n",
              "array([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "execution_count": 142,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 10. One-hot encode the tensor you created in 9.\n",
        "tf.one_hot(indices=tensor_5, depth=10, on_value=None, off_value=None, axis=None, dtype=None, name=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "505"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgHK5CjY3oVX"
      },
      "source": [
        "## ðŸ“– Extra-curriculum\n",
        "\n",
        "* Read through the [list of TensorFlow Python APIs](https://www.tensorflow.org/api_docs/python/), pick one we haven't gone through in this notebook, reverse engineer it (write out the documentation code for yourself) and figure out what it does.\n",
        "* Try to create a series of tensor functions to calculate your most recent grocery bill (it's okay if you don't use the names of the items, just the price in numerical form).\n",
        "  * How would you calculate your grocery bill for the month and for the year using tensors?\n",
        "* Go through the [TensorFlow 2.x quick start for beginners](https://www.tensorflow.org/tutorials/quickstart/beginner) tutorial (be sure to type out all of the code yourself, even if you don't understand it).\n",
        "  * Are there any functions we used in here that match what's used in there? Which are the same? Which haven't you seen before?\n",
        "* Watch the video [\"What's a tensor?\"](https://www.youtube.com/watch?v=f5liqUk0ZTw) - a great visual introduction to many of the concepts we've covered in this notebook."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMHAtaiFyROOAD0GJ9ufhOp",
      "collapsed_sections": [
        "fzjcZ4FHCOb5"
      ],
      "include_colab_link": true,
      "name": "00_tensorflow_fundamentals.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
